{
    "0": {
        "level 1": [
            [
                "def kappa_weighted(testData, k, w):\n    p0 = np.sum(w)\n    p1 = np.sum(testData * w) / p0\n    p_e = np.sum(np.sum(testData, axis=0) * np.sum(w, axis=0) / p0)\n    return (p1 - p_e) / (1 - p_e)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Calculate the weighted Cohen's kappa value of a k-dimensional matrix \"testData\" using the weight matrix \"w\". Return the computed value as a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    assert len(testData) == len(w), \"testData and w must have the same length\"\n    assert all(len(row) == k for row in testData), \"All rows in testData must have k elements\"\n    assert all(len(row) == k for row in w), \"All rows in w must have k elements\"\n\n    n = len(testData)\n    p_e = np.sum(np.multiply(testData, w)) / n\n    p_0 = np.sum([np.sum(row) * np.sum(w[i]) for i, row in enumerate(testData)]) / (n * (n - 1))\n    kappa = (p_e - p_0) / (1 - p_0)\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Calculate the weighted Cohen's kappa value of a k-dimensional matrix \"testData\" using the weight matrix \"w\". Return the computed value as a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    n = len(testData)\n    Pw = np.sum(w)\n    Pbar = np.sum(testData) / (n * k)\n    Pwbar = np.sum(np.multiply(testData, w)) / (n * k)\n    P = np.zeros(k)\n    Pw = np.zeros(k)\n    for i in range(k):\n        P[i] = np.sum(testData[:, i]) / (n * k)\n        Pw[i] = np.sum(np.multiply(testData[:, i], w)) / (n * k)\n    PbarW = np.sum(Pw) / k\n    numerator = PbarW - Pbar\n    denominator = 1 - PbarW\n    kappa = numerator / denominator if denominator != 0 else 0\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    overall_agreement = 0.0\n    agreement_expected = 0.0\n    total_items = 0\n\n    for i in range(k):\n        for j in range(k):\n            total = np.sum(testData[i][j] * w[i][j])\n            total_items += total\n            expected = np.sum(testData[i]) * np.sum(testData[j]) / k\n            agreement_expected += (expected**2)\n            overall_agreement += (total**2)\n\n    overall_agreement = overall_agreement - agreement_expected\n\n    kappa = (overall_agreement - agreement_expected) / (total_items - agreement_expected)\n    kappa *= (total_items / (total_items - 1))\n    kappa /= (1 - agreement_expected / total_items)\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    n = len(testData)\n    N = np.sum(testData)\n    sum_probs = np.sum(np.sum(testData * w, axis=1))\n    sum_w = np.sum(w)\n    sum_weighted_probs = np.sum(np.sum(testData * w * w, axis=1))\n\n    p0 = sum_probs / sum_w\n    po = (sum_probs / sum_w) ** 2\n    p_e = po + (1.0 - po) / (n - 1) * np.sum((np.sum(testData * w, axis=1) / sum_w)**2)\n\n    kappa = (p0 - p_e) / (1.0 - p_e)\n    \n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    p0 = np.sum(w)\n    p1 = np.sum(testData * w) / p0\n    p_e = np.sum((np.sum(testData, axis=0) / np.sum(testData)) ** 2 * w)\n    kappa = 1.0 - ((p0 - p1) / (1 - p_e))\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Compute the weighted Cohen's kappa metric for a matrix 'testData' of dimension k using the 'w' matrix for weights. \n    The result should be a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Compute the sum of weights and the sum of squares of weights. \n    W = np.sum(w)\n    W2 = np.sum(np.multiply(w, w))\n    # Compute the overall agreement in the data. \n    P0 = np.sum(testData * w) / W\n    # Compute the expected agreement under chance. \n    P1 = np.sum(np.multiply(testData, w)) * np.sum(np.multiply(testData, w)) / W2 / W\n    # Compute and return the kappa statistic. \n    return (P0 - P1) / (1 - P1)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Compute the weighted Cohen's kappa metric for a matrix 'testData' of dimension k using the 'w' matrix for weights. The result should be a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    sum_weight = 0\n    weighted_pairs = 0\n    for i in range(k):\n        for j in range(i+1, k):\n            sum_weight += w[i][j]\n            weighted_pairs += w[i][j] * testData[i][j]\n    observed_agreement = weighted_pairs / sum_weight\n\n    total_weight = sum_weight\n    chance_agreement = 0\n    for i in range(k):\n        chance_agreement += w[i][i]/k\n    chance_agreement /= total_weight\n\n    kappa = (observed_agreement - chance_agreement) / (1 - chance_agreement)\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    overall_agreement = 0.0\n    agreement_expected = 0.0\n    total_items = 0.0\n    for i in range(k):\n        for j in range(i+1, k):\n            weight_ij = w[i][j]\n            expected_ij = weight_ij * np.sum(testData[i]) * np.sum(testData[j]) / k**2\n            agreement_ij = np.sum(np.minimum(testData[i], testData[j]))\n            total_items += weight_ij\n            overall_agreement += weight_ij * (agreement_ij - expected_ij)\n            agreement_expected += weight_ij * expected_ij\n    return (overall_agreement - agreement_expected) / (1 - agreement_expected)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Compute the weighted Cohen's kappa metric for a matrix 'testData' of dimension k using the 'w' matrix for weights. The result should be a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    p0 = np.sum(np.sum(testData*w, axis=1))/np.sum(np.sum(w, axis=1))\n    p1 = np.sum(testData*w) / np.sum(w)\n    \n    n0 = np.sum(np.sum(testData, axis=1))\n    n1 = np.sum(testData)\n\n    num = (p1-p0)\n    den = (n1*1.0 - n0*1.0)\n    \n    den = den*(den-n)\n    \n    return num / den",
                false
            ],
            [
                null,
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Evaluate the weighted Cohen's kappa score for a k-dimensional matrix named 'testData', utilizing the weight matrix 'w', and return the resulting float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    assert len(testData) == len(w), \"testData and w must have the same length\"\n    assert all(len(row) == k for row in testData), \"All rows in testData must have k elements\"\n    assert all(len(row) == k for row in w), \"All rows in w must have k elements\"\n\n    n = len(testData)\n    p_e = np.sum(np.multiply(testData, w)) / n\n    p_o = np.sum([np.sum(testData * w) for testData in testData]) / (n * n)\n    kappa = (p_o - p_e) / (1 - p_e)\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Evaluate the weighted Cohen's kappa score for a k-dimensional matrix named 'testData', utilizing the weight matrix 'w', and return the resulting float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    n = len(testData)\n    Pw = np.sum(w)\n    Pbar = np.sum(testData) / (n * k)\n    Pwbar = np.sum(np.multiply(testData, w)) / (n * k)\n    P = np.zeros(k)\n    Pw = np.zeros(k)\n    for i in range(k):\n        P[i] = np.sum(testData[:, i]) / (n * k)\n        Pw[i] = np.sum(np.multiply(testData[:, i], w)) / (n * k)\n    PbarW = np.sum(Pw) / k\n    numerator = PbarW - Pbar\n    denominator = 1 - PbarW\n    kappa = numerator / denominator if denominator != 0 else 0\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    overall_agreement = 0.0\n    agreement_expected = 0.0\n    total_items = 0.0\n    n = len(testData)\n\n    for i in range(k):\n        class_total = np.sum(w[i])\n        total_items += class_total\n\n        pi = np.sum(testData[i]) / n\n        weight_pi = np.sum(w[i] * testData[i]) / n\n\n        overall_agreement += class_total * pi ** 2\n        agreement_expected += class_total * weight_pi ** 2\n\n    kappa = (overall_agreement - agreement_expected) / (1 - agreement_expected)\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    n = len(testData)\n    N = np.sum(testData)\n    sum_probs = np.sum(np.sum(testData * w, axis=1))\n    sum_expected = sum_probs ** 2\n    P0 = sum_expected / N\n    P1 = np.sum((np.sum(testData * w, axis=0) / N) ** 2)\n    K = (P1 - P0) / (1 - P0)\n    return K",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    p0 = np.sum(w, axis=1)  # sum of weights per row\n    p0 = np.multiply(p0.reshape(1,-1), p0.reshape(-1,1))  # square of sum of weights per row\n    p0 = np.sum(p0)  # sum of weighted histograms of categories\n    p0 = p0 / np.sum(w)  # compute overall weighted observed agreement probability\n    pe = np.sum(testData * w) / np.sum(w)  # compute expected agreement probability\n\n    if pe != 0 and p0 != 0:\n        kappa = (p0 - pe) / (1 - pe)\n    else:\n        kappa = None\n        \n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Determine the weighted Cohen's kappa value from a k-dimensional 'testData' matrix applying weights from matrix 'w'. Ensure the output is a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    assert testData.shape == (k, k), \"testData should be a k x k matrix\"\n    assert w.shape == (k, k), \"w should be a k x k matrix\"\n\n    # Calculate overall agreement\n    total_sum = 0\n    for i in range(k):\n        total_sum += np.sum(testData[i, :])\n    p_bar = total_sum / (k * k)\n\n    # Calculate weighted agreement\n    weighted_sum = 0\n    for i in range(k):\n        for j in range(k):\n            weighted_sum += w[i, j] * testData[i, j]\n    p_hat = weighted_sum / (k * k)\n\n    # Calculate kappa\n    kappa = (p_hat - p_bar) / (1 - p_bar)\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Determine the weighted Cohen's kappa value from a k-dimensional 'testData' matrix applying weights from matrix 'w'. Ensure the output is a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    N = len(testData)\n    Pw = np.sum(w)\n    Pbar = np.sum(testData) / (N * k)\n    Pwbar = np.sum(np.multiply(testData, w)) / (N * k)\n    P = np.zeros(k)\n    Pw = np.zeros(k)\n    for i in range(k):\n        P[i] = np.sum(testData[:, i]) / N\n        Pw[i] = np.sum(np.multiply(testData[:, i], w)) / N\n    exp = np.sum(np.multiply(P, Pw))\n    Pbarwbar = np.multiply(Pbar, Pwbar)\n    return (exp - Pbarwbar) / (1 - Pbarwbar)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    overall_agreement = 0.0\n    agreement_weighted = 0.0\n    total_weight = np.sum(w)\n    for i in range(k):\n        temp_sum = np.sum(testData[i])\n        overall_agreement += (temp_sum/n)**2\n        agreement_weighted += (temp_sum/n)**2 * w[i]\n    overall_agreement = overall_agreement - (n**2)/(n**2 - 1)\n    agreement_weighted = agreement_weighted - (n**2)/(n**2 - 1)\n    kappa = 1.0 - (agreement_weighted / overall_agreement)\n    \n    return float(kappa)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    n = len(testData)\n    N = np.sum(testData)\n    sum_probs = np.sum(np.sum(testData * w, axis=1))\n    sum_w = np.sum(w)\n    sum_weighted_probs = np.sum(np.sum(testData * w * w, axis=1))\n\n    p0 = sum_probs / sum_w\n    po = (sum_weighted_probs - np.sum(np.sum(testData * w, axis=1)) * p0) / (N - n * p0)\n\n    p_e = np.sum(np.sum(testData * w, axis=1) * p0)\n    kappa = (po - p0) / (1 - p0)\n    \n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    p0 = np.sum(w, axis=1) / np.sum(w)\n    p0 = np.repeat(p0, k).reshape(len(testData), -1)\n\n    p1 = np.sum(testData * w, axis=1) / np.sum(w)\n    p1 = np.repeat(p1, k).reshape(len(testData), -1)\n\n    p0_hat = np.sum(p0) / (len(testData) * k)\n    p1_hat = np.sum(p1) / (len(testData) * k)\n\n    kappa = (p1_hat - p0_hat) / (1 - p0_hat)\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    For a given k-dimensional matrix 'testData', compute the Cohen's kappa value using weighting provided by matrix 'w', and return the resultant float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    assert testData.shape == w.shape, \"Matrix dimensions do not match\"\n    n = np.sum(w, axis=1)  # sample size\n    assert np.all(n > 0), \"Sample size must be greater than 0\"\n    W = w / n[:, None]  # normalized weights\n\n    p_e = np.sum(W * testData, axis=1)  # expected agreement under random agreement\n    P = (np.sum(W * testData ** 2, axis=1) - n) / (n * (n - 1))  # observed agreement\n\n    # compute Cohen's kappa\n    kappa = (P - p_e).mean() / (1 - p_e.mean())\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    For a given k-dimensional matrix 'testData', compute the Cohen's kappa value using weighting provided by matrix 'w', and return the resultant float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    n = len(testData)\n    Pw = np.sum(w)\n    Pbar = np.sum(testData) / (n * k)\n    Pwbar = np.sum(np.multiply(testData, w)) / (n * k)\n    P = np.zeros(k)\n    Pw = np.zeros(k)\n    for i in range(k):\n        P[i] = np.sum(testData[:, i]) / (n * k)\n        Pw[i] = np.sum(np.multiply(testData[:, i], w)) / (n * k)\n    PbarW = np.sum(Pw) / k\n    numerator = PbarW - Pbar\n    denominator = PbarW - np.sum(np.power(Pw, 2)) / k\n    return 1 - (numerator / denominator)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    overall_agreement = 0.0\n    agreement_weighted = 0.0\n    total_weight = 0.0\n\n    for i in range(k):\n        agreement = 0.0\n        weight = 0.0\n        for j in range(k):\n            agreement += w[i][j] * testData[i][j] * (testData[i][j] - 1)\n            weight += w[i][j] * testData[i][j]\n\n        overall_agreement += weight * (weight - 1)\n        agreement_weighted += agreement\n        total_weight += weight * weight\n\n    if overall_agreement == 0.0 or agreement_weighted == 0.0:\n        return 0.0\n\n    return (agreement_weighted / overall_agreement - 1) / (1 - total_weight / np.sum(np.square(np.sum(testData, axis=1))) / k)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    n = len(testData)\n    N = np.sum(testData)\n    sum_probs = np.sum(np.sum(testData * w, axis=1))\n    sum_w = np.sum(w)\n    sum_weighted_probs = np.sum(np.sum(testData * w * w, axis=1))\n\n    p0 = sum_probs / sum_w\n    po = (sum_probs / sum_w) ** 2\n    p_e = po + (1.0 - po) / (n - 1) * np.sum((np.sum(testData * w, axis=1) / sum_w) ** 2)\n    kappa = (p0 - p_e) / (1.0 - p_e)\n    \n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Assess the Cohen's kappa measurement weighted by matrix 'w' for a matrix 'testData' of k-dimensions, returning the evaluation as a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Extract dimensions from original matrix and weight matrix\n    n, m = testData.shape[0], w.shape[0]\n\n    # Calculate the weighted observed agreement matrix\n    observed_matrix = np.zeros((k, k))\n    for i in range(k):\n        for j in range(k):\n            observed_matrix[i, j] = np.sum(testData[testData[:, 0] == i, 1] == j) * w[i, j]\n\n    # Calculate the weighted observed agreement\n    numerator = np.sum(np.sum(observed_matrix)) - np.sum(np.sum(w * observed_matrix))\n    denominator = np.sum(np.sum(w * testData[:, 1].reshape((n, 1)) == testData[:, 0].reshape((n, 1))))\n    observed_kappa = numerator / denominator\n\n    # Calculate weighted chance agreement\n    weight_sum = np.sum(w)\n    chance_agreement = weight_sum * np.sum(w * testData[:, 1].reshape((n, 1)) == testData[:, 0].reshape((n, 1))) / (n * weight_sum)\n\n    # Calculate the weighted kappa coefficient\n    weighted_kappa = (observed_kappa - chance_agreement) / (1 - chance_agreement)\n\n    return weighted_kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Assess the Cohen's kappa measurement weighted by matrix 'w' for a matrix 'testData' of k-dimensions, returning the evaluation as a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    assert testData.shape == (k, k), \"testData should be a k x k matrix\"\n    assert w.shape == (k, k), \"w should be a k x k matrix\"\n\n    # Calculate the total sum of weights\n    total_sum_of_weights = np.sum(w)\n    # Calculate the sum of squares of the weights\n    sum_of_squares_weights = np.sum(np.square(w))\n    # Calculate the sum of squares of the weights minus the total sum of weights\n    sum_of_squares_weights_minus_total_sum_of_weights = np.sum(np.square(w)) - total_sum_of_weights\n    # Calculate the sum of the products of testData and weights\n    sum_of_product_of_testData_and_weights = np.sum(testData*w)\n    # Calculate the product of the sum of weights and the sum of squares of weights\n    product_of_sum_of_weights_and_sum_of_squares_weights = total_sum_of_weights * sum_of_squares_weights\n\n    # Calculate the weighted kappa value\n    weighted_kappa_value = ((sum_of_product_of_testData_and_weights - product_of_sum_of_weights_and_sum_of_squares_weights) / \n                            (1 - sum_of_squares_weights_minus_total_sum_of_weights))\n\n    return weighted_kappa_value",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Assess the Cohen's kappa measurement weighted by matrix 'w' for a matrix 'testData' of k-dimensions, returning the evaluation as a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    N = len(testData)\n    Pw = [0] * (k+1)\n    Py = [0] * (k+1)\n    Pwe = [0] * (k+1)\n    Pe = 0\n\n    # Calculate Pw, Py, Pwe, Pe\n    for i in range(N):\n        for j in range(k):\n            Pw[testData[i][j]] += w[i][j]\n            Py[testData[i][j]] += 1\n            Pwe[testData[i][j]] += w[i][j] * testData[i][j]\n        Pe += sum(testData[i]) * sum(w[i]) / (N * N)\n    Py = [i / (N * k) for i in Py]\n    Pwe = [i / (N * k) for i in Pwe]\n    Pe /= (N * k)\n\n    # Calculate kappa\n    kappa = 0\n    for i in range(k+1):\n        kappa += w[i] * (Pwe[i] - Py[i] * Pw[i])\n    kappa = (kappa - Pe) / (1 - Pe)\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    overall_agreement = 0.0\n    agreement_expected = 0.0\n    agreement_total = 0.0\n    n = len(testData)\n\n    for i in range(k):\n        class_total = np.sum(w[i])\n        overall_agreement += w[i][i]\n        for j in range(k):\n            agreement_total += w[i][j]\n            agreement_expected += class_total * (w[i][j] / n)\n\n    agreement_expected /= (n * n)\n    overall_agreement /= n\n    kappa = (overall_agreement - agreement_expected) / (1 - agreement_expected)\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    n = len(testData)\n    N = np.sum(testData)\n    sum_probs = np.sum(np.sum(testData * w, axis=1))\n    sum_w = np.sum(w)\n    sum_weighted_probs = np.sum(np.sum(testData * w * w, axis=1))\n\n    p0 = sum_probs / sum_w\n    po = (sum_probs / sum_w) ** 2\n    p_e = po * sum_w\n\n    kappa = (p0 - p_e) / (1 - p_e)\n\n    return kappa",
                false
            ]
        ],
        "level 2": [
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Calculate the weighted Cohen's kappa value of a k-dimensional matrix \"testData\" using the weight matrix \"w\". Return the computed value as a float. Begin by converting the input \"testData\" into a numerical matrix, and similarly convert \"w\" into a numerical matrix of weights. Proceed to compute the sum of elements along each row and each column of the matrix \"testData\", and compute the total sum of all elements. Calculate \"P0\" as the sum of the product of the weight matrix and the data matrix. Calculate \"Pe\", the expected agreement, by multiplying the sum of column sums with the sum of row sums, dividing by the total sum, and then taking the product with the weight matrix. Finally, compute the weighted kappa as one minus the ratio of \"P0\" to \"Pe\".\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Convert testData and w into numpy array\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Check if the shapes of testData and w match\n    if testData.shape != w.shape:\n        raise ValueError(\"Shapes of testData and w do not match!\")\n\n    # Compute the sum of elements along each row and each column of testData\n    row_sum = np.sum(testData, axis=1)\n    col_sum = np.sum(testData, axis=0)\n\n    # Compute the total sum of all elements\n    total_sum = np.sum(testData)\n\n    # Calculate P0\n    P0 = np.sum(w * testData)\n\n    # Calculate Pe\n    Pe = np.sum(row_sum * col_sum / total_sum) * np.sum(w)\n\n    # Compute the weighted kappa\n    kappa = (P0 - Pe) / (total_sum - Pe)\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    # Convert input data from list of lists to numpy array\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Compute row and column sums\n    row_sums = np.sum(testData, axis=1)\n    col_sums = np.sum(testData, axis=0)\n    total_sum = np.sum(row_sums)\n\n    # Compute P0\n    P0 = np.sum(w * testData)\n\n    # Compute Pe\n    Pe = np.sum(np.outer(row_sums, col_sums)) / total_sum\n\n    # Compute weighted kappa\n    weighted_kappa = 1 - (P0 / Pe)\n\n    return weighted_kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Calculate the weighted Cohen's kappa value of a k-dimensional matrix \"testData\" using the weight matrix \"w\". Return the computed value as a float. Begin by converting the input \"testData\" into a numerical matrix, and similarly convert \"w\" into a numerical matrix of weights. Proceed to compute the sum of elements along each row and each column of the matrix \"testData\", and compute the total sum of all elements. Calculate \"P0\" as the sum of the product of the weight matrix and the data matrix. Calculate \"Pe\", the expected agreement, by multiplying the sum of column sums with the sum of row sums, dividing by the total sum, and then taking the product with the weight matrix. Finally, compute the weighted kappa as one minus the ratio of \"P0\" to \"Pe\".\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # convert testData and w to numerical matrix\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # compute sum of elements along each row and each column\n    row_sums = np.sum(testData, axis=1)\n    col_sums = np.sum(testData, axis=0)\n    total_sum = np.sum(row_sums)\n    \n    # compute expected agreement\n    P_e = np.outer(row_sums, col_sums) / total_sum\n    P_e *= np.sum(w)\n\n    # compute observed agreement\n    P_0 = np.sum(testData * w)\n    \n    # compute weighted kappa\n    kappa = 1 - P_0/P_e\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    # Convert input into numerical matrices\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Compute sum of elements along each row and column of testData\n    row_sums = np.sum(testData, axis=1)\n    col_sums = np.sum(testData, axis=0)\n\n    # Compute total sum of all elements in testData\n    total_sum = np.sum(row_sums)\n  \n    # Calculate P0\n    P0 = np.sum(w * testData)\n\n    # Calculate Pe\n    Pe = np.sum(row_sums * col_sums) / total_sum\n    \n    # Compute the weighted kappa\n    kappa = 1 - (P0 / Pe)\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    npData = np.array(testData)\n    npW = np.array(w)\n\n    rowSum = np.sum(npData, axis=1)\n    colSum = np.sum(npData, axis=0)\n    totalSum = np.sum(rowSum)\n    \n    P0 = np.sum(np.multiply(npW, npData))\n    Pe = np.sum(np.multiply(rowSum, colSum)) / totalSum\n    Pe *= np.sum(npW)\n\n    kappa = 1 - (P0 / Pe)\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    For a k-dimensional matrix 'testData' and a weight matrix 'w', compute the weighted Cohen's kappa value. Initially, transform 'test__Data' into a numerical matrix, and convert 'w' into a weight matrix. Calculate the total sum of elements, as well as the sums along each row and column in 'testData'. Establish 'P0' by summing the weighted product of 'testData' and 'w', and compute 'Pe', the expected agreement, via the product of the weighted sum of row sums and column sums divided by the total matrix sum. Return the weighted kappa as one minus the ratio of 'P0' to 'Pe'.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    k = len(testData)\n    n = len(testData[0])\n    w_matrix = np.array(w)\n    test_matrix = np.array(testData)\n    total_weight = np.sum(w_matrix)\n    total_test = np.sum(test_matrix)\n    row_sums = np.sum(test_matrix, axis=1)\n    column_sums = np.sum(test_matrix, axis=0)\n\n    weighted_matrix = test_matrix * w_matrix\n    weighted_sum = np.sum(weighted_matrix)\n\n    w_row_sums = np.sum(row_sums * w_matrix, axis=1)\n    w_column_sums = np.sum(column_sums * w_matrix, axis=0)\n\n    p0 = weighted_sum / total_weight\n    pe = np.sum(w_row_sums) * np.sum(w_column_sums) / total_weight**2\n\n    return 1 - p0 / pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    # Convert testData from list of lists to numpy array\n    testData = np.array(testData)\n    # Convert w from list of lists to numpy array\n    w = np.array(w)\n    # Compute the total sum of elements in testData\n    total_sum = np.sum(testData)\n    # Compute the sums along each row and column in testData\n    row_sums = np.sum(testData, axis=1)\n    col_sums = np.sum(testData, axis=0)\n    # Establish P0 by summing the weighted product of testData and w\n    P0 = np.sum(testData * w)\n    # Compute Pe, the expected agreement, via the product of the weighted sum of row sums and column sums divided by the total matrix sum\n    Pe = np.sum(row_sums * w) * np.sum(col_sums * w) / total_sum\n    # Return the weighted kappa as one minus the ratio of P0 to Pe\n    return 1 - P0 / Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    For a k-dimensional matrix 'testData' and a weight matrix 'w', compute the weighted Cohen's kappa value. Initially, transform 'testData' into a numerical matrix, and convert 'w' into a weight matrix. Calculate the total sum of elements, as well as the sums along each row and column in 'testData'. Establish 'P0' by summing the weighted product of 'testData' and 'w', and compute 'Pe', the expected agreement, via the product of the weighted sum of row sums and column sums divided by the total matrix sum. Return the weighted kappa as one minus the ratio of 'P0' to 'Pe'.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    testData = np.array(testData, dtype = float)\n    w = np.array(w, dtype = float)\n    total_sum = np.sum(w)\n    row_sums = np.sum(testData, axis = 1)\n    column_sums = np.sum(testData, axis = 0)\n    P0 = np.sum(w*testData)\n    Pe = np.sum(w*np.outer(row_sums, column_sums))/total_sum\n    kappa = (P0 - Pe)/(1 - Pe)\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    # transform 'testData' into a numerical matrix\n    testData = np.array(testData)\n    # transform 'w' into a weight matrix\n    w = np.array(w)\n    # Calculate the total sum of elements in 'testData'\n    total_sum = np.sum(testData * w)\n    # Calculate the sums along each row\n    row_sums = np.sum(testData * w, axis=1, keepdims=True)\n    # Calculate the sums along each column\n    col_sums = np.sum(testData * w, axis=0, keepdims=True)\n    # Establish 'P0' by summing the weighted product of 'testData' and 'w'\n    P0 = np.sum(testData * w)\n    # Compute 'Pe', the expected agreement via the product of the weighted sum of row sums and column sums divided by the total matrix sum\n    Pe = np.dot(np.dot(row_sums, w), col_sums) / total_sum\n    # Return the weighted kappa as one minus the ratio of 'P0' to 'Pe'\n    return 1 - (P0 / Pe)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    For a k-dimensional matrix 'testData' and a weight matrix 'w', compute the weighted Cohen's kappa value. Initially, transform 'testData' into a numerical matrix, and convert 'w' into a weight matrix. Calculate the total sum of elements, as well as the sums along each row and column in 'testData'. Establish 'P0' by summing the weighted product of 'testData' and 'w', and compute 'Pe', the expected agreement, via the product of the weighted sum of row sums and column sums divided by the total matrix sum. Return the weighted kappa as one minus the ratio of 'P0' to 'Pe'.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Convert testData and w into numpy arrays.\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Calculate total sum, row sums, and column sums.\n    total_sum = np.sum(w * testData)\n    row_sums = np.sum(w * testData, axis=1)\n    col_sums = np.sum(w * testData, axis=0)\n\n    # Compute P0 and Pe.\n    P0 = np.sum(w * np.outer(row_sums, col_sums))\n    Pe = np.sum(row_sums * col_sums / total_sum)\n\n    # Calculate weighted kappa.\n    weighted_kappa = 1 - P0 / Pe\n    return weighted_kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Utilize a k-dimensional matrix 'testData' and a weight matrix 'w' to derive the weighted Cohen's kappa statistic. Begin by transitioning 'testData' to a numerical array structure and similarly for 'w'. Sum up the elements across each row and column of 'testData', alongside the complete sum of all elements. Evaluate 'P0' as the consolidated product of 'testData' and weight matrix 'w'. For 'Pe', the expected agreement, calculate the matrix product of weighted row and column sum totals divided by the global sum, and finally, deliver the weighted kappa by subtracting the 'P0/Pe' ratio from one.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Transform testData and w into numpy arrays\n    testData = np.array(testData)\n    w = np.array(w)\n    \n    # Calculate the sum of all elements in testData and w\n    global_sum = testData.sum()\n    w_sum = w.sum()\n\n    # Calculate the sum of elements across each row and column of testData\n    row_sums = testData.sum(axis=1)\n    column_sums = testData.sum(axis=0)\n\n    # Calculate P0 as the product of testData and w\n    P0 = np.multiply(testData, w).sum()\n\n    # Calculate Pe as the matrix product of weighted row and column sum totals\n    Pe = np.outer(row_sums, column_sums) * w_sum / global_sum\n\n    # Calculate the weighted kappa by subtracting the 'P0/Pe' ratio from one\n    weighted_kappa = (P0 - Pe) / (global_sum - Pe)\n\n    return weighted_kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Sum of total ratings per item\n    r_row = np.sum(testData, axis=0)\n    # Sum of total ratings per annotator\n    r_col = np.sum(testData, axis=1)\n    total_ratings = np.sum(r_row)\n\n    # Weighted matrix\n    w_matrix = testData * w\n    # Sum of weighted ratings per item\n    wr_row = np.sum(w_matrix, axis=0)\n    # Sum of weighted ratings per annotator\n    wr_col = np.sum(w_matrix, axis=1)\n    # Sum of weighted total ratings\n    total_weighted_ratings = np.sum(wr_row)\n\n    # Expected agreement\n    P_e = np.outer(r_row, r_col) / total_ratings\n    # Weighted expected agreement\n    P_w_e = np.outer(wr_row, wr_col) / total_weighted_ratings\n\n    # Weighted kappa\n    kappa = (np.sum(w_matrix * P_e) - np.sum(P_w_e)) / (1 - np.sum(P_w_e))\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Utilize a k-dimensional matrix 'testData' and a weight matrix 'w' to derive the weighted Cohen's kappa statistic. Begin by transitioning 'testData' to a numerical array structure and similarly for 'w'. Sum up the elements across each row and column of 'testData', alongside the complete sum of all elements. Evaluate 'P0' as the consolidated product of 'testData' and weight matrix 'w'. For 'Pe', the expected agreement, calculate the matrix product of weighted row and column sum totals divided by the global sum, and finally, deliver the weighted kappa by subtracting the 'P0/Pe' ratio from one.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Transform the testData and weight matrices to numpy arrays\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Calculate the sum of each row, column, and the total sum\n    sum_row = np.sum(testData, axis=0)\n    sum_col = np.sum(testData, axis=1)\n    total_sum = np.sum(testData)\n\n    # Calculate P0\n    P0 = np.sum(testData * w)\n\n    # Calculate Pe\n    Pe = np.sum(sum_row * sum_col) / total_sum\n\n    # Calculate kappa\n    kappa = (P0 - Pe) / (1 - Pe)\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    # Transform the input to numpy arrays.\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Calculate the totals for each row and column.\n    row_sum = np.sum(testData, axis=1)\n    column_sum = np.sum(testData, axis=0)\n    global_sum = np.sum(testData)\n\n    # Calculate the expected agreement (Pe).\n    Pe = np.dot(row_sum.reshape(-1, 1), column_sum.reshape(1, -1)) / global_sum\n\n    # Calculate the agreement (P0).\n    P0 = np.sum(np.multiply(testData, w))\n\n    # Calculate the weighted kappa.\n    weighted_kappa = (P0 - Pe) / (1 - Pe)\n\n    return weighted_kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    npData = np.array(testData)\n    npW = np.array(w)\n\n    row_sum = npData.sum(axis=1)\n    col_sum = npData.sum(axis=0)\n    global_sum = npData.sum()\n\n    P0 = np.dot(npData, npW)\n\n    P_e = np.outer(row_sum, col_sum) / global_sum\n\n    kappa = (P0 - P_e) / (1 - P_e)\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    To determine the weighted Cohen's kappa value from a k-dimensional matrix 'testData' with a weight matrix 'w', start by converting both 'testData' and 'w' into numerical matrices. Next, compute the sum of elements for each row, each column, and the matrix as a whole in 'testData'. Compute 'P0' as the sum of the weight matrix multiplied by the data matrix, and 'Pe', the expected agreement, from multiplying the sum of column sums by the sum of row sums, divided by the sum of all matrix elements, all weighted by 'w'. The final weighted kappa is calculated as one minus the ratio of 'P0' to 'Pe'.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Calculate all sum of elements for each row, each column and the matrix as a whole\n    row_sums = np.sum(testData, axis=1)\n    col_sums = np.sum(testData, axis=0)\n    row_col_sum = np.sum(row_sums)\n    \n    w_row_sums = np.sum(w, axis=1)\n    w_col_sums = np.sum(w, axis=0)\n    w_row_col_sum = np.sum(w_row_sums)\n    \n    matrix_sum = np.sum(testData)\n    \n    # Weighted observed agreement P0\n    P0 = np.sum(testData * w)\n    \n    # Weighted expected agreement Pe\n    Pe = np.sum(w_row_sums * w_col_sums / w_row_col_sum)\n    \n    # Weighted Kappa\n    weighted_kappa = 1.0 - P0 / Pe\n    \n    return weighted_kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    # Convert all data from list of lists to numpy arrays\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Compute row sums, column sums and total sum for both testData and weight matrix\n    testData_row_sums = testData.sum(axis=1)\n    testData_col_sums = testData.sum(axis=0)\n    w_row_sums = w.sum(axis=1)\n    w_col_sums = w.sum(axis=0)\n    testData_total_sum = testData.sum()\n\n    # Calculate P0\n    P0 = np.tensordot(w, testData)\n\n    # Calculate Pe\n    Pe = np.tensordot(w_row_sums / testData_row_sums, testData_col_sums / w_col_sums)\n\n    # Calculate the weighted kappa\n    kappa = 1 - P0 / Pe\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    To determine the weighted Cohen's kappa value from a k-dimensional matrix 'testData' with a weight matrix 'w', start by converting both 'testData' and 'w' into numerical matrices. Next, compute the sum of elements for each row, each column, and the matrix as a whole in 'testData'. Compute 'P0' as the sum of the weight matrix multiplied by the data matrix, and 'Pe', the expected agreement, from multiplying the sum of column sums by the sum of row sums, divided by the sum of all matrix elements, all weighted by 'w'. The final weighted kappa is calculated as one minus the ratio of 'P0' to 'Pe'.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    testData = np.array(testData)\n    w = np.array(w)\n\n    testData_sum = np.sum(testData)  # sum of all elements in testData\n    testData_sum_col = np.sum(testData, axis=0)  # sum of each column in testData\n    testData_sum_row = np.sum(testData, axis=1)  # sum of each row in testData\n\n    P0 = np.sum(w * testData)  # sum of weight matrix multiplied by the data matrix\n\n    Pe = np.sum(w * testData_sum_row) * np.sum(w * testData_sum_col) / (testData_sum * testData_sum) # expected agreement \n\n    kappa = (P0 - Pe) / (1 - Pe) # weighted kappa value\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    # Convert 'testData' and 'w' into numerical matrices.\n    testData = np.array(testData)\n    w = np.array(w)\n    \n    # Compute sums of elements for each row, each column, and the matrix as a whole.\n    col_sums = np.sum(testData, axis=0)\n    row_sums = np.sum(testData, axis=1)\n    total_sum = np.sum(testData)\n    \n    # Compute 'P0' as the sum of the weight matrix multiplied by the data matrix.\n    P0 = np.sum(w * testData)\n    \n    # Compute 'Pe', the expected agreement.\n    Pe = np.sum(col_sums * row_sums) / (total_sum * (k - 1))\n    \n    # The final weighted kappa is calculated as one minus the ratio of 'P0' to 'Pe'.\n    return 1 - (P0 / Pe)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    npData = np.array(testData)\n    npW = np.array(w)\n\n    P0 = (npData * npW).sum()\n    Pe = ((np.sum(npData, 0) * np.sum(npData, 1)) / npData.size).sum()\n\n    return 1 - P0 / Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Obtain the weighted Cohen's kappa statistic from a k-dimensional 'testData' matrix and a weigh matrix 'w' by initially converting 'testData' and 'w' respectively into their numerical matrix forms. Accumulate the sum of elements across the rows and columns of 'testData', and the general matrix sum. Calculate 'P0' by tallying up the multiplicative results of 'testData' and the weight matrix. Then develop 'Pe', expected agreement, by taking the product of the weighted sums of column sums and row sums, normalized by the total elements' sum. Conclude with computing the weighted kappa as one deducted by the 'P0/Pe' quotient.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Convert the input to numpy arrays\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Check if the dimensions of the input matrices match\n    assert testData.shape == w.shape, \"testData and w do not have the same shape.\"\n    \n    # Calculate the sum of elements across the rows and columns of 'testData'\n    rowSums = testData.sum(axis=1)\n    colSums = testData.sum(axis=0)\n    \n    # Calculate the sum of general matrix elements\n    totalElements = testData.sum()\n    \n    # Accumulate the sum of elements across the rows and columns of 'testData'\n    sumSquares = (rowSums * colSums).sum()\n    \n    # Tally up the multiplicative results of 'testData' and the weight matrix\n    P0 = (testData * w).sum()\n    \n    # Calculate Pe\n    Pe = sumSquares / totalElements\n    \n    # Calculate weighted kappa value\n    kappa = (P0 - Pe) / (1 - Pe)\n    \n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    testDataMat = np.array(testData)\n    wMat = np.array(w)\n\n    # Compute the sum of row and column sums of the testData matrix\n    rowSum = np.sum(testDataMat, axis=1)\n    colSum = np.sum(testDataMat, axis=0)\n\n    # Compute the sum of the elements of the testData matrix\n    totalSum = np.sum(testDataMat)\n\n    # Compute the weighted sum of elements across the rows and columns of 'testData', and the general matrix sum\n    weightedTestDataSum = np.sum(testDataMat * wMat)\n\n    # Compute the sum of 'testData' multiplied by the weight matrix\n    weightedSum = np.sum(testDataMat * wMat)\n\n    # Compute the expected agreement\n    expectedAgreement = np.sum(rowSum*colSum / totalSum)\n\n    # Compute the weighted kappa\n    weightedKappa = ((weightedTestDataSum - expectedAgreement) /\n                     (totalSum - expectedAgreement))\n\n    return weightedKappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Obtain the weighted Cohen's kappa statistic from a k-dimensional 'testData' matrix and a weigh matrix 'w' by initially converting 'testData' and 'w' respectively into their numerical matrix forms. Accumulate the sum of elements across the rows and columns of 'testData', and the general matrix sum. Calculate 'P0' by tallying up the multiplicative results of 'testData' and the weight matrix. Then develop 'Pe', expected agreement, by taking the product of the weighted sums of column sums and row sums, normalized by the total elements' sum. Conclude with computing the weighted kappa as one deducted by the 'P0/Pe' quotient.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Convert the data to numpy arrays\n    data = np.array(testData)\n    weights = np.array(w)\n    \n    # Calculate P0\n    P0 = np.sum(data*weights)\n    \n    # Calculate Pe\n    sum_data = np.sum(data)\n    sum_weights = np.sum(weights)\n    Pe = sum_weights*sum_data / (k*k)\n    \n    # Calculate weighted kappa\n    kappa = (P0 - Pe) / (1 - Pe)\n    \n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    # Convert 'testData' and 'w' to numerical matrix forms\n    testData = np.array(testData)\n    w = np.array(w)\n    \n    # Calculate sums of elements across rows and columns of 'testData'\n    row_sums = np.sum(testData, axis=1)\n    col_sums = np.sum(testData, axis=0)\n    \n    # Calculate the total elements' sum\n    total_sum = np.sum(testData)\n    \n    # Create empty array for weighted matrix 'P0'\n    P0 = np.empty((k, k))\n    \n    # Compute the weighted 'P0'\n    for i in range(k):\n        for j in range(k):\n            P0[i][j] = w[i][j] * testData[i][j]\n            \n    # Calculate the weighted 'Pe'\n    Pe = np.outer(row_sums * w, col_sums * w) / total_sum\n    \n    # Compute weighted kappa as one minus the 'P0/Pe' quotient\n    weighted_kappa = 1 - np.sum(P0) / np.sum(Pe)\n    \n    return weighted_kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    npData = np.array(testData)\n    npW = np.array(w)\n\n    # Accumulate sum of rows and columns.\n    rowSums = np.sum(npData, axis = 1)\n    colSums = np.sum(npData, axis = 0)\n    totalSum = np.sum(npData)\n    wSums = np.dot(npData, npW)\n\n    # Calculate 'P0'\n    P0 = np.sum(npData * npW)\n    \n    # Calculate 'Pe'\n    Pe = np.dot(np.dot(rowSums, npW), colSums) / totalSum\n    \n    # Calculate kappa\n    kappa = (P0 - Pe)/(1 - Pe)\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Using a k-dimensional 'testData' matrix and weight matrix 'w', extract the weighted Cohen's kappa measure. Change 'testData' and 'w' into their corresponding numerical matrices. Determine the sum of each row and column in 'testData', and the sum of all matrix values. Ascertain 'P0' as the sum resulting from multiplying 'testData' by the weight matrix 'w'. Figure out 'Pe', the expected agreement, by performing a division of the product of column and row sums by the total elements, all scaled by 'w'. Finalize by computing the weighted kappa as one minus the proportion of 'P0' over 'Pe'.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Convert testData and w into numpy arrays\n    testData = np.array(testData)\n    w = np.array(w)\n    # Calculate the sums of each row, column and total elements\n    row_sums = np.sum(testData, axis=1)\n    col_sums = np.sum(testData, axis=0)\n    row_col_sum = np.sum(row_sums)\n    total_elems = np.sum(testData)\n    # Calculate the sum of 'testData' weighted by 'w'\n    P0 = np.sum(testData * w)\n    # Calculate the expected agreement\n    Pe = row_col_sum * (np.sum(w * (row_sums[:, None] * col_sums[None, :])) / total_elems)\n    # Calculate the weighted kappa\n    kappa = 1 - P0 / Pe\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    # Convert testData from list of lists to numpy array\n    testData = np.array(testData)\n    # Convert w from list of lists to numpy array\n    w = np.array(w)\n    # Calculate sum of each row in testData\n    row_sums = testData.sum(axis=1)\n    # Calculate sum of each column in testData\n    col_sums = testData.sum(axis=0)\n    # Calculate sum of all elements in testData\n    total_sum = testData.sum()\n    # Calculate P0 by multiplying testData with w\n    P0 = np.multiply(testData, w).sum()\n    # Calculate Pe\n    Pe = (np.multiply(row_sums, col_sums) * w).sum() / total_sum\n    # Calculate weighted kappa\n    kappa = 1 - (P0 / Pe)\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Using a k-dimensional 'testData' matrix and weight matrix 'w', extract the weighted Cohen's kappa measure. Change 'testData' and 'w' into their corresponding numerical matrices. Determine the sum of each row and column in 'testData', and the sum of all matrix values. Ascertain 'P0' as the sum resulting from multiplying 'testData' by the weight matrix 'w'. Figure out 'Pe', the expected agreement, by performing a division of the product of column and row sums by the total elements, all scaled by 'w'. Finalize by computing the weighted kappa as one minus the proportion of 'P0' over 'Pe'.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Convert testData and w to numpy arrays\n    testData = np.array(testData)\n    w = np.array(w)\n\n    # Calculate the sum of each row and column in testData\n    row_sums = np.sum(testData, axis=1)\n    col_sums = np.sum(testData, axis=0)\n\n    # Calculate the total sum of all matrix values\n    total_sum = np.sum(testData)\n\n    # Calculate P0, the sum resulting from multiplying testData by the weight matrix w\n    P0 = np.sum(testData * w)\n\n    # Calculate Pe, the expected agreement\n    Pe = np.sum(row_sums * col_sums) / total_sum * w\n\n    # Calculate the weighted kappa\n    weighted_kappa = 1.0 - P0 / Pe\n\n    return weighted_kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    # Convert 'testData' and 'w' into numerical matrices.\n    testData = np.array(testData)\n    w = np.array(w)\n    \n    # Extract sums of each row and column in 'testData'.\n    sumRow = np.sum(testData, axis=1)\n    sumColumn = np.sum(testData, axis=0)\n    \n    # Determine 'P0', the sum resulting from multiplying 'testData' by 'w'. \n    P0 = np.sum(testData * w)\n    \n    # Figure out 'Pe', the expected agreement. \n    Pe = np.sum(sumRow * sumColumn / np.sum(testData) * w)\n    \n    # Calculate 'P0' over 'Pe', and the weighted kappa as one minus this proportion.\n    kappa_weighted = (P0 / Pe) - 1\n\n    return kappa_weighted",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    npData = np.array(testData)\n    npW = np.array(w)\n\n    row_sums = npData.sum(axis=1)\n    col_sums = npData.sum(axis=0)\n    total_sum = npData.sum()\n    P0 = np.sum(npData * npW)\n    Pe = np.sum(col_sums * row_sums / total_sum * npW)\n\n    weighted_kappa = 1 - P0 / Pe\n\n    return weighted_kappa",
                false
            ]
        ],
        "level 3": [
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    weights = np.array(w)\n    \n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    sumMat = np.sum(dataMat)\n    \n    P0 = np.dot(weights, dataMat)\n    Pe = np.dot(ysum.T, xsum) / sumMat\n    Pe = np.dot(weights, Pe)\n    \n    return 1 - P0 / Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    weights = np.array(w)\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    sum = np.sum(dataMat)\n    P0 = np.dot(weights, dataMat)\n    Pe = np.dot(ysum.T, xsum) / sum\n    Pe = np.dot(weights, Pe)\n    kappa = 1 - P0/Pe\n    return float(kappa)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Calculate the weighted Cohen's kappa value of a k-dimensional matrix \"testData\" using the weight matrix \"w\". Return the computed value as a float. Begin by converting the input \"testData\" into a numpy array named \"dataMat\", and similarly convert \"w\" into a numpy array of weights. Compute the sum of elements along each row (\"xsum\") and each column (\"ysum\") of the matrix \"dataMat\", and compute the total sum of all elements in \"dataMat\" (named \"sum\"). Calculate \"P0\" by taking the dot product of the weight matrix \"w\" and \"dataMat\". Calculate \"Pe\", the expected agreement, by taking the dot product of \"ysum\" transposed and \"xsum\", dividing by \"sum\", and then taking the dot product with \"w\". Finally, compute the weighted kappa as \"1 - P0/Pe\".\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Conversion of input data to numpy array\n    dataMat = np.array(testData)\n    wMat = np.array(w)\n\n    # Calculation of the sum of elements along each row and column\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    sum_dataMat = np.sum(dataMat)\n\n    # Calculation of P0\n    P0 = np.dot(wMat, dataMat)\n\n    # Calculation of Pe\n    Pe = np.dot(np.array([ysum]).T, xsum) / sum_dataMat\n\n    # Final computation of weighted kappa\n    kappa_val = 1 - P0 / Pe\n\n    return kappa_val",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    weights = np.array(w)\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    sum_all = np.sum(dataMat)\n    P0 = np.dot(weights, dataMat)\n    Pe = np.dot(ysum.T, xsum) / sum_all\n    Pe = np.dot(weights, Pe)\n    return 1 - P0 / Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    weights = np.array(w)\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    total = np.sum(dataMat)\n    P0 = np.dot(weights, dataMat)\n    Pe = np.dot(weights, np.outer(xsum, ysum)) / total\n    return 1 - P0/Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    weightsMat = np.array(w)\n    xsum = dataMat.sum(1)\n    ysum = dataMat.sum(0)\n    tsum = dataMat.sum()\n    P0 = (dataMat * weightsMat).sum()\n    Pe = (np.dot(ysum, np.dot(weightsMat, xsum)) / tsum)\n    return 1 - P0/Pe",
                true
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Compute the float representation of the weighted Cohen's kappa using a k-dimensional 'testData' and a corresponding weight matrix 'w'. Begin by transforming 'testData' to a numpy array labeled 'dataMat' and 'w' to a numpy weights array. Sum the elements of each row in 'dataMat' to get 'xsum' and each column to obtain 'ysum'. Determine the total of all matrix elements as 'sum'. Compute 'P0' as the dot product of 'dataMat' and 'w'. Further compute 'Pe', or the expected agreement by calculating the dot product of the transposed 'ysum' and 'xsum', dividing by 'sum', then dotting with 'w'. Calculate and return the weighted kappa as '1 - P0/Pe'.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Transform testData to numpy array, and weights to numpy array\n    dataMat = np.array(testData)\n    weights = np.array(w)\n\n    # Get total sum of all matrix elements\n    sum = np.sum(dataMat)\n\n    # Calculate P0, which is the dot product of dataMat and weights\n    P0 = np.dot(dataMat, weights)\n\n    # Calculate the sum of each row in dataMat, and transpose it to ysum\n    xsum = np.sum(dataMat, axis=1)\n    ysum = xsum.reshape(-1, 1)\n\n    # Calculate Pe, which is the dot product of ysum and xsum, then divide by sum, and dot with weights\n    Pe = np.dot((ysum * xsum / sum), weights)\n\n    # Calculate and return the weighted kappa as 1 - P0/Pe\n    return 1 - P0/Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Compute the float representation of the weighted Cohen's kappa using a k-dimensional 'testData' and a corresponding weight matrix 'w'. Begin by transforming 'testData' to a numpy array labeled 'dataMat' and 'w' to a numpy weights array. Sum the elements of each row in 'dataMat' to get 'xsum' and each column to obtain 'ysum'. Determine the total of all matrix elements as 'sum'. Compute 'P0' as the dot product of 'dataMat' and 'w'. Further compute 'Pe', or the expected agreement by calculating the dot product of the transposed 'ysum' and 'xsum', dividing by 'sum', then dotting with 'w'. Calculate and return the weighted kappa as '1 - P0/Pe'.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n\n    # Convert testData and w to numpy arrays\n    dataMat = np.array(testData)\n    weights = np.array(w)\n\n    # Convert testData to a matrix\n    dataMat = np.reshape(dataMat, (1, len(dataMat)))\n\n    # Sum the elements in each row and column\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    \n    # Calculate the total sum of all matrix elements\n    total = np.sum(dataMat)\n\n    # Compute P0\n    P0 = np.dot(dataMat, weights)\n\n    # Compute Pe\n    Pe = np.dot(np.dot(np.reshape(ysum, (k, 1)), np.reshape(xsum, (1, k))), weights)/total\n\n    # Compute and return the weighted kappa\n    weighted_kappa = 1 - P0/Pe\n\n    return weighted_kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    weights = np.array(w)\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    sum_all = np.sum(dataMat)\n    P0 = np.dot(dataMat, weights)\n    Pe = np.dot(np.dot(ysum, xsum), weights) / sum_all\n    return 1 - P0 / Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    weights = np.array(w)\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    total = np.sum(dataMat)\n    P0 = np.dot(dataMat, weights)\n    Pe = np.dot(ysum, xsum / total) * total / (k*k)\n    return 1 - P0/Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    wMat = np.array(w)\n    xsum = dataMat.sum(1)\n    ysum = dataMat.sum(0)\n    sum = dataMat.sum()\n    P0 = np.dot(wMat.sum(1), dataMat)\n    Pe = np.dot(np.dot(ysum, xsum), wMat.sum(1)) / sum\n    return 1 - P0/Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    w = np.array(w)\n    xsum = dataMat.sum(axis=1)\n    ysum = dataMat.sum(axis=0)\n    sum = dataMat.sum()\n    P0 = (w * dataMat).sum()\n    Pe = np.dot(np.dot(np.transpose(ysum), xsum), w).sum() / sum\n    return 1 - P0/Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    For a k-dimensional matrix 'testData' and a weight matrix 'w', calculate the floating-point value of the weighted Cohen's kappa. First, turn 'testData' and 'w' into numpy arrays named 'dataMat' and a numpy weight array subsequently. Obtain 'xsum' as the summation of each row in 'dataMet', 'ysum' being the summation of each column. Accumulate the grand total of 'dataMat' elements as 'sum'. Calculate 'P0' by dotting 'w' with 'dataMat'. 'Pe' or expected agreement is calculated by taking a dot product of 'ysum' transpose with 'xsum', dividing this by 'sum', and then dot product this result with 'w'. Conclude by computing the weighted kappa as '1 - P0/Pe' and return it.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # convert test data and weight matrix to numpy array\n    dataMat = np.array(testData)\n    weights = np.array(w)\n\n    # obtain sum of each row and each column\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n\n    # accumulate grand total of dataMat elements\n    sum = np.sum(dataMat)\n\n    # calculate P0\n    P0 = np.dot(w, dataMat)\n\n    # calculate Pe\n    Pe = np.dot(np.dot(ysum.reshape(-1, 1).T, xsum.reshape(-1, 1)), weights)\n\n    # calculate kappa\n    kappa = 1 - (P0 / Pe)\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    wMat = np.array(w)\n    xsum = np.sum(dataMat, axis=1) \n    ysum = np.sum(dataMat, axis=0)\n    sum = np.sum(dataMat)\n    P0 = np.dot(wMat, dataMat)\n    Pe = np.dot(np.dot(ysum.T, xsum), wMat) / sum\n    kappa = 1 - P0 / Pe\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    weightMat = np.array(w)\n    xsum = np.sum(dataMat, axis=0)\n    ysum = np.sum(dataMat, axis=1)\n    sum = np.sum(dataMat)\n    P0 = np.dot(weightMat, dataMat)\n    Pe = np.dot(np.dot(ysum.T, xsum), sum) / sum\n    kappa = 1 - P0 / Pe\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.mat(testData)\n    weights = np.array(w)\n    \n    xsum = np.sum(dataMat, axis=0)\n    ysum = np.sum(dataMat, axis=1)\n    sumMat = np.sum(dataMat)\n    \n    P0 = np.sum(np.multiply(dataMat, weights))\n    Pe = np.sum(np.multiply(ysum.T, xsum)) / sumMat\n    Pe = np.sum(np.multiply(ysum.T, xsum)) / sumMat\n    \n    kappaVal = (P0 - Pe) / (1 - Pe)\n    \n    return kappaVal",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    weights = np.array(w)\n    xsum = dataMat.sum(axis=1)\n    ysum = dataMat.sum(axis=0)\n    sum = dataMat.sum()\n    P0 = np.dot(weights, dataMat)\n    Pe = np.dot(ysum.T, xsum) / sum\n    return 1 - P0 / Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Find the weighted Cohen's kappa value for a k-dimensional 'testData' matrix with the weight matrix 'w', returned as a float.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # Convert testData and w to numpy arrays\n    dataMat = np.array(testData)\n    weights = np.array(w)\n\n    # Get sums across rows and columns and complete sum\n    xsum = np.sum(dataMat, axis=0)\n    ysum = np.sum(dataMat, axis=1)\n    total_sum = np.sum(dataMat)\n\n    # Compute P0\n    P0 = weights.dot(dataMat)\n\n    # Compute Pe\n    Pe = np.dot(ysum.T, xsum) / total_sum\n\n    # Compute weighted kappa\n    kappa = 1 - P0 / Pe\n\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    weights = np.array(w)\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    sum_all = np.sum(dataMat)\n    P0 = np.dot(weights, dataMat)\n    Pe = np.dot(ysum.T, xsum) / sum_all\n    kappa = 1 - P0 / Pe \n    return float(kappa)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.mat(testData)\n    weights = np.array(w)\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    sumc = np.sum(dataMat)\n    P0 = np.dot(weights, dataMat)\n    Pe = np.dot(ysum.transpose(), xsum) / sumc\n    P0 /= sumc\n    return 1 - P0/Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.mat(testData)\n    weightsMat = np.mat(w)\n    xsum = dataMat.sum(1)\n    ysum = dataMat.sum(0)\n    sum = xsum.sum()\n    P0 = weightsMat * dataMat\n    Pe = ysum.T * xsum / sum\n    return 1 - P0.sum() / Pe.sum()",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    wMat = np.array(w)\n    xsum = np.sum(dataMat, 1)\n    ysum = np.sum(dataMat, 0)\n    total = np.sum(dataMat)\n    P0 = np.dot(wMat, dataMat.T)\n    Pe = np.dot(ysum, xsum) / total\n    P0 = P0.item() if isinstance(P0, np.ndarray) and P0.size == 1 else P0  # get the value from np.array if it is a single number\n    Pe = Pe.item() if isinstance(Pe, np.ndarray) and Pe.size == 1 else Pe  # get the value from np.array if it is a single number\n    kappa = 1 - P0 / Pe\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Determine the weighted Cohen's kappa for a matrix 'testData' of k-dimensions utilizing the weights in matrix 'w', delivering the result as a float. Initially, convert 'testData' into a numpy matrix termed 'dataMat' and 'w' into its corresponding numpy weight matrix. Compute 'xsum' as the sum of all rows and 'ysum' as the sum of all columns in 'dataMat', along with 'sum' as the aggregate of 'dataMat'. Ascertain 'P0' through dot product of 'w' with 'dataMat' and calculate 'Pe' or expected agreement by dot product of transposed 'ysum' and 'xsum', scaled by 'sum', then dot multiplies with 'w'. Yield the weighted kappa computed as '1 - P0/Pe'.\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    dataMat = np.mat(testData)\n    weightMat = np.mat(w)\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    sum_data = np.sum(dataMat)\n    P0 = np.sum(np.multiply(weightMat, dataMat))\n    Pe = np.multiply((1.0/k)*np.sum(np.multiply(weightMat, ysum)), xsum)\n    return 1 - P0/Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.mat(testData)\n    wMat = np.mat(w)\n    xsum = np.sum(dataMat, axis=1) \n    ysum = np.sum(dataMat, axis=0)\n    sum = np.sum(dataMat)\n    P0 = np.dot(wMat, dataMat)\n    Pe = np.dot(np.transpose(ysum), xsum) / sum\n    kappa = 1 - P0.item() / Pe.item()\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.mat(testData)\n    weightMat = np.mat(w)\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n    sum_total = np.sum(dataMat)\n    P0 = dataMat * weightMat\n    Pe = np.sum(xsum*ysum/(sum_total))\n    kappa = 1 - P0 / Pe\n    return float(kappa)",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    wMat = np.array(w)\n    xsum = dataMat.sum(axis=1)\n    ysum = dataMat.sum(axis=0)\n    sum = dataMat.sum()\n    P0 = np.dot(wMat, dataMat)\n    Pe = np.dot(np.dot(ysum.transpose(), xsum), sum)\n    kappa = 1 - P0/Pe\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    w = np.array(w)\n    xsum = dataMat.sum(axis=1)\n    ysum = dataMat.sum(axis=0)\n    sum = dataMat.sum()\n    P0 = np.dot(w, dataMat)\n    Pe = np.dot(np.dot(ysum.T, xsum), sum)\n    return 1 - P0 / Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    \"\"\"\n    Calculate the weighted Cohen\u2019s kappa metric as a float from a k-dimensional 'testData' matrix and a weight matrix 'w'.\n\n    :param testData: The k-dimensional matrix that needs to calculate the cohens kappa value\n    :param k: int, Matrix dimension\n    :param w: The k-dimensional matrix of the weights.\n    :return:float, the weighted cohens kappa value of the matrix\n    \"\"\"\n    # turn testData and w into numpy arrays\n    dataMat = np.array(testData)\n    wMat = np.array(w)\n\n    # calculate xsum and ysum\n    xsum = np.sum(dataMat, axis=1)\n    ysum = np.sum(dataMat, axis=0)\n\n    # calculate sum\n    sumTotal = np.sum(dataMat)\n\n    # calculate P0\n    P0 = np.dot(np.dot(wMat, dataMat), wMat.T)\n\n    # calculate Pe\n    Pe = np.dot(np.dot(ysum.T, xsum), sumTotal)\n\n    # calculate weighted kappa\n    kappa = 1 - P0/Pe\n    return kappa",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    wMat = np.array(w)\n    xsum = np.sum(dataMat, axis=1) \n    ysum = np.sum(dataMat, axis=0)\n    sum = np.sum(dataMat)\n    P0 = np.dot(np.dot(wMat, dataMat.T).T, xsum)\n    Pe = np.dot(ysum, xsum) * sum\n    return 1 - P0/Pe",
                false
            ],
            [
                "def kappa_weighted(testData, k, w):\n    dataMat = np.array(testData)\n    wMat = np.array(w)\n    xsum = np.sum(dataMat, axis=0)\n    ysum = np.sum(dataMat, axis=1)\n    sum_dataMat = np.sum(dataMat)\n    P0 = np.dot(np.dot(wMat, dataMat), ysum.T)\n    Pe = np.dot(np.dot(ysum.T, xsum), sum_dataMat)\n    return 1 - P0/Pe",
                false
            ]
        ]
    },
    "1": {
        "level 1": [
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Calculate the correlation coefficient over the rank of two sets of data \"data1\" and \"data2\". \n    Each data set is a list of values. Return the calculated correlation coefficient as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Step 1: Calculate the rank of data1\n    rank_data1 = [sorted(data1).index(i) for i in data1]\n    # Step 2: Calculate the rank of data2\n    rank_data2 = [sorted(data2).index(i) for i in data2]\n    # Step 3: Calculate the correlation coefficient\n    n = len(data1)\n    sum_rank_data1 = sum(rank_data1)\n    sum_rank_data2 = sum(rank_data2)\n    sum_rank_data1_square = sum([i**2 for i in rank_data1])\n    sum_rank_data2_square = sum([i**2 for i in rank_data2])\n    sum_product_rank = sum([rank_data1[i] * rank_data2[i] for i in range(n)])\n    correlation_coefficient = (n * sum_product_rank - sum_rank_data1 * sum_rank_data2) / \\\n                              math.sqrt((n*sum_rank_data1_square - sum_rank_data1**2) * (n*sum_rank_data2_square - sum_rank_data2**2))\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    from scipy.stats import rankdata\n    from scipy.stats import pearsonr\n    \n    ranked_data1 = rankdata(data1)\n    ranked_data2 = rankdata(data2)\n\n    correlation_coefficient, _ = pearsonr(ranked_data1, ranked_data2)\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Calculate the correlation coefficient over the rank of two sets of data \"data1\" and \"data2\". Each data set is a list of values. Return the calculated correlation coefficient as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Calculate the rank of each set of data\n    rank1 = sorted([(score, i) for i, score in enumerate(data1, 1)], key=lambda x: x[0])\n    rank2 = sorted([(score, i) for i, score in enumerate(data2, 1)], key=lambda x: x[0])\n\n    # Sum the rank differences and square them\n    sum_rank_diff_squared = sum((rank1[i][1] - rank2[i][1]) ** 2 for i in range(len(rank1)))\n\n    # Calculate the correlation coefficient\n    correlation_coefficient = 1 - (6 * sum_rank_diff_squared) / (len(rank1) * (len(rank1) ** 2 - 1))\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Calculate the correlation coefficient over the rank of two sets of data \"data1\" and \"data2\". Each data set is a list of values. Return the calculated correlation coefficient as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Sort the data sets\n    data1_sorted = sorted(data1)\n    data2_sorted = sorted(data2)\n    \n    # Calculate the rank of each data point in the sorted data set\n    rank1 = [data1_sorted.index(x)+1 for x in data1]\n    rank2 = [data2_sorted.index(x)+1 for x in data2]\n    \n    # Calculate the mean of the ranks\n    rank1_mean = sum(rank1)/len(rank1)\n    rank2_mean = sum(rank2)/len(rank2)\n    \n    # Calculate the deviation from the mean\n    rank1_deviation = [r-rank1_mean for r in rank1]\n    rank2_deviation = [r-rank2_mean for r in rank2]\n    \n    # Calculate the variance\n    rank1_variance = sum([r**2 for r in rank1_deviation])/len(rank1_deviation)\n    rank2_variance = sum([r**2 for r in rank2_deviation])/len(rank2_deviation)\n    \n    # Calculate the covariance\n    covariance = sum([r1*r2 for r1,r2 in zip(rank1_deviation, rank2_deviation)])/(len(rank1_deviation)-1)\n    \n    # Calculate the standard deviation\n    rank1_std_dev = math.sqrt(rank1_variance)\n    rank2_std_dev = math.sqrt(rank2_variance)\n    \n    # Calculate the correlation coefficient\n    correlation = covariance / (rank1_std_dev * rank2_std_dev)\n    \n    return correlation",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Calculate the rank of each data point in both lists\n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n    \n    # Calculate the sum of the differences between the ranks\n    diff_sum = sum(abs(a - b) for a, b in zip(rank1, rank2))\n\n    # Calculate the correlation coefficient using the formula\n    corr_coef = 1 - 6.0 * diff_sum / (n * (n**2 - 1))\n\n    return corr_coef",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    rank1 = [sorted(data1).index(i)+1 for i in data1]\n    rank2 = [sorted(data2).index(i)+1 for i in data2]\n    \n    sum_rank_diff_squared = sum([(rank1[i]-rank2[i])**2 for i in range(n)])\n    \n    correlation_coefficient = 1 - (6 * sum_rank_diff_squared) / (n * (n**2 - 1))\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    rank_data1 = [sorted(data1).index(i) for i in data1]\n    rank_data2 = [sorted(data2).index(i) for i in data2]\n    numerator = sum((rank_data1[i] - rank_data2[i])**2 for i in range(n))\n    denominator = n * (n**2 - 1)\n    correlation_coefficient = 1 - ((6*numerator) / denominator)\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Compute the correlation coefficient using ranked values from two datasets, 'data1' and 'data2'. Each dataset contains a list of numerical values. The function should return the result as a floating-point number.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    def rank(data):\n        # sort the data and assign ranks\n        data_sorted = sorted(data)\n        ranks = [data_sorted.index(i) for i in data]\n        return ranks\n\n    def covariance(x, y, mx, my):\n        # calculate covariance\n        return sum((x[i] - mx) * (y[i] - my) for i in range(len(x))) / (len(x) - 1)\n\n    def correlation(cov, sx, sy):\n        # calculate correlation\n        return cov / math.sqrt(sx * sy)\n\n    mx = sum(data1) / len(data1)\n    my = sum(data2) / len(data2)\n\n    sx = sum((i - mx) ** 2 for i in data1) / len(data1)\n    sy = sum((i - my) ** 2 for i in data2) / len(data2)\n\n    cov = covariance(rank(data1), rank(data2), mx, my)\n\n    return correlation(cov, sx, sy)",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create rank lists for data1 and data2\n    rank1 = [sorted(data1).index(value) + 1 for value in data1]\n    rank2 = [sorted(data2).index(value) + 1 for value in data2]\n    \n    # Calculate the sum of the products of the ranks\n    sum_products = sum(x*y for x, y in zip(rank1, rank2))\n    \n    # Calculate the sum of the squares of the ranks\n    sum_squares_rank1 = sum(x**2 for x in rank1)\n    sum_squares_rank2 = sum(y**2 for y in rank2)\n    \n    # Calculate the correlation coefficient\n    correlation_coefficient = (n * sum_products - sum(rank1) * sum(rank2)) / math.sqrt((n * sum_squares_rank1 - sum(rank1)**2) * (n * sum_squares_rank2 - sum(rank2)**2))\n    \n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Rank the data\n    ranked_data1 = [sorted(data1).index(x)+1 for x in data1] \n    ranked_data2 = [sorted(data2).index(x)+1 for x in data2] \n\n    # Calculate the sum of differences between the ranks of the pairs\n    diff_sum = sum([(ranked_data1[i] - ranked_data2[i])**2 for i in range(n)])\n\n    # Calculate the correlation coefficient\n    corr_coef = 1 - (6 * diff_sum) / (n * (n**2 - 1))\n    \n    return corr_coef",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Determine the correlation coefficient for two lists of numerical values, 'data1' and 'data2', by first ranking each set of data. Return the resulting coefficient as a type float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n    n = len(data1)\n    \n    # Calculate the sum of rank differences\n    sum_diff_rank = sum([(rank1[i] - rank2[i])**2 for i in range(n)])\n   \n    # Calculate the correlation coefficient\n    return 1 - 6 * sum_diff_rank / (n * (n**2 - 1))",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    from scipy.stats import rankdata\n    from scipy.stats import pearsonr\n    \n    ranked_data1 = rankdata(data1)\n    ranked_data2 = rankdata(data2)\n\n    correlation_coefficient, _ = pearsonr(ranked_data1, ranked_data2)\n\n    return float(correlation_coefficient)",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Determine the correlation coefficient for two lists of numerical values, 'data1' and 'data2', by first ranking each set of data. Return the resulting coefficient as a type float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # First, create a list of tuples where each tuple contains the original index and the corresponding rank\n    data1_rank = [(i, rank) for i, (value, rank) in enumerate(sorted((value, i) for i, value in enumerate(data1)))]\n    data2_rank = [(i, rank) for i, (value, rank) in enumerate(sorted((value, i) for i, value in enumerate(data2)))]\n\n    # Then, sort the list of tuples by the original index\n    data1_rank.sort(key=lambda x: x[0])\n    data2_rank.sort(key=lambda x: x[0])\n\n    # Finally, calculate the correlation coefficient using the rank data\n    n = len(data1)\n    sum_xy = 0\n    sum_x = 0\n    sum_y = 0\n    sum_x_square = 0\n    sum_y_square = 0\n\n    for i in range(n):\n        sum_xy += data1_rank[i][1] * data2_rank[i][1]\n        sum_x += data1_rank[i][1]\n        sum_y += data2_rank[i][1]\n        sum_x_square += data1_rank[i][1] ** 2\n        sum_y_square += data2_rank[i][1] ** 2\n\n    correlation_coefficient = (n * sum_xy - sum_x * sum_y) / math.sqrt((n * sum_x_square - sum_x ** 2) * (n * sum_y_square - sum_y ** 2))\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Determine the correlation coefficient for two lists of numerical values, 'data1' and 'data2', by first ranking each set of data. Return the resulting coefficient as a type float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # calculate rank\n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n\n    # calculate n, mean rank\n    n = len(data1)\n    mean_rank1 = sum(rank1) / n\n    mean_rank2 = sum(rank2) / n\n\n    # calculate sum of deviations\n    sum_dev1 = sum((rank - mean_rank1) ** 2 for rank in rank1)\n    sum_dev2 = sum((rank - mean_rank2) ** 2 for rank in rank2)\n\n    # calculate Spearman's rank correlation coefficient\n    rho = 6 * sum((rank1[i] - mean_rank1) * (rank2[i] - mean_rank2) for i in range(n)) / ((n * (n**2 - 1)) * (sum_dev1 + sum_dev2))\n\n    return rho",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Ranking the data\n    rank1 = [sorted(data1).index(x)+1 for x in data1]\n    rank2 = [sorted(data2).index(x)+1 for x in data2]\n\n    # Calculating the covariance\n    covar = sum((rank1[i] - sum(rank1) / n) * (rank2[i] - sum(rank2) / n) for i in range(n))\n\n    # Calculating the standard deviation\n    std_dev1 = math.sqrt(sum((rank1[i] - sum(rank1) / n) ** 2 for i in range(n)) / n)\n    std_dev2 = math.sqrt(sum((rank2[i] - sum(rank2) / n) ** 2 for i in range(n)) / n)\n\n    # Calculating the correlation coefficient\n    corr_coeff = covar / (std_dev1 * std_dev2)\n\n    return corr_coeff",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    rank1 = [sorted(data1).index(i)+1 for i in data1]\n    rank2 = [sorted(data2).index(i)+1 for i in data2]\n    \n    sum_rank1 = sum(rank1)\n    sum_rank2 = sum(rank2)\n    sum_rank1_sq = sum([r ** 2 for r in rank1])\n    sum_rank2_sq = sum([r ** 2 for r in rank2])\n    prod_rank = sum([r * s for r, s in zip(rank1, rank2)])\n    \n    corr = (n * prod_rank - sum_rank1 * sum_rank2) / (math.sqrt(n*sum_rank1_sq - sum_rank1**2) * math.sqrt(n*sum_rank2_sq - sum_rank2**2))\n    return corr",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    from scipy.stats import rankdata\n    from scipy.stats import pearsonr\n    \n    ranked_data1 = rankdata(data1)\n    ranked_data2 = rankdata(data2)\n\n    correlation_coefficient, _ = pearsonr(ranked_data1, ranked_data2)\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    For two data lists, 'data1' and 'data2', calculate the correlation coefficient of their ranks and output the coefficient as a float value.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Ranking the data\n    rank1 = {x: i for i, x in enumerate(sorted(data1))}\n    rank2 = {x: i for i, x in enumerate(sorted(data2))}\n\n    # Calculate the difference between the ranks\n    diffs = [rank1[x] - rank2[x] for x in data1]\n\n    # Calculate the standard deviation of the differences\n    std_dev = math.sqrt(sum(d**2 for d in diffs) / len(data1))\n\n    # Calculate the correlation coefficient\n    coefficient = 1 - 6 * sum(d**2 for d in diffs) / (len(data1) * (len(data1)**2 - 1))\n\n    return coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # calculate ranks\n    data1_rank = [sorted(data1).index(x) for x in data1]\n    data2_rank = [sorted(data2).index(x) for x in data2]\n    \n    # calculate the sum of products\n    sum_product = sum([x*y for x, y in zip(data1_rank, data2_rank)])\n    \n    # calculate the sum of squares \n    sum_data1_rank = sum([x**2 for x in data1_rank])\n    sum_data2_rank = sum([x**2 for x in data2_rank])\n    \n    # calculate the Pearson correlation coefficient\n    num = n*sum_product - sum(data1_rank)*sum(data2_rank)\n    denom = math.sqrt((n*sum_data1_rank - sum(data1_rank)**2)*(n*sum_data2_rank - sum(data2_rank)**2))\n    \n    if denom == 0: \n        return 0\n    else:\n        return num/denom",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Calculate the ranks of the data\n    ranks1 = [sorted(data1).index(x) for x in data1]\n    ranks2 = [sorted(data2).index(x) for x in data2]\n\n    # Calculate the differences between each pair of ranks, squared and summed over all pairs\n    diff_squares = sum((r1 - r2) ** 2 for r1, r2 in zip(ranks1, ranks2))\n\n    # Calculate the correlation coefficient\n    correlation = 1.0 - 6.0 * diff_squares / (n * (n ** 2 - 1))\n\n    return correlation",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n\n    d_rank1 = sum([(i-sum(rank1)/n)**2 for i in rank1])\n    d_rank2 = sum([(i-sum(rank2)/n)**2 for i in rank2])\n\n    cov = 0\n    for x1, x2 in zip(rank1, rank2):\n        cov += (x1-sum(rank1)/n) * (x2-sum(rank2)/n)\n\n    return cov / math.sqrt(d_rank1 * d_rank2)",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    from scipy.stats import rankdata\n    from scipy.stats import pearsonr\n    \n    ranked_data1 = rankdata(data1)\n    ranked_data2 = rankdata(data2)\n\n    correlation_coefficient, _ = pearsonr(ranked_data1, ranked_data2)\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Using two sequences of numbers, 'data1' and 'data2', compute the correlation coefficient based on their rankings. The coefficient should be returned as a floating-point number.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    length = len(data1)\n    rank1 = [sorted(data1).index(d) + 1 for d in data1]\n    rank2 = [sorted(data2).index(d) + 1 for d in data2]\n    rank_sum = sum([(rank1[i] - rank2[i])**2 for i in range(length)])\n    denom = length * (length**2 - 1)\n    return 1 - (6 * rank_sum) / denom",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # calculate rank of data1\n    data1_rank = [sorted(data1).index(i) for i in data1]\n    # calculate rank of data2\n    data2_rank = [sorted(data2).index(i) for i in data2]\n    \n    # calculate the sum of products of ranks\n    sum_rank_prod = 0\n    for i in range(n):\n        sum_rank_prod += data1_rank[i] * data2_rank[i]\n        \n    # calculate the sum of ranks\n    sum_rank1 = sum(data1_rank)\n    sum_rank2 = sum(data2_rank)\n    \n    # calculate the sum of squares of ranks\n    sum_rank1_sq = sum([i**2 for i in data1_rank])\n    sum_rank2_sq = sum([i**2 for i in data2_rank])\n    \n    # calculate the correlation coefficient\n    correlation_coefficient = (n*sum_rank_prod - sum_rank1*sum_rank2)/math.sqrt((n*sum_rank1_sq - sum_rank1**2)*(n*sum_rank2_sq - sum_rank2**2))\n    \n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Compute the rank of each data point in both lists\n    rank1 = [sorted(data1).index(x) for x in data1]\n    rank2 = [sorted(data2).index(x) for x in data2]\n    \n    # Compute the sum of the differences between the ranks\n    diff_sum = sum(abs(a - b) for a, b in zip(rank1, rank2))\n\n    # Compute the correlation coefficient\n    r = 1 - 6 * diff_sum / (n * (n**2 - 1))\n\n    return r",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n\n    d1 = [i - (n - 1) / 2 for i in rank1]\n    d2 = [i - (n - 1) / 2 for i in rank2]\n\n    r = 1 - (6 * sum([di * dj for di, dj in zip(d1, d2)]) / (n * (n**2 - 1)))\n\n    return r",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    from scipy.stats import rankdata\n    from scipy.stats import spearmanr\n\n    data1_rank = rankdata(data1)\n    data2_rank = rankdata(data2)\n\n    correlation_coefficient, _ = spearmanr(data1_rank, data2_rank)\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Evaluate the rank correlation coefficient between two series of numeric elements, 'data1' and 'data2', then return this coefficient expressed as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    n = len(data1)\n    sum_of_products = 0\n    sum_of_data1 = 0\n    sum_of_data2 = 0\n    sum_of_squares_data1 = 0\n    sum_of_squares_data2 = 0\n\n    for data1_val, data2_val in zip(data1, data2):\n        sum_of_data1 += data1_val\n        sum_of_data2 += data2_val\n        sum_of_products += data1_val * data2_val\n        sum_of_squares_data1 += data1_val ** 2\n        sum_of_squares_data2 += data2_val ** 2\n\n    rank_sum = sum((i - 1 / 2) * (rank1 - rank2) ** 2 for rank1, rank2, i in zip(data1, data2, range(1, n + 1)))\n\n    correlation_coefficient = 1 - (6 * rank_sum) / (n * (n ** 2 - 1))\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # calculate ranks of data\n    data1_rank = [(i - sorted(data1).index(x)) for i, x in enumerate(sorted(data1))]\n    data2_rank = [(i - sorted(data2).index(x)) for i, x in enumerate(sorted(data2))]\n    \n    # calculate sum of ranks and squares of ranks\n    sum_data1_rank = sum(data1_rank)\n    sum_data2_rank = sum(data2_rank)\n    sum_data1_rank_squared = sum(x**2 for x in data1_rank)\n    sum_data2_rank_squared = sum(x**2 for x in data2_rank)\n    \n    # calculate covariance and variance\n    cov = sum(x*y for x, y in zip(data1_rank, data2_rank)) - (sum_data1_rank * sum_data2_rank / n)\n    var1 = sum_data1_rank_squared - (sum_data1_rank**2 / n)\n    var2 = sum_data2_rank_squared - (sum_data2_rank**2 / n)\n    \n    # calculate correlation coefficient\n    r = 1 - ((n * cov) / (math.sqrt(var1 * var2)))\n    \n    return r",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Calculate the rank of each data point in both lists\n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n    \n    # Calculate the sum of the differences between the ranks\n    diff_sum = sum(abs(a - b) for a, b in zip(rank1, rank2))\n\n    # Calculate the correlation coefficient\n    r = 1 - (6 * diff_sum) / (n * (n * n - 1))\n\n    return r",
                false
            ]
        ],
        "level 2": [
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n\n    mean_rank1 = sum(rank1) / n\n    mean_rank2 = sum(rank2) / n\n\n    numerator = sum((r1 - mean_rank1) * (r2 - mean_rank2) for r1, r2 in zip(rank1, rank2))\n    denominator = math.sqrt(sum((r - mean_rank1) ** 2 for r in rank1) * sum((r - mean_rank2) ** 2 for r in rank2))\n\n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    from scipy import stats\n    if len(data1) != len(data2):\n        raise ValueError(\"Both data sets must have the same length\")\n    rank_data1 = stats.rankdata(data1)\n    rank_data2 = stats.rankdata(data2)\n    mean_rank1 = sum(rank_data1) / len(rank_data1)\n    mean_rank2 = sum(rank_data2) / len(rank_data2)\n    numerator = sum((rank - mean_rank1) * (rank - mean_rank2) for rank in rank_data1)\n    denominator = math.sqrt(sum((rank - mean_rank1) ** 2 for rank in rank_data1) * sum((rank - mean_rank2) ** 2 for rank in rank_data2))\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Calculate the Spearman correlation coefficient over the rank of two sets of data \"data1\" and \"data2\". Each data set is a list of values. Rank each data set from the smallest to the largest value and assign ranks starting from zero. Compute the mean rank for each data set. Use the ranks to compute the numerator, the covariance of the ranks, as the sum of the product of the deviations of corresponding ranks from their respective means. Compute the denominator, the product of standard deviation of the ranks, as the product of the square roots of the sum of the squares of the deviations of the ranks from their respective means. Return the calculated correlation coefficient, which is the quotient of the numerator and the denominator, as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    if len(data1) != len(data2):\n        raise ValueError(\"Both data sets must have the same length\")\n    \n    data1_rank = [rank for rank, value in sorted(enumerate(data1), key=lambda x:x[1])]\n    data2_rank = [rank for rank, value in sorted(enumerate(data2), key=lambda x:x[1])]\n\n    data1_mean_rank = sum(data1_rank) / len(data1_rank)\n    data2_mean_rank = sum(data2_rank) / len(data2_rank)\n\n    numerator = sum((r1 - data1_mean_rank) * (r2 - data2_mean_rank) for r1, r2 in zip(data1_rank, data2_rank))\n    denominator = math.sqrt(sum((r - data1_mean_rank)**2 for r in data1_rank) * sum((r - data2_mean_rank)**2 for r in data2_rank))\n\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create ranks for both data sets\n    rank1 = [0]*n\n    rank2 = [0]*n\n    for i in range(n):\n        rank1[i] = i\n        rank2[i] = i\n    \n    # Sort data sets and update ranks\n    for i in range(n-1):\n        for j in range(i+1, n):\n            if data1[i] > data1[j]:\n                rank1[i], rank1[j] = rank1[j], rank1[i]\n            if data2[i] > data2[j]:\n                rank2[i], rank2[j] = rank2[j], rank2[i]\n    \n    # Compute the mean rank for each data set\n    mean_rank1 = sum(rank1)/n\n    mean_rank2 = sum(rank2)/n\n    \n    # Compute the numerator, the covariance of the ranks\n    numerator = sum((rank1[i]-mean_rank1) * (rank2[i]-mean_rank2) for i in range(n))\n    \n    # Compute the denominator, the product of standard deviations of the ranks\n    std_dev_rank1 = math.sqrt(sum((rank1[i]-mean_rank1)**2 for i in range(n)) / n)\n    std_dev_rank2 = math.sqrt(sum((rank2[i]-mean_rank2)**2 for i in range(n)) / n)\n    denominator = std_dev_rank1 * std_dev_rank2\n    \n    # Return the correlation coefficient\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Rank data1\n    rnk1 = [sorted(data1).index(x) for x in data1]\n    mean_r1 = sum(rnk1) / n\n\n    # Rank data2\n    rnk2 = [sorted(data2).index(x) for x in data2]\n    mean_r2 = sum(rnk2) / n\n\n    # Calculate numerator\n    numerator = sum((a - mean_r1) * (b - mean_r2) for a, b in zip(rnk1, rnk2))\n\n    # Calculate denominator\n    std_dev_r1 = math.sqrt(sum((a - mean_r1) ** 2 for a in rnk1) / (n - 1))\n    std_dev_r2 = math.sqrt(sum((a - mean_r2) ** 2 for a in rnk2) / (n - 1))\n    denominator = std_dev_r1 * std_dev_r2\n\n    # Calculate correlation coefficient\n    correlation_coefficient = numerator / denominator\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n\n    mean1 = sum(rank1) / n\n    mean2 = sum(rank2) / n\n\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(rank1, rank2))\n    \n    std_dev1 = (sum((i - mean1) ** 2 for i in rank1) / n) ** 0.5\n    std_dev2 = (sum((i - mean2) ** 2 for i in rank2) / n) ** 0.5\n\n    return numerator / (std_dev1 * std_dev2 * n)",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    rank_sum1, rank_sum2 = 0, 0\n    dev1_sum, dev2_sum = 0, 0\n\n    # Calculate ranks.\n    data1 = [(val, i) for i, val in enumerate(sorted(set(data1)))]\n    data2 = [(val, i) for i, val in enumerate(sorted(set(data2)))]\n    rank_dict1 = dict(data1)\n    rank_dict2 = dict(data2)\n\n    for i in range(n):\n        rank1 = rank_dict1[data1[i][0]]\n        rank2 = rank_dict2[data2[i][0]]\n        rank_sum1 += rank1\n        rank_sum2 += rank2\n        dev1_sum += (rank1 - rank_sum1/n)**2\n        dev2_sum += (rank2 - rank_sum2/n)**2\n\n    stddev1, stddev2 = math.sqrt(dev1_sum/(n-1)), math.sqrt(dev2_sum/(n-1))\n    numerator = (rank_sum1 - n*(n-1)/2)*(rank_sum2 - n*(n-1)/2)\n    denominator = (n-1)*stddev1*stddev2\n    return numerator/denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Determine the Spearman correlation coefficient using two input data lists, 'data1' and 'data2'. Each list should be ranked from smallest to largest with ranks beginning at zero. Compute the average rank for both data sets. Calculate the numerator as the sum of the products of rank deviations from their means. For the denominator, compute the product of the standard deviations of the ranks, obtained by taking the square roots of the sum of squared deviations from their ranks' means. Provide the correlation coefficient as a float, being the numerator divided by the denominator.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    import numpy as np\n    from scipy.stats import rankdata\n\n    # Ranking data1 and data2\n    rank_data1 = rankdata(data1)\n    rank_data2 = rankdata(data2)\n\n    # Computing the mean ranks\n    mean_rank_data1 = np.mean(rank_data1)\n    mean_rank_data2 = np.mean(rank_data2)\n\n    # Computing rank deviations from their means\n    rank_deviation_data1 = rank_data1 - mean_rank_data1\n    rank_deviation_data2 = rank_data2 - mean_rank_data2\n\n    # Computing numerator\n    numerator = np.sum(rank_deviation_data1 * rank_deviation_data2)\n\n    # Computing denominator\n    rank_deviation_squared_data1 = rank_deviation_data1 ** 2\n    rank_deviation_squared_data2 = rank_deviation_data2 ** 2\n    denominator = np.sqrt(np.sum(rank_deviation_squared_data1) * np.sum(rank_deviation_squared_data2))\n\n    # Computing correlation coefficient\n    correlation_coefficient = numerator / denominator\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create ranks for both data sets\n    rank1 = [0]*n\n    rank2 = [0]*n\n    for i in range(n):\n        rank1[i] = sum(j < data1[i] for j in data1)\n        rank2[i] = sum(j < data2[i] for j in data2)\n        \n    # Calculate mean rank for both data sets\n    mean_rank1 = sum(rank1)/n\n    mean_rank2 = sum(rank2)/n\n    \n    # Calculate numerator and denominator\n    numerator = sum((rank1[i] - mean_rank1) * (rank2[i] - mean_rank2) for i in range(n))\n    den_square = sum((rank1[i] - mean_rank1)**2 for i in range(n)) + sum((rank2[i] - mean_rank2)**2 for i in range(n))\n    denominator = math.sqrt(den_square)\n    \n    # Calculate and return correlation coefficient\n    coefficient = numerator / denominator\n    return coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Ranking\n    data1_sorted = sorted(data1)\n    data2_sorted = sorted(data2)\n    ranks1 = [data1_sorted.index(x) for x in data1]\n    ranks2 = [data2_sorted.index(x) for x in data2]\n\n    # Mean rank\n    mean_rank1 = sum(ranks1) / n\n    mean_rank2 = sum(ranks2) / n\n\n    # Deviation from mean rank\n    dev1 = [(rank - mean_rank1) for rank in ranks1]\n    dev2 = [(rank - mean_rank2) for rank in ranks2]\n\n    # Sum of squared deviations from rank means\n    sum_of_squared_dev1 = sum(d**2 for d in dev1)\n    sum_of_squared_dev2 = sum(d**2 for d in dev2)\n\n    # Standard deviation of rank\n    std_dev_rank1 = math.sqrt(sum_of_squared_dev1)\n    std_dev_rank2 = math.sqrt(sum_of_squared_dev2)\n\n    # Numerator\n    numerator = sum(dev1[i]*dev2[i] for i in range(n))\n\n    # Correlation coefficient\n    correlation_coefficient = numerator / (std_dev_rank1*std_dev_rank2)\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    rank1 = [i for _, i in sorted(zip(data1, range(n)))]\n    rank2 = [i for _, i in sorted(zip(data2, range(n)))]\n    \n    rank1_mean = sum(rank1) / n\n    rank2_mean = sum(rank2) / n\n    \n    rank1_deviation = [rank - rank1_mean for rank in rank1]\n    rank2_deviation = [rank - rank2_mean for rank in rank2]\n    \n    numerator = sum(rank1_deviation[i] * rank2_deviation[i] for i in range(n))\n    denominator = math.sqrt(sum(d**2 for d in rank1_deviation) * sum(d**2 for d in rank2_deviation))\n    \n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    rank_sum1 = sum(data1)\n    rank_sum2 = sum(data2)\n    numerator = sum([(data1[i] - rank_sum1/n) * (data2[i] - rank_sum2/n) for i in range(n)])\n    square_dev1 = sum([(data1[i] - rank_sum1/n)**2 for i in range(n)])\n    square_dev2 = sum([(data2[i] - rank_sum2/n)**2 for i in range(n)])\n    denominator = math.sqrt(square_dev1 * square_dev2)\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Compute the Spearman correlation coefficient for two data sets labeled 'data1' and 'data2', where each is a list of numbers ranked from least to greatest, starting ranks from zero. Calculate the mean of the ranks for each set. The numerator involves the sum of the multiplied deviations of corresponding ranks from their averages. The denominator is the multiplication of the square root of summed squared deviations from the averages of each rank set. Return this correlation coefficient, the division of the numerator by the denominator, as a floating-point number.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Compute the mean of the ranks for each set.\n    mean_data1 = sum(data1) / len(data1)\n    mean_data2 = sum(data2) / len(data2)\n\n    # Compute the deviation of each rank from its mean.\n    deviations_data1 = [rank - mean_data1 for rank in data1]\n    deviations_data2 = [rank - mean_data2 for rank in data2]\n\n    # Compute the squared deviation of each rank from its mean.\n    squared_deviations_data1 = [deviation ** 2 for deviation in deviations_data1]\n    squared_deviations_data2 = [deviation ** 2 for deviation in deviations_data2]\n\n    # Compute the sum of squared deviations from the averages of the rank sets.\n    sum_squared_deviations_data1 = sum(squared_deviations_data1)\n    sum_squared_deviations_data2 = sum(squared_deviations_data2)\n\n    # Compute the square root of the summed squared deviations.\n    root_sum_squared_deviations_data1 = math.sqrt(sum_squared_deviations_data1)\n    root_sum_squared_deviations_data2 = math.sqrt(sum_squared_deviations_data2)\n\n    # Compute the sum of the multiplied deviations of corresponding ranks from their averages.\n    numerator = sum([deviations_data1[i] * deviations_data2[i] for i in range(len(data1))])\n\n    # Compute the correlation coefficient, which is the division of the numerator by the denominator.\n    coefficient = numerator / (root_sum_squared_deviations_data1 * root_sum_squared_deviations_data2)\n\n    return coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    mean_rank1 = sum(data1) / len(data1)\n    mean_rank2 = sum(data2) / len(data2)\n    numerator = sum((rank1 - mean_rank1) * (rank2 - mean_rank2) for rank1, rank2 in zip(data1, data2))\n    denominator = math.sqrt(sum((rank - mean_rank1) ** 2 for rank in data1) * sum((rank - mean_rank2) ** 2 for rank in data2))\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Calculate mean rank for each set\n    mean1 = sum(data1) / n\n    mean2 = sum(data2) / n\n\n    # Calculate numerator\n    numerator = sum((rank1 - mean1) * (rank2 - mean2) for rank1, rank2 in zip(data1, data2))\n\n    # Calculate denominator\n    denominator = math.sqrt(sum((rank - mean1) ** 2 for rank in data1) * sum((rank - mean2) ** 2 for rank in data2))\n\n    # Return result\n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n\n    mean_rank1 = sum(rank1) / n\n    mean_rank2 = sum(rank2) / n\n\n    numerator = sum([(rank1[i] - mean_rank1)*(rank2[i] - mean_rank2) for i in range(n)])\n    denominator = math.sqrt(sum([(rank1[i] - mean_rank1)**2 for i in range(n)]) * sum([(rank2[i] - mean_rank2)**2 for i in range(n)]))\n\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    from scipy.stats import rankdata\n    from scipy.stats import spearmanr\n\n    data1_rank = rankdata(data1)\n    data2_rank = rankdata(data2)\n\n    correlation_coefficient = spearmanr(data1_rank, data2_rank)\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    For two arrays 'data1' and 'data2', rank the data from the smallest value to the largest initiating with ranks at zero and compute the Spearman correlation coefficient. Each set's mean rank must be calculated. Then, calculate the numerator as the cumulated product of the rank differences from their respective averages. The denominator should be derived from the square root of the sum of squared rank differences from the averages, multiplied together. Finally, return the calculated coefficient, a float that is the numerator divided by the denominator.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Combine data1 and data2 into a single list\n    combined_data = data1 + data2\n\n    # Create a dictionary to store each data point with its rank\n    rank_dict = {}\n    for index, data in enumerate(sorted(combined_data)):\n        if data not in rank_dict:\n            rank_dict[data] = 0.5 * (index + 1)  # Rank starts at 1, but we need it starts at 0, hence the + 1\n\n    # Calculate the numerator and denominator\n    numerator = 0\n    denominator = 0\n    for data1, data2 in zip(data1, data2):\n        rank_diff = rank_dict[data1] - rank_dict[data2]\n        numerator += rank_diff ** 2\n        denominator += rank_diff ** 2\n    numerator *= len(data1)\n    denominator = math.sqrt(denominator * len(data1))\n\n    # If denominator is zero, then the correlation coefficient is undefined\n    if denominator == 0.0:\n        return 0\n\n    # Calculate the correlation coefficient\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    mean_rank1 = sum(sorted(data1).index(x) for x in data1) / len(data1)\n    mean_rank2 = sum(sorted(data2).index(x) for x in data2) / len(data2)\n    rank_diffs1 = [sorted(data1).index(x) - mean_rank1 for x in data1]\n    rank_diffs2 = [sorted(data2).index(x) - mean_rank2 for x in data2]\n    numerator = sum(a * b for a, b in zip(rank_diffs1, rank_diffs2))\n    denominator = math.sqrt(sum(a * a for a in rank_diffs1) * sum(a * a for a in rank_diffs2))\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Calculate ranks for data1 and data2\n    rank1 = [sorted(data1).index(x) for x in data1]\n    rank2 = [sorted(data2).index(x) for x in data2]\n\n    # Calculate means of ranks\n    mean_rank1 = sum(rank1) / n\n    mean_rank2 = sum(rank2) / n\n\n    # Calculate numerator and denominator of Spearman's rank correlation coefficient\n    numerator = sum((r1 - mean_rank1) * (r2 - mean_rank2) for r1, r2 in zip(rank1, rank2))\n    denominator = math.sqrt(sum((r - mean_rank1) ** 2 for r in rank1 + rank2))\n\n    # Calculate and return correlation coefficient\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n\n    mean_rank1 = sum(rank1) / n\n    mean_rank2 = sum(rank2) / n\n\n    numerator = sum((r1 - mean_rank1) * (r2 - mean_rank2) for r1, r2 in zip(rank1, rank2))\n    denominator = math.sqrt(sum((r - mean_rank1) ** 2 for r in rank1) * sum((r - mean_rank2) ** 2 for r in rank2))\n\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    rank_sum1, rank_sum2 = 0, 0\n    dev_sum1, dev_sum2 = 0, 0\n\n    # Rank the data.\n    data1.sort()\n    data2.sort()\n\n    # Create a dictionary that maps each number in data1 and data2 to its rank.\n    rank_dict1 = {data1[i]: i for i in range(n)}\n    rank_dict2 = {data2[i]: i for i in range(n)}\n\n    for i in range(n):\n        # Calculate the mean rank for each list.\n        rank_sum1 += rank_dict1[data1[i]]\n        rank_sum2 += rank_dict2[data2[i]]\n\n    mean_rank_1, mean_rank_2 = rank_sum1 / n, rank_sum2 / n\n\n    for i in range(n):\n        # Calculate the sum of each rank's squared deviations from their respective mean ranks.\n        dev_sum1 += (rank_dict1[data1[i]] - mean_rank_1) ** 2\n        dev_sum2 += (rank_dict2[data2[i]] - mean_rank_2) ** 2\n\n    # Calculate the numerator: the sum of each pair of rank's deviation from their means.\n    numerator = sum((rank_dict1[data1[i]] - mean_rank_1) * (rank_dict2[data2[i]] - mean_rank_2) for i in range(n))\n    # Calculate the denominator, multiply the square roots of the sums of each rank's squared deviations from their respective mean ranks.\n    denominator = math.sqrt(dev_sum1) * math.sqrt(dev_sum2)\n\n    # Return the division of the numerator by the denominator.\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Write a function to calculate the Spearman correlation coefficient for ranked data sets 'data1' and 'clusive 2. Rank the data from the lowest to the highest, beginning with zero. Find the mean rank for each list. The numerator should be the sum of the result of multiplying each pair of rank's deviation from their means. For the denominator, multiply the square roots of the sums of each rank's squared deviations from their respective mean ranks. Output the division of the numerator by the denominator as a float indicating the correlation coefficient.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    data1.sort()\n    data2.sort()\n\n    mean_rank_data1 = sum(range(len(data1))) / len(data1)\n    mean_rank_data2 = sum(range(len(data2))) / len(data2)\n\n    numerator = sum([(data1[i] - mean_rank_data1) * (data2[i] - mean_rank_data2) for i in range(len(data1))])\n    denominator = math.sqrt(sum([(data1[i] - mean_rank_data1) ** 2 for i in range(len(data1))]) * sum([(data2[i] - mean_rank_data2) ** 2 for i in range(len(data2))]))\n\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create rank lists for data1 and data2\n    rank1 = [0]*n\n    rank2 = [0]*n\n    for i in range(n):\n        rank1[i] = data1.index(sorted(data1)[i])\n        rank2[i] = data2.index(sorted(data2)[i])\n    \n    # Calculate means of rank lists\n    mean_rank1 = sum(rank1)/n\n    mean_rank2 = sum(rank2)/n\n    \n    # Calculate numerator and denominator\n    numerator = 0\n    denominator1 = 0\n    denominator2 = 0\n    for i in range(n):\n        numerator += (rank1[i] - mean_rank1)*(rank2[i] - mean_rank2)\n        denominator1 += (rank1[i] - mean_rank1)**2\n        denominator2 += (rank2[i] - mean_rank2)**2\n    \n    denominator = math.sqrt(denominator1*denominator2)\n    \n    # Return correlation coefficient\n    return numerator/denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Rank the data\n    data1_ranked = sorted((x, i) for i, x in enumerate(data1))\n    data2_ranked = sorted((x, i) for i, x in enumerate(data2))\n\n    # Calculate the mean rank for each list\n    mean1 = sum(i for _, i in data1_ranked) / n\n    mean2 = sum(i for _, i in data2_ranked) / n\n\n    # Calculate the numerator as the sum of the result of multiplying each pair of rank's deviation from their means\n    numerator = sum((i[0] - mean1) * (i[1] - mean2) for i in zip(data1_ranked, data2_ranked))\n\n    # Calculate the denominator as the square root of the sums of each rank's squared deviations from their respective mean ranks\n    denominator = math.sqrt(sum((i[0] - mean1) ** 2 for i in data1_ranked) * sum((i[1] - mean2) ** 2 for i in data2_ranked))\n\n    # Calculate and return the correlation coefficient\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    rank1 = [sorted(data1).index(i) for i in data1]\n    rank2 = [sorted(data2).index(i) for i in data2]\n\n    mean_rank1 = sum(rank1) / n\n    mean_rank2 = sum(rank2) / n\n\n    numerator = sum([(rank1[i] - mean_rank1)*(rank2[i] - mean_rank2) for i in range(n)])\n    denominator = math.sqrt(sum([(rank1[i] - mean_rank1)**2 for i in range(n)]) * sum([(rank2[i] - mean_rank2)**2 for i in range(n)]))\n\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    from scipy import stats\n    if len(data1) != len(data2):\n        return \"data1 and data2 must have the same length\"\n    rank_data1 = stats.rankdata(data1)\n    rank_data2 = stats.rankdata(data2)\n    mean_rank1 = sum(rank_data1) / len(rank_data1)\n    mean_rank2 = sum(rank_data2) / len(rank_data2)\n    numerator = sum((rank - mean_rank1) * (rank - mean_rank2) for rank in rank_data1)\n    denominator = math.sqrt(sum((rank - mean_rank1) ** 2 for rank in rank_data1) * sum((rank - mean_rank2) ** 2 for rank in rank_data2))\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Execute the calculation of the Spearman correlation coefficient for two lists of values, 'data1' and 'data2'. Rank these lists from their smallest to largest values starting at zero. Ascertain the mean of these ranks. The numerator is the combined sum of products of differences between ranks from their average values. The denominator is the product of the standard deviations, each derived by computing the square root of the sum of each rank's squared differences from their means. The outcome should be provided as the quotient of the numerator by the denominator as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Convert data to list\n    data1, data2 = list(data1), list(data2)\n\n    # Create the rank of each data\n    rank_data1 = sorted((x, i) for i, x in enumerate(data1))\n    rank_data2 = sorted((x, i) for i, x in enumerate(data2))\n\n    # Take the average of the ranks\n    avg_rank_data1 = sum(r for r, _ in rank_data1) / len(data1)\n    avg_rank_data2 = sum(r for r, _ in rank_data2) / len(data2)\n\n    # Compute the numerator\n    numerator = sum((r1 - avg_rank_data1)*(r2 - avg_rank_data2) for (_, r1), (_, r2) in zip(rank_data1, rank_data2))\n\n    # Compute the denominator\n    denominator = (sum((r - avg_rank_data1)**2 for r, _ in rank_data1)\n                  * sum((r - avg_rank_data2)**2 for r, _ in rank_data2))**0.5\n\n    # Compute the correlation coefficient\n    correlation_coefficient = numerator / denominator\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create rank lists for data1 and data2\n    rank1 = [0]*n\n    rank2 = [0]*n\n    for i in range(n):\n        rank1[i] = i\n        rank2[i] = i\n    data1.sort()\n    data2.sort()\n    for i in range(n):\n        rank1[data1.index(data1[i])] = i\n        rank2[data2.index(data2[i])] = i\n    \n    # Calculate correlation coefficient\n    sum_rank_diff = sum([rank1[i]-rank2[i] for i in range(n)])\n    numerator = 6*sum_rank_diff*sum_rank_diff\n    denumerator = n*(n*n-1)\n\n    correlation_coefficient = numerator/denumerator\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Ranking\n    data1_sorted_index = sorted(range(len(data1)), key=lambda i: data1[i])\n    data2_sorted_index = sorted(range(len(data2)), key=lambda i: data2[i])\n\n    # Compute ranks and mean\n    ranks1 = [(data1_sorted_index.index(i)) for i in range(n)]\n    ranks2 = [(data2_sorted_index.index(i)) for i in range(n)]\n\n    mean_rank1 = sum(ranks1)/n\n    mean_rank2 = sum(ranks2)/n\n\n    # Compute numerator and denominator\n    numerator = sum([(ranks1[i] - mean_rank1) * (ranks2[i] - mean_rank2) for i in range(n)])\n    denominator = math.sqrt(sum([(ranks1[i] - mean_rank1) ** 2 for i in range(n)]) * sum([(ranks2[i] - mean_rank2) ** 2 for i in range(n)]))\n\n    # Return correlation coefficient\n    return float(numerator / denominator)",
                false
            ]
        ],
        "level 3": [
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Calculate the ranks for each list\n    ranked_data1 = [sorted(data1).index(i) + 1 for i in data1]\n    ranked_data2 = [sorted(data2).index(i) + 1 for i in data2]\n\n    # Calculate the mean rank for each list\n    mean_rank1 = sum(ranked_data1) / n\n    mean_rank2 = sum(ranked_data2) / n\n    \n    # Calculate the numerator\n    numerator = sum([(ranked_data1[i] - mean_rank1) * (ranked_data2[i] - mean_rank2) for i in range(n)])\n    \n    # Calculate the denominator\n    denominator = math.sqrt(sum([(ranked_data1[i] - mean_rank1) ** 2 for i in range(n)]) * sum([(ranked_data2[i] - mean_rank2) ** 2 for i in range(n)]))\n\n    # Calculate the correlation coefficient\n    correlation_coefficient = numerator / denominator if denominator != 0 else 0\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    from scipy import stats\n    if len(data1) != len(data2):\n        return ValueError(\"Both data sets must have the same number of elements.\")\n\n    ranked_data1 = stats.rankdata(data1)\n    ranked_data2 = stats.rankdata(data2)\n\n    n = len(ranked_data1)\n    mean_rank1 = sum(ranked_data1) / n\n    mean_rank2 = sum(ranked_data2) / n\n    rank_dif1 = [rank - mean_rank1 for rank in ranked_data1]\n    rank_dif2 = [rank - mean_rank2 for rank in ranked_data2]\n    diff_square1 = [dif**2 for dif in rank_dif1]\n    diff_square2 = [dif**2 for dif in rank_dif2]\n\n    numerator = sum([rank_dif1[i]*rank_dif2[i] for i in range(n)])\n    denominator = math.sqrt(sum(diff_square1) * sum(diff_square2))\n    \n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Calculate the Spearman correlation coefficient over the rank of two sets of data \"data1\" and \"data2\". Each data set is a list of values. First, sort each list \"data1\" and \"data2\" and then assign ranks to the original data based on this sorted list, which are stored in \"ranked_data1\" and \"ranked_data2\". Compute the mean rank for each data set by summing all the ranks and dividing by the number of elements \"n\". Calculate the numerator, the covariance of the ranks, by summing the product of the differences of each rank from their respective mean ranks for both data sets. Calculate the denominator, the product of standard deviation of the ranks, by multiplying the square roots of the sum of the squares of the rank differences from their respective mean ranks for both lists. The correlation coefficient, returned as a float, is computed by dividing the numerator by the denominator. If the denominator is zero, return zero.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    n = len(data1)\n\n    # sort the data\n    sorted_data1 = sorted(data1)\n    sorted_data2 = sorted(data2)\n\n    # assign ranks to the original data\n    ranked_data1 = [sorted_data1.index(d) + 1 for d in data1]\n    ranked_data2 = [sorted_data2.index(d) + 1 for d in data2]\n\n    # compute the mean rank for each data set\n    mean_rank1 = sum(ranked_data1) / n\n    mean_rank2 = sum(ranked_data2) / n\n\n    # calculate the numerator\n    numerator = sum([(ranked_data1[i] - mean_rank1) * (ranked_data2[i] - mean_rank2) for i in range(n)])\n\n    # calculate the denominator\n    denominator = math.sqrt(sum([(ranked_data1[i] - mean_rank1) ** 2 for i in range(n)]) * sum([(ranked_data2[i] - mean_rank2) ** 2 for i in range(n)]))\n\n    # compute the correlation coefficient\n    correlation_coefficient = numerator / denominator if denominator != 0 else 0\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create rank lists for data1 and data2\n    ranked_data1 = [sorted(data1).index(i)+1 for i in data1]\n    ranked_data2 = [sorted(data2).index(i)+1 for i in data2]\n\n    # Calculate the mean rank for each data set\n    mean_rank_data1 = sum(ranked_data1)/n\n    mean_rank_data2 = sum(ranked_data2)/n\n\n    # Calculate the numerator, the covariance of the ranks\n    numerator = sum((ranked_data1[i]-mean_rank_data1)*(ranked_data2[i]-mean_rank_data2) for i in range(n))\n\n    # Calculate the denominator, the product of standard deviation of the ranks\n    denominator = math.sqrt(sum((ranked_data1[i]-mean_rank_data1)**2 for i in range(n)) * sum((ranked_data2[i]-mean_rank_data2)**2 for i in range(n)))\n\n    # Calculate the correlation coefficient\n    correlation_coefficient = numerator / denominator if denominator != 0 else 0\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # sort data1 and data2 and get their ranks\n    ranked_data1 = sorted([(val, idx) for idx, val in enumerate(data1)], key=lambda x: x[0])\n    ranked_data2 = sorted([(val, idx) for idx, val in enumerate(data2)], key=lambda x: x[0])\n\n    # calculate the mean rank for each data set\n    mean_rank1 = sum(ranked_data1[idx][1] for idx in range(n))/n\n    mean_rank2 = sum(ranked_data2[idx][1] for idx in range(n))/n\n\n    # calculate the numerator\n    numerator = sum((ranked_data1[idx][1] - mean_rank1)*(ranked_data2[idx][1] - mean_rank2) for idx in range(n))\n    \n    # calculate the denominator\n    denominator = math.sqrt(sum((ranked_data1[idx][1] - mean_rank1)**2 for idx in range(n))*sum((ranked_data2[idx][1] - mean_rank2)**2 for idx in range(n)))\n\n    # calculate the correlation coefficient   \n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Calculate the ranks for each data set\n    ranked_data1 = sorted([rank for rank, _ in sorted(enumerate(data1), key=lambda x:x[1])])\n    ranked_data2 = sorted([rank for rank, _ in sorted(enumerate(data2), key=lambda x:x[1])])\n    \n    # Compute the average rank of each data set\n    avg_rank_data1 = sum(ranked_data1) / n\n    avg_rank_data2 = sum(ranked_data2) / n\n    \n    # Compute the numerator and denominator for the correlation coefficient\n    numerator = sum((ranked_data1[i] - avg_rank_data1) * (ranked_data2[i] - avg_rank_data2) for i in range(n))\n    denominator = math.sqrt(sum((ranked_data1[i] - avg_rank_data1)**2 for i in range(n))) * math.sqrt(sum((ranked_data2[i] - avg_rank_data2)**2 for i in range(n)))\n    \n    # Compute the correlation coefficient\n    correlation_coefficient = numerator / denominator if denominator != 0 else 0\n    \n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    if n != len(data2):\n        raise ValueError(\"Input data sets must have the same length\")\n    \n    ranked_data1 = [(i+1) for i in sorted(range(n), key=data1.__getitem__)]\n    ranked_data2 = [(i+1) for i in sorted(range(n), key=data2.__getitem__)]\n    \n    mean_rank1 = sum(ranked_data1)/n\n    mean_rank2 = sum(ranked_data2)/n\n    \n    numerator = sum((ranked_data1[i] - mean_rank1)*(ranked_data2[i] - mean_rank2) for i in range(n))\n    denominator = math.sqrt(sum((ranked_data1[i] - mean_rank1)**2 for i in range(n))*sum((ranked_data2[i] - mean_rank2)**2 for i in range(n)))\n    \n    if denominator == 0:\n        return 0\n    else:\n        return numerator/denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Compute the Spearman correlation coefficient for two groups of numbers labeled 'data1' and 'data2'. First, sort each group separately and assign a ranking to the original values based on the sorted order, represented by 'ranked_data1' and 'ranked_data2'. Then, determine the average rank of each data set by dividing the total of the ranks by the count 'n'. To compute the numerator, sum up the multiplied differences between each rank and its corresponding average rank across both data groups. For the denominator, calculate the standard deviations of the ranked values by multiplying the square roots of the summed squares of the differences from the mean ranks for each data set. The final correlation coefficient is the quotient of the numerator by the denominator, returning zero if the denominator is zero.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Sort the data and assign rank\n    sorted_data1 = sorted(data1, key=data1.index)\n    sorted_data2 = sorted(data2, key=data2.index)\n    ranked_data1 = [sorted_data1.index(i) + 1 for i in data1]\n    ranked_data2 = [sorted_data2.index(i) + 1 for i in data2]\n\n    # Calculate average rank\n    avg_rank1 = sum(ranked_data1) / len(ranked_data1)\n    avg_rank2 = sum(ranked_data2) / len(ranked_data2)\n\n    # Calculate numerator\n    numerator = sum([(ranked_data1[i] - avg_rank1) * (ranked_data2[i] - avg_rank2) for i in range(len(data1))])\n\n    # Calculate denominator\n    denominator = math.sqrt(sum([(ranked_data1[i] - avg_rank1) ** 2 for i in range(len(data1))])) * math.sqrt(sum([(ranked_data2[i] - avg_rank2) ** 2 for i in range(len(data2))]))\n\n    # Calculate correlation coefficient\n    if denominator != 0:\n        correlation_coefficient = numerator / denominator\n    else:\n        correlation_coefficient = 0\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create dictionary to map original values to their corresponding ranks\n    ranks1 = {x: i for i, x in enumerate(sorted(data1), 1)}\n    ranks2 = {x: i for i, x in enumerate(sorted(data2), 1)}\n    \n    # Calculate the average rank\n    avg_rank1 = sum(ranks1[x] for x in data1) / n\n    avg_rank2 = sum(ranks2[x] for x in data2) / n\n    \n    # Calculate the numerator and the denominator\n    numerator = sum((ranks1[x] - avg_rank1) * (ranks2[y] - avg_rank2) for x, y in zip(data1, data2))\n    denominator = math.sqrt(sum((ranks1[x] - avg_rank1)**2 for x in data1) * sum((ranks2[y] - avg_rank2)**2 for y in data2))\n    \n    # Return the correlation coefficient\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # sort data1 and data2 separately\n    sorted_data1 = sorted(data1)\n    sorted_data2 = sorted(data2)\n\n    # assign ranks to the original data\n    ranked_data1 = [sorted_data1.index(x) + 1 for x in data1]\n    ranked_data2 = [sorted_data2.index(x) + 1 for x in data2]\n\n    # calculate the average rank of each data set\n    avg_rank1 = sum(ranked_data1) / n\n    avg_rank2 = sum(ranked_data2) / n\n\n    # calculate the numerator\n    numerator = sum((rx - avg_rank1) * (ry - avg_rank2) for rx, ry in zip(ranked_data1, ranked_data2))\n\n    # calculate the denominator\n    denominator = math.sqrt(sum((rx - avg_rank1)**2 for rx in ranked_data1) * sum((ry - avg_rank2)**2 for ry in ranked_data2))\n\n    # the final correlation coefficient\n    correlation_coefficient = numerator / denominator if denominator != 0 else 0\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Calculate the ranks for each list\n    ranked_data1 = {x: i+1 for i, x in enumerate(sorted(data1))}\n    ranked_data2 = {x: i+1 for i, x in enumerate(sorted(data2))}\n\n    # Calculate the mean rank of both datasets\n    mean_rank1 = sum(ranked_data1.values()) / n\n    mean_rank2 = sum(ranked_data2.values()) / n\n\n    # Calculate the numerator\n    numerator = sum((ranked_data1[x] - mean_rank1) * (ranked_data2[y] - mean_rank2) for x, y in zip(data1, data2))\n\n    # Calculate the denominator\n    deviation1 = [ranked_data1[i] - mean_rank1 for i in data1]\n    deviation2 = [ranked_data2[i] - mean_rank2 for i in data2]\n    denominator = math.sqrt(sum(i**2 for i in deviation1) * sum(i**2 for i in deviation2))\n\n    # Return the correlation coefficient or 0 if denominator is zero\n    return numerator / denominator if denominator else 0",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    if n != len(data2):\n        raise ValueError(\"Input lists must have the same length\")\n\n    if n == 0:\n        return 0\n      \n    data1.sort()\n    data2.sort()\n\n    ranked_data1 = [0]*len(data1)\n    ranked_data2 = [0]*len(data2)\n\n    for i in range(len(data1)):\n        ranked_data1[i] = i+1\n        ranked_data2[i] = i+1\n\n    mean_rank1 = sum(ranked_data1)/n\n    mean_rank2 = sum(ranked_data2)/n\n\n    numerator = sum([(ranked_data1[i]-mean_rank1)*(ranked_data2[i]-mean_rank2) for i in range(len(data1))])\n    denominator = math.sqrt(sum([(ranked_data1[i]-mean_rank1)**2 for i in range(len(data1))])*sum([(ranked_data2[i]-mean_rank2)**2 for i in range(len(data2))]))\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator/denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    For two datasets 'data1' and 'data2', calculate the Spearman correlation coefficient. Begin by sorting both lists and assigning ranks to the initial values in 'ranked_data1' and 'ranked_data2'. Calculate each set's mean rank by summing the ranks and dividing by the count 'n'. For the numerator, add up the products of rank deviations from their respective averages across both datasets. For the denominator, find the product of the two groups' rank standard deviations by multiplying the square roots of the sum of squares of these deviations. Return the correlation coefficient by dividing the numerator by the denominator, or zero if the denominator equals zero.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Sort the data and get the ranks\n    sorted_data1 = sorted(data1)\n    sorted_data2 = sorted(data2)\n    data1_ranks = []\n    data2_ranks = []\n    for x in sorted_data1:\n        data1_ranks.append(sorted_data1.index(x) + 1)\n    for y in sorted_data2:\n        data2_ranks.append(sorted_data2.index(y) + 1)\n\n    # Calculate the mean ranks and the deviation from mean ranks\n    mean_rank1 = sum(data1_ranks) / len(data1_ranks)\n    mean_rank2 = sum(data2_ranks) / len(data2_ranks)\n    rank_deviation1 = [rank - mean_rank1 for rank in data1_ranks]\n    rank_deviation2 = [rank - mean_rank2 for rank in data2_ranks]\n\n    # Calculate the numerator and denominator for the correlation coefficient\n    numerator = sum(a * b for a, b in zip(rank_deviation1, rank_deviation2))\n    denominator = math.sqrt(sum(x ** 2 for x in rank_deviation1) * sum(x ** 2 for x in rank_deviation2))\n\n    # If the denominator is zero, return zero because division by zero is undefined. Otherwise, return the correlation coefficient.\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create rank lists for data1 and data2\n    ranked_data1 = [(x, i) for i, x in enumerate(sorted(data1))]\n    ranked_data2 = [(x, i) for i, x in enumerate(sorted(data2))]\n    \n    # Calculate the average rank for data1 and data2\n    mean_rank_data1 = sum([x for x, _ in ranked_data1]) / n\n    mean_rank_data2 = sum([x for x, _ in ranked_data2]) / n\n    \n    # Calculate numerator\n    numerator = sum([(x - mean_rank_data1) * (y - mean_rank_data2) for x, y in zip([x for x, _ in ranked_data1], [y for y, _ in ranked_data2])])\n    \n    # Calculate denominator\n    denom_data1 = math.sqrt(sum([(x - mean_rank_data1)**2 for x, _ in ranked_data1]))\n    denom_data2 = math.sqrt(sum([(y - mean_rank_data2)**2 for y, _ in ranked_data2]))\n    \n    # Calculate correlation coefficient\n    correlation_coefficient = numerator / (denom_data1 * denom_data2)\n    \n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # Sorting the data and assigning ranks\n    ranked_data1 = [sorted(data1).index(x) + 1 for x in data1]\n    ranked_data2 = [sorted(data2).index(x) + 1 for x in data2]\n\n    # Calculating mean rank for each dataset\n    mean_rank1 = sum(ranked_data1) / n\n    mean_rank2 = sum(ranked_data2) / n\n\n    # Calculating the numerator\n    numerator = sum([(ranked_data1[i] - mean_rank1) * (ranked_data2[i] - mean_rank2) for i in range(n)])\n\n    # Calculating the denominator\n    denominator = math.sqrt(sum([(ranked_data1[i] - mean_rank1) ** 2 for i in range(n)]) * sum([(ranked_data2[i] - mean_rank2) ** 2 for i in range(n)]))\n\n    # Calculating the correlation coefficient\n    corr_coef = numerator / denominator if denominator != 0 else 0\n\n    return corr_coef",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Sort both lists and get their ranks\n    sorted_data1 = sorted(range(len(data1)), key=lambda i: data1[i])\n    sorted_data2 = sorted(range(len(data2)), key=lambda i: data2[i])\n    ranked_data1 = [sorted_data1.index(i) for i in range(n)]\n    ranked_data2 = [sorted_data2.index(i) for i in range(n)]\n    \n    # Compute averages of the ranks\n    avg_rank1 = sum(ranked_data1) / n\n    avg_rank2 = sum(ranked_data2) / n\n\n    # Compute numerator and denominator\n    numerator = sum((ranked_data1[i] - avg_rank1) * (ranked_data2[i] - avg_rank2) for i in range(n))\n    denominator = math.sqrt(sum((ranked_data1[i] - avg_rank1) ** 2 for i in range(n)) * \n                            sum((ranked_data2[i] - avg_rank2) ** 2 for i in range(n)))\n\n    # Check if the denominator is zero to avoid division by zero\n    if denominator == 0:\n        return 0\n\n    # Compute and return the correlation coefficient\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    if n != len(data2):\n        raise ValueError(\"Input lists must have the same length\")\n\n    data1.sort()\n    data2.sort()\n\n    ranked_data1 = [data1.index(i) for i in data1]\n    ranked_data2 = [data2.index(i) for i in data2]\n\n    avg_rank1 = sum(ranked_data1) / n\n    avg_rank2 = sum(ranked_data2) / n\n\n    numerator = sum([(i - avg_rank1) * (j - avg_rank2) for i, j in zip(ranked_data1, ranked_data2)])\n\n    deviation1_squared = [(i - avg_rank1)**2 for i in ranked_data1]\n    deviation2_squared = [(i - avg_rank2)**2 for i in ranked_data2]\n\n    denom_root = math.sqrt(sum(deviation1_squared) * sum(deviation2_squared))\n    \n    if denom_root == 0:\n        return 0\n    else:\n        return numerator / denom_root",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Find the Spearman correlation coefficient for the data lists 'data1' and 'data2'. Begin by sorting these lists and mapping the initial data to their ordered ranks in 'ranked_data1' and 'ranked_data2'. Then, get the average rank for each list by dividing the sum of ranks by 'n'. Calculate the numerator, which is the sum of products from the deviation of each data's rank from its average across both lists. For the denominator, obtain the square roots of the sums of squared deviations for each list, then multiply these roots. The result, or correlation coefficient, is the ratio of the numerator to the denominator, returning zero if no denominator exists.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    n = len(data1)\n    ranked_data1 = sorted((x, i) for i, x in enumerate(data1))\n    ranked_data2 = sorted((x, i) for i, x in enumerate(data2))\n\n    avg_rank1 = sum(r for (x, r) in ranked_data1) / n\n    avg_rank2 = sum(r for (x, r) in ranked_data2) / n\n\n    numerator = sum((r1 - avg_rank1) * (r2 - avg_rank2) for (x1, r1), (x2, r2) in zip(ranked_data1, ranked_data2))\n    denominator = math.sqrt(sum((r - avg_rank1) ** 2 for (x, r) in ranked_data1) * sum((r - avg_rank2) ** 2 for (x, r) in ranked_data2))\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create dictionary of rank\n    data1_rank = {x: i + 1 for i, x in enumerate(sorted(data1))}\n    data2_rank = {x: i + 1 for i, x in enumerate(sorted(data2))}\n    \n    # Calculate the numerator\n    numerator = sum((data1_rank[a] - sum(data1_rank.values()) / n) * (data2_rank[b] - sum(data2_rank.values()) / n) for a, b in zip(data1, data2))\n    \n    # Calculate the denominator\n    denominator = math.sqrt(sum((data1_rank[a] - sum(data1_rank.values()) / n) ** 2 for a in data1) * sum((data2_rank[b] - sum(data2_rank.values()) / n) ** 2 for b in data2))\n    \n    # Validate if denominator is zero\n    if denominator == 0: \n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # sort data\n    sorted_data1 = sorted(data1)\n    sorted_data2 = sorted(data2)\n\n    # get ranks\n    ranked_data1 = [sorted_data1.index(d)+1 for d in data1]\n    ranked_data2 = [sorted_data2.index(d)+1 for d in data2]\n\n    # get average ranks\n    avg_rank1 = sum(ranked_data1) / n\n    avg_rank2 = sum(ranked_data2) / n\n\n    # numerator\n    numerator = sum((r1 - avg_rank1) * (r2 - avg_rank2) for r1, r2 in zip(ranked_data1, ranked_data2))\n    \n    # denominator\n    std_dev1 = math.sqrt(sum((r - avg_rank1) ** 2 for r in ranked_data1))\n    std_dev2 = math.sqrt(sum((r - avg_rank2) ** 2 for r in ranked_data2))\n    denominator = std_dev1 * std_dev2\n\n    # correlation coefficient\n    correlation_coefficient = numerator / denominator if denominator else 0\n\n    return correlation_coefficient",
                true
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Calculate the mean rank for data1\n    ranked_data1 = sorted([rank for rank in enumerate(sorted((x for x in data1), reverse=True))], key=lambda x: x[1])\n    mean_rank_1 = sum(rank[0] for rank in ranked_data1) / n\n    \n    # Calculate the mean rank for data2\n    ranked_data2 = sorted([rank for rank in enumerate(sorted((x for x in data2), reverse=True))], key=lambda x: x[1])\n    mean_rank_2 = sum(rank[0] for rank in ranked_data2) / n\n    \n    # Calculate the rank differences\n    rank_diffs_1 = [rank[0] - mean_rank_1 for rank in ranked_data1]\n    rank_diffs_2 = [rank[0] - mean_rank_2 for rank in ranked_data2]\n    \n    # Calculate the numerator\n    numerator = sum([d1 * d2 for d1, d2 in zip(rank_diffs_1, rank_diffs_2)])\n    \n    # Check for the denominator\n    std_dev_rank_1 = math.sqrt(sum([d**2 for d in rank_diffs_1]) / n)\n    std_dev_rank_2 = math.sqrt(sum([d**2 for d in rank_diffs_2]) / n)\n    denominator = std_dev_rank_1 * std_dev_rank_2\n\n    # Calculate the correlation coefficient\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    rank_sum1 = sum(sorted(range(1, n+1), key=lambda x: data1[x-1]))\n    rank_sum2 = sum(sorted(range(1, n+1), key=lambda x: data2[x-1]))\n    mean_rank1 = rank_sum1 / n\n    mean_rank2 = rank_sum2 / n\n    rank_diff_sum1 = sum([(data1[i]-mean_rank1)**2 for i in range(n)])\n    rank_diff_sum2 = sum([(data2[i]-mean_rank2)**2 for i in range(n)])\n    std_dev_rank1 = (rank_diff_sum1 / n)**0.5\n    std_dev_rank2 = (rank_diff_sum2 / n)**0.5\n    if std_dev_rank1*std_dev_rank2 == 0:\n        return 0\n    return sum([(data1[i]-mean_rank1)*(data2[i]-mean_rank2) for i in range(n)]) / (std_dev_rank1*std_dev_rank2)",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Determine the Spearman correlation coefficient for two datasets 'data1' and 'data2'. Sort and rank the original entries in each list, captured in 'ranked_data1' and 'ranked_data2'. Compute the mean rank by summing up the ranks and dividing by 'n'. The numerator is obtained by summing the multiplied differences of each data's rank from their mean across both data sets. For the denominator, the product of the standard deviations of rankings, square the sum of the rank differences from their means, take the square root of these sums, and multiply them. Finally, divide the numerator by the denominator to get the correlation coefficient, or return zero if the denominator is zero.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    if len(data1) != len(data2):\n        return \"The two data sets must have the same length.\"\n\n    # Ranking the data\n    ranked_data1 = [sorted(data1).index(i) for i in data1]\n    ranked_data2 = [sorted(data2).index(i) for i in data2]\n\n    # Calculating mean rank\n    mean_rank_data1 = sum(ranked_data1) / len(ranked_data1)\n    mean_rank_data2 = sum(ranked_data2) / len(ranked_data2)\n\n    # Calculating the numerator\n    numerator = sum([(ranked_data1[i] - mean_rank_data1) * (ranked_data2[i] - mean_rank_data2) for i in range(len(data1))])\n    \n    # Calculating the denominator\n    denominator = math.sqrt(sum([(ranked_data1[i] - mean_rank_data1)**2 for i in range(len(data1))]) * sum([(ranked_data2[i] - mean_rank_data2)**2 for i in range(len(data1))]))\n\n    # If the denominator is zero, return 0\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create rank lists for data1 and data2\n    ranked_data1 = [sorted(data1, reverse=True).index(i) + 1 for i in data1]\n    ranked_data2 = [sorted(data2, reverse=True).index(i) + 1 for i in data2]\n\n    # Calculate mean rank for data1 and data2\n    mean_rank_data1 = sum(ranked_data1) / n\n    mean_rank_data2 = sum(ranked_data2) / n\n\n    # Calculate numerator and denominator for correlation coefficient\n    numerator = sum([(ranked_data1[i] - mean_rank_data1) * (ranked_data2[i] - mean_rank_data2) for i in range(n)])\n    denominator = math.sqrt(sum([(ranked_data1[i] - mean_rank_data1) ** 2 for i in range(n)]) * sum([(ranked_data2[i] - mean_rank_data2) ** 2 for i in range(n)]))\n\n    # Handle the case where the denominator is zero\n    if denominator == 0:\n        return 0\n\n    # Calculate and return the correlation coefficient\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # sort and rank both data lists\n    ranked_data1 = sorted([(value, rank) for rank, value in enumerate(sorted(data1))])\n    ranked_data2 = sorted([(value, rank) for rank, value in enumerate(sorted(data2))])\n\n    # calculate mean rank\n    mean_rank1 = sum([rank for value, rank in ranked_data1]) / n\n    mean_rank2 = sum([rank for value, rank in ranked_data2]) / n\n\n    # calculate numerator and denominator\n    numerator = sum([(rank1 - mean_rank1) * (rank2 - mean_rank2) for (_, rank1), (_, rank2) in zip(ranked_data1, ranked_data2)])\n    denominator = math.sqrt(sum([(rank1 - mean_rank1) ** 2 for (_, rank1) in ranked_data1]) * sum([(rank2 - mean_rank2) ** 2 for (_, rank2) in ranked_data2]))\n\n    # calculate correlation coefficient or return zero if denominator is zero\n    correlation_coefficient = numerator / denominator if denominator != 0 else 0\n\n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Calculate the ranks for each list\n    ranked_data1 = {x: i+1 for i, x in enumerate(sorted(data1))}\n    ranked_data2 = {x: i+1 for i, x in enumerate(sorted(data2))}\n\n    # Calculate the mean rank of each dataset\n    mean_rank1 = sum(ranked_data1.values()) / n\n    mean_rank2 = sum(ranked_data2.values()) / n\n\n    # Calculate the numerator\n    numerator = sum((ranked_data1[x] - mean_rank1) * (ranked_data2[y] - mean_rank2) for x, y in zip(data1, data2))\n\n    # Calculate the denominator\n    denominator = math.sqrt(sum((ranked_data1[x] - mean_rank1)**2 for x in data1) * sum((ranked_data2[y] - mean_rank2)**2 for y in data2))\n\n    # Divide numerator by denominator if denominator is not zero, otherwise return 0\n    if denominator:\n        return numerator / denominator\n    else:\n        return 0",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    rank_sum1 = sum(rank for rank in range(1, n + 1))\n    rank_sum2 = sum(rank for rank in range(1, n + 1))\n\n    for i in range(n):\n        for j in range(i + 1, n):\n            if data1[i] > data1[j]:\n                rank_sum1 += 1\n            if data2[i] > data2[j]:\n                rank_sum2 += 1\n\n    mean_rank1 = rank_sum1 / n\n    mean_rank2 = rank_sum2 / n\n\n    numerator = sum((rank - mean_rank1) * (rank - mean_rank2) for rank in range(1, n + 1))\n\n    denominator = math.sqrt(\n        sum((rank - mean_rank1) ** 2 for rank in range(1, n + 1)) *\n        sum((rank - mean_rank2) ** 2 for rank in range(1, n + 1)))\n\n    if denominator == 0:\n        return 0\n\n    return numerator / denominator",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    \"\"\"\n    Calculate the Spearman correlation coefficient from two datasets 'data1' and 'data2'. Each dataset must first be sorted and their original items ranked accordingly in 'ranked_data1' and 'ranked_data2'. Calculate the mean rank of each dataset by dividing the total ranks by 'n'. For computing the numerator, add the products of the differences from the mean rank for each entry across both datasets. Find the denominator by multiplying the square roots of the sums of squared differences of the ranks from their average for each list. The correlation coefficient results from dividing the numerator by the denominator, or zero if the denominator is zero.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    n = len(data1)\n    \n    # Sort the data and get the ranks\n    sorted_data1 = sorted(data1)\n    sorted_data2 = sorted(data2)\n    ranked_data1 = [sorted_data1.index(i) + 1 for i in data1]\n    ranked_data2 = [sorted_data2.index(i) + 1 for i in data2]\n    \n    # Calculate the mean rank\n    mean_rank1 = sum(ranked_data1) / n\n    mean_rank2 = sum(ranked_data2) / n\n    \n    # Calculate the numerator and denominator\n    numerator = sum((r1 - mean_rank1) * (r2 - mean_rank2) for r1, r2 in zip(ranked_data1, ranked_data2))\n    denominator = math.sqrt(sum((r - mean_rank1) ** 2 for r in ranked_data1) * sum((r - mean_rank2) ** 2 for r in ranked_data2))\n    \n    # Avoid division by zero\n    if denominator == 0:\n        return 0\n\n    # Calculate the correlation coefficient\n    correlation_coefficient = numerator / denominator\n    \n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n    \n    # Create ranked lists for both datasets\n    ranked_data1 = [(x,i+1) for i,x in sorted(enumerate(data1),key = lambda x:x[1])]\n    ranked_data2 = [(x,i+1) for i,x in sorted(enumerate(data2),key = lambda x:x[1])]\n    \n    # Find mean rank of each dataset\n    mean_rank_data1 = sum(rank for _,rank in ranked_data1)/n\n    mean_rank_data2 = sum(rank for _,rank in ranked_data2)/n\n    \n    # Calculate numerator\n    numerator = sum((rank[0]-mean_rank_data1)*(rank[1]-mean_rank_data2) for rank in zip(ranked_data1,ranked_data2))\n    \n    # Calculate denominator\n    denominator = math.sqrt(sum((rank[0]-mean_rank_data1)**2 for rank in ranked_data1) * sum((rank[0]-mean_rank_data2)**2 for rank in ranked_data2))\n    \n    # Avoid division by zero and compute correlation coefficient\n    correlation_coefficient = numerator/denominator if denominator != 0 else 0\n    \n    return correlation_coefficient",
                false
            ],
            [
                "def correlation_coefficient_rank(data1, data2):\n    n = len(data1)\n\n    # sorting and rank the datasets\n    sorted_data1 = sorted(data1)\n    sorted_data2 = sorted(data2)\n\n    ranked_data1 = [sorted_data1.index(i) for i in data1]\n    ranked_data2 = [sorted_data2.index(i) for i in data2]\n\n    # calculating mean rank\n    mean_rank_data1 = sum(ranked_data1) / n\n    mean_rank_data2 = sum(ranked_data2) / n\n\n    # calculating numerator\n    numerator = sum((ranked_data1[i] - mean_rank_data1) * (ranked_data2[i] - mean_rank_data2) for i in range(n))\n\n    # calculating denominator\n    denominator = math.sqrt(sum((ranked_data1[i] - mean_rank_data1) ** 2 for i in range(n))) * math.sqrt(sum((ranked_data2[i] - mean_rank_data2) ** 2 for i in range(n)))\n\n    # calculating correlation coefficient\n    if denominator == 0:\n        correlation_coefficient = 0\n    else:\n        correlation_coefficient = numerator / denominator\n\n    return correlation_coefficient",
                true
            ]
        ]
    },
    "2": {
        "level 1": [
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a list or a tuple.')\n    if isinstance(data, tuple):\n        data = [data]\n    total_recall = 0\n    precisions = []\n    for recalls_nums in data:\n        recalls = recalls_nums[0]\n        nums = recalls_nums[1]\n        recall_without_discount = np.sum(recalls) / nums\n        index = np.argmax(recalls)\n        recall = recall_without_discount * (1 - discount_rate) ** index\n        total_recall += recall\n        precisions.append(recalls)\n    return total_recall / len(data), precisions",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrr_list = []\n    if isinstance(data, list):\n        for data_element in data:\n            mrr_list.append(discounted_mrr(data_element, discount_rate))\n        return np.mean(mrr_list), mrr_list\n    else:\n        actual, ground_truth_num = data\n        reciprocal_rank = 0\n        for i, pred in enumerate(actual):\n            if pred == ground_truth_num:\n                reciprocal_rank = 1. / (i + 1)\n                break\n        return reciprocal_rank * (1 - discount_rate) + (1 - reciprocal_rank) * discount_rate, [reciprocal_rank]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Calculate the discounted Mean Reciprocal Rank \"MRR\" of the input data which discounts the rank of the first relevant result. Use the input \"data\", which can be a tuple or a list of tuples, and \"discount_rate\" to determine the discounting effect. The function should return a tuple: the first element being the mean recall if \"data\" is a list, or the recall if \"data\" is a single tuple; the second element should be a list of recall values for each tuple in the input \"data\".\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n     ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    total_discounted_mrr = 0\n    recall_values = []\n    if isinstance(data, list):\n        for item in data:\n            mrr = MetricsCalculator2.discounted_mrr(item, discount_rate)\n            total_discounted_mrr += mrr\n            recall_values.append(mrr)\n        return total_discounted_mrr / len(data), recall_values\n    else:\n        mrr = 0\n        for i in range(data[1]):\n            if data[0][i] == 1:\n                mrr = 1 / (i + 1) - discount_rate\n                break\n        return mrr, [mrr]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data[0], list):\n        mrr_list = []\n        for d in data:\n            mrr_list.append(discounted_mrr(d, discount_rate))\n        return np.mean(mrr_list), mrr_list\n\n    total_num = len(data[0])\n    correct_num = sum(data[0])\n    ranks = np.arange(1, total_num + 1)\n    discount = np.log(ranks) / np.log(1.0 + discount_rate)\n    discounted_ranks = np.minimum(ranks, discount)\n    mrr = correct_num / np.sum(discounted_ranks)\n    return mrr, [mrr]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs, precisions = [], []\n    if isinstance(data[0], list):\n        for d in data:\n            top_k_relevant = sum(d[0][:d[1]])\n            mrrs.append((top_k_relevant / d[1]) / (1 - discount_rate) * discount_rate)\n            precisions.append(top_k_relevant / len(d[0]))\n    else:\n        top_k_relevant = sum(data[0][:data[1]])\n        mrrs.append((top_k_relevant / data[1]) / (1 - discount_rate) * discount_rate)\n        precisions.append(top_k_relevant / len(data[0]))\n    return np.mean(mrrs), precisions",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a list or a tuple.')\n    if isinstance(data, tuple):\n        data = [data]\n    total_recall = 0.0\n    precision_list = []\n    for ranking_list, total_num in data:\n        if not isinstance(ranking_list, list):\n            raise ValueError('Each tuple or list must represent a ranking list.')\n        if len(ranking_list) != total_num:\n            raise ValueError('The length of ranking list must equal to total ground truth num.')\n        if 1 not in ranking_list:\n            raise ValueError('No correct answer in the ranking list.')\n        rank = ranking_list.index(1) + 1\n        if rank == 0:\n            return 0, [0] * len(data)\n        else:\n            total_recall += 1.0 / rank * discount_rate ** (rank - 1)\n            precision_list.append(1.0 / rank * sum(ranking_list[:rank]))\n    if total_recall == 0:\n        return 0, precision_list\n    else:\n        return total_recall / len(data), precision_list",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrr_sum = 0\n    precisions = []\n    if isinstance(data, list):   # list of tuple\n        for rank, (query, total) in enumerate(data, 1):\n            rr = 0\n            for rank_i, result in enumerate(query, 1):\n                if result:\n                    rr = 1.0 / rank_i  # Reciprocal Rank\n                    break\n            mrr_sum += rr / (1 + discount_rate) ** rank  # Discounted MRR\n            precisions.append(rr)\n        mrr_avg = mrr_sum / len(data)  # Average MRR\n    else:   # tuple\n        rank, (query, total) = data\n        for rank_i, result in enumerate(query, 1):\n            if result:\n                mrr_avg = 1.0 / rank_i  # Reciprocal Rank\n                break\n        for rank_i, result in enumerate(query, 1):\n            precisions.append(1 if result else 0)\n    return mrr_avg, precisions",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Compute the discounted Mean Reciprocal Rank (MRR) for given input 'data' either as a tuple or list of tuples, using the 'discount_rate' for discounting. Return a tuple where the first element is the average recall if 'data' is a list, or the individual recall if 'data' is a tuple; the second element should be a list of recall values corresponding to each tuple in 'data'.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n     ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError('data must be a list or a tuple')\n\n    if isinstance(data, list):\n        if not all(isinstance(i, tuple) for i in data):\n            raise ValueError('each element in list should be a tuple')\n\n    if discount_rate < 0 or discount_rate > 1:\n        raise ValueError('discount_rate must be between 0 and 1')\n\n    if isinstance(data, tuple):\n        data = [data]\n\n    rr_values = []\n    for i, single_data in enumerate(data):\n        if not isinstance(single_data, tuple) or len(single_data) != 2:\n            raise ValueError('each element in list should be a tuple: (actual result, ground truth num)')\n        actual_result = single_data[0]\n        ground_truth_num = single_data[1]\n\n        if not isinstance(actual_result, (list, tuple)) or len(actual_result) != ground_truth_num:\n            raise ValueError('actual result should be a list or tuple with length equal to ground truth num')\n\n        ground_truth_idx = actual_result.index(1) + 1\n        rr_value = 1 / ground_truth_idx\n        rr_value = rr_value * (1 - discount_rate) + (discount_rate * (1 if ground_truth_idx == 1 else 0))\n        \n        rr_values.append(rr_value)\n\n    return (np.mean(rr_values), rr_values)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data[0], list):\n        mrr_list = []\n        for d in data:\n            mrr_list.append(discounted_mrr(d, discount_rate))\n        return np.mean(mrr_list), mrr_list\n\n    total_num = len(data[0])\n    correct_num = sum(data[0])\n    ranks = np.arange(1, total_num + 1)\n    discount = np.log(ranks) / np.log(1 + discount_rate)\n    mrr = (1 / ranks[correct_num - 1]) * discount[correct_num - 1]\n    return mrr, [mrr]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs, precisions = [], []\n    for item in data:\n        ranks = [1/i for i, x in enumerate(item[0], 1) if x == 1]  # calculate ranks for each correct answer\n        if not ranks:  # if no correct answers, rank is len(item[0])+1, which is inf\n            mrrs.append(1/(item[1]+1))  # recall for this item\n            precisions.append(0)  # precision for this item\n        else:\n            rank = min(ranks)  # the rank of the best answer\n            mrr = rank / (item[1] + 1)  # calculate MRR\n            precision = 1/len(ranks)  # calculate precision\n            mrrs.append(discount_rate * mrr + (1 - discount_rate) * rank)  # discount MRR\n            precisions.append(precision)  # add precision to list\n    return sum(mrrs)/len(mrrs), precisions  # return average MRR and precision list",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a tuple or a list.')\n    if isinstance(data, tuple):\n        data = [data]\n    total_recall = 0.0\n    precision_list = []\n    for ranking_list in data:\n        if not isinstance(ranking_list, tuple) or len(ranking_list) != 2:\n            raise ValueError('Each list of data must be a tuple of 2 elements: ranking list and total ground truth.')\n        ranking, total_num = ranking_list\n        if not isinstance(ranking, list) or not all(isinstance(i, int) and i in [0, 1] for i in ranking):\n            raise ValueError('The ranking list must be a list of 0s and 1s.')\n        if not isinstance(total_num, int) or total_num < 0:\n            raise ValueError('The total ground truth should be a non-negative integer.')\n        if total_num == 0: continue  # if no ground truth, recall is 0\n        actual_num = sum(ranking)\n        recall = min(1.0, actual_num / total_num)\n        if actual_num == 0:\n            precison = 0.0\n        else:\n            precison = recall / actual_num\n        precision_list.append(precison)\n        total_recall += recall\n    if len(data) == 0:\n        raise ValueError('There is no valid list in input.')\n    total_recall /= len(data)\n    return total_recall, precision_list",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for i, result in enumerate(data):\n        data_mrr, _ = MetricsCalculator2.mrr(result)\n        if data_mrr:\n            mrrs.append(1.0 / (data_mrr * discount_rate))\n        else:\n            mrrs.append(0.0)\n    return sum(mrrs) / len(mrrs), mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Determine the discounted Mean Reciprocal Rank 'MRR' by using 'data' as either a tuple or a list of tuples, and apply the 'discount_rate' to affect the ranking. The function should output a tuple: if 'data' is a list then the average recall otherwise just the recall for a tuple, along with a list of recalls for each tuple in 'data'.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n         ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    recalls = []\n    for result in data:\n        if isinstance(result, tuple):\n            result, total_num = result\n            rank = result.index(1) + 1\n            discount_rate = np.max([discount_rate, rank])\n            recall = 1 / (1 + discount_rate)\n            recalls.append(recall)\n        else:\n            total_num = result[1]\n            result = result[0]\n            rank = result.index(1) + 1\n            discount_rate = np.max([discount_rate, rank])\n            recall = 1 / (1 + discount_rate)\n            recalls.append(recall)\n    if len(data) == 1:\n        return recalls[0], [recalls[0]]\n    return sum(recalls) / len(recalls), recalls",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data[0], list):\n        recalls = [1 / (rank if rank != 0 else 1) ** discount_rate for _, rank in data]\n        return np.sum(recalls), recalls\n    else:\n        rank = data[1]\n        return 1 / (rank if rank != 0 else 1) ** discount_rate, [1 / (rank if rank != 0 else 1) ** discount_rate]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs, precisions = [], []\n    if isinstance(data[0], list):\n        for d in data:\n            mrrs.append(MetricsCalculator2().mrr(d) / discount_rate ** (d[1] - 1))\n    else:\n        for d in data:\n            mrr, precision = MetricsCalculator2().mrr(d[0]), MetricsCalculator2().map(d[0])\n            mrrs.append(mrr / (discount_rate ** (d[1] - np.argmax(d[0])) if d[1] != 1 and d[1] - np.argmax(d[0]) != 0 else 1))\n            precisions.append(precision)\n    return np.mean(mrrs), precisions",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a list or a tuple.')\n    if isinstance(data, tuple):\n        data = [data]\n    total_recall = []\n    for item in data:\n        recalls = [1 / (index + 1) for index, value in enumerate(item[0]) if value == 1]\n        total_recall.append(sum(recalls))\n    mrr = [recall / (index + 1) ** discount_rate for index, recall in enumerate(total_recall)]\n    return np.mean(mrr), mrr",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for query in data:\n        if isinstance(query, tuple):\n            query, total_num = query\n            ranks = query.argsort().argsort() + 1\n            mrr = [1.0 / rank for rank in ranks if rank > 0][0]\n            mrrs.append(mrr)\n        else:\n            if isinstance(query, list):\n                query = [1 if i == query.index(max(query)) else 0 for i in range(len(query))]\n            ranks = query.argsort().argsort() + 1\n            discount_positions = [1.0 / (rank - discount_rate) if rank > discount_rate else 1.0 for rank in ranks]\n            mrrs.append(discount_positions[0] if len(discount_positions) > 0 else 0)\n    mean_mrrs = np.mean(mrrs)\n    return mean_mrrs, mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Calculate the discounted Mean Reciprocal Rank (MRR) using a 'discount_rate' where the 'data' is either a single tuple or a list of tuples. The function must return a tuple: first element being the mean recall for 'data' as a list or recall for a single tuple, and the second element will be the list of recalls for each element of 'data'.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n         ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    recalls = []\n    for result in data:\n        mrr = 0\n        rank = 0\n        for r in result[0]:\n            rank += 1\n            if r == 1:\n                mrr = 1 / rank\n                break\n        if rank != 0:\n            mrr = mrr / (1 - discount_rate)\n        recalls.append(mrr)\n    final_recall = sum(recalls) / len(recalls)\n    return final_recall, recalls",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, list):\n        recalls = []\n        for item in data:\n            recalls.append(MetricsCalculator2.discounted_mrr(item, discount_rate))\n        return sum(recalls) / len(recalls), recalls\n    else:\n        ranks = np.where(data[0] == 1)[0]\n        if len(ranks) == 0:\n            return 0, [0]\n        else:\n            return 1 / (1 + discount_rate), [1 / (1 + discount_rate)]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs, precisions = [], []\n    if isinstance(data[0], list):\n        for d in data:\n            mrr, precision = MetricsCalculator2._calculate_mrr_precision(d, discount_rate)\n            mrrs.append(mrr)\n            precisions.append(precision)\n        return sum(mrrs) / len(data), precisions\n    else:\n        mrr, precision = MetricsCalculator2._calculate_mrr_precision(data, discount_rate)\n        return mrr, precision\n\ndef _calculate_mrr_precision(data, discount_rate):\n    actual, total_ground = data[0], data[1]\n    rr = [1 / i for i, a in enumerate(actual, start=1) if a == 1]  # rank\n    if not rr:  # if the first item is not in top 1\n        return 0, 0\n    mrr = (1 - discount_rate) / discount_rate * sum(rr) / len(rr)  # discounted MRR\n    precision = sum(actual[:min(len(actual), total_ground)]) / total_ground  # precision\n    return mrr, precision",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a list or a tuple.')\n    if isinstance(data, tuple):\n        data = [data]\n    total_recalls = []\n    for item in data:\n        recalls = [1 / (index + 1) for index, value in enumerate(item[0]) if value == 1]\n        total_recalls.append(sum(recalls))\n    mrr = sum(total_recalls) / len(total_recalls)\n    discounted_mrr = mrr * (1 - discount_rate)\n    return discounted_mrr, total_recalls",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for query, total_relevant in data:\n        # calculate MRR for each query\n        rank = query.index(1) + 1  # 1-indexed rank of first relevant item\n        mrr = 1 / rank  # simple reciprocal rank\n        # apply discount\n        mrr *= (1 - discount_rate) ** (rank - 1)\n        mrrs.append(mrr)\n    # average over all queries\n    return np.mean(mrrs), mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    For the input 'data', which could be either a tuple or a list of tuples, calculate the discounted Mean Reciprocal Rank (MRR) using 'discount_rate'. Output a tuple: mean recall if 'data' is a list, or the single recall if it's a tuple. Include a list of calculated recalls for all tuples in 'data'.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n    ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    if isinstance(data, list):\n        total_recall = 0\n        precisions = []\n        for item in data:\n            recall, _ = discounted_mrr(item, discount_rate)\n            total_recall += recall\n            precisions.append(recall)\n        return total_recall / len(data), precisions\n\n    ranks = [i for i, value in enumerate(data[0]) if value == 1]\n    if not ranks:\n        return 0.0, [0.0]  # return 0 recall and precision if no correct answer\n\n    rank = ranks[0]\n    discounted_rank = min(1, rank / discount_rate)\n    recall = 1 / discounted_rank\n    precision = recall / data[1]\n    return recall, [precision]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mean_recall = 0\n    recalls = []\n    if isinstance(data[0], list):\n        for sub_data in data:\n            recall, _ = MetricsCalculator2.discounted_mrr(sub_data, discount_rate)\n            recalls.append(recall)\n        return np.mean(recalls), recalls\n\n    else:\n        for actual, ground_truth_size in data:\n            if 0 in actual[:ground_truth_size]:\n                # If the first item in actual is a correct answer, the recall is 1\n                recall = 1\n            else:\n                # If the first item in actual is a wrong answer, the recall is the discounted rate\n                recall = discount_rate\n            mean_recall += recall\n        return mean_recall / len(data), recalls",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs, recalls = [], []\n    if isinstance(data[0], list):\n        for d in data:\n            top_k_relevant = sum(d[:d[1]])\n            mrr = top_k_relevant / min(d[1], len(d[0]))\n            mrrs.append(mrr)\n            recall = top_k_relevant / d[1]\n            recall = recall / (1 - discount_rate) if recall > 0 else 0\n            recalls.append(recall)\n        return sum(recalls) / len(recalls), recalls\n    else:\n        top_k_relevant = sum(data[:data[1]])\n        mrr = top_k_relevant / min(data[1], len(data[0]))\n        recall = top_k_relevant / data[1]\n        recall = recall / (1 - discount_rate) if recall > 0 else 0\n        return recall, [recall]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a tuple or a list.')\n    if isinstance(data, tuple):\n        data = [data]\n    total_recall = 0\n    precisions = []\n    for recalls in data:\n        actual_res = recalls[0]\n        ground_truth_num = recalls[1]\n        if ground_truth_num == 0:\n            return 0, [0] * len(data)\n        rank = 0\n        for i, res in enumerate(actual_res):\n            if res == 1:\n                rank += 1\n                break\n        recall = 1. / (rank + discount_rate)\n        total_recall += recall\n        precisions.append(recall)\n    if len(data) > 0:\n        return total_recall / len(data), precisions\n    else:\n        return 0, [0] * len(data)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for query in data:\n        result = query[0]\n        total_items = query[1]\n        rr = 0\n        discount_factor = 1\n        for rank, r in enumerate(result):\n            if r == 1:\n                rr = discount_factor / (rank + 1)\n                break\n            discount_factor *= (1 - discount_rate)\n        mrrs.append(rr)\n    if len(data) == 1:\n        return (mrrs[0], [mrrs[0]])\n    else:\n        return (np.mean(mrrs), mrrs)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Evaluate the Mean Reciprocal Rank (MRR) after discounting with 'discount_rate', where the input 'data' can be a tuple or a collection of tuples. Return a tuple in which the first element is either the mean recall for a list or specific recall for a tuple, and the second is a list of recall measurements for each tuple in 'data'.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n     ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    total_mrr = 0.0\n    mrr_list = []\n    if isinstance(data, list):\n        for sample in data:\n            mrr_list.append(MetricsCalculator2.discounted_mrr(sample, discount_rate))\n        return np.mean(mrr_list), mrr_list\n    else:\n        actual_result, ground_truth_num = data\n        rank_list = [i+1 for i, x in enumerate(actual_result) if x == 1]\n        if len(rank_list) > 0:\n            total_mrr = 1/rank_list[0]*(1-discount_rate) + discount_rate\n        return total_mrr, total_mrr",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mean_recall = 0.0\n    precision_scores = []\n    if type(data[0]) is list:  # if data is a list of lists\n        for each in data:\n            rr_score = MetricsCalculator2.discounted_mrr([each], discount_rate)\n            mean_recall += rr_score[0]\n            precision_scores.append(rr_score[1][0])\n        return mean_recall/len(data), precision_scores\n    else:  # if data is a list of tuples\n        for each in data:\n            actual, total_ground_truth = each\n            rank = 0\n            for i in actual:\n                rank += 1\n                if i == 1:\n                    break\n            if rank == 1:\n                mean_recall += 1.0\n            else:\n                mean_recall += 1.0/rank\n            precision_scores.append(rank)\n        return mean_recall/len(data), precision_scores",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs, precisions = [], []\n    for item in data:\n        ranks = [1/i for i, x in enumerate(item[0], 1) if x == 1]  # calculate ranks for each correct answer\n        if not ranks:  # if no correct answers, rank is len(item[0])+1, which is inf\n            mrrs.append(1/(item[1]+1))  # recall for this list is 0\n            precisions.append(0)\n        else:\n            mrr = sum(ranks)/len(ranks)  # calculate mean rank\n            mrr = mrr/(1-discount_rate) if mrr > discount_rate else 1  # apply discount\n            mrrs.append(mrr)\n            precisions.append(1/len(ranks) if mrr <= 1 else 1)  # calculate precision\n    if isinstance(data[0][0], list):\n        return np.mean(mrrs), precisions  # return average mrr and precision for all lists\n    return mrrs[0], precisions[0]  # return mrr and precision for one list",
                false
            ]
        ],
        "level 2": [
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a list or a tuple.')\n    if isinstance(data, tuple):\n        data = [data]\n    adjusted_mrrs = []\n    for datum in data:\n        if len(datum) != 2:\n            raise ValueError('Each element in the data tuple must contain exactly two elements')\n        sequence, relevant_count = datum\n        if not isinstance(sequence, (list, tuple)) or not all(isinstance(item, int) and item in [0, 1] for item in sequence):\n            raise ValueError('The sequence must be a list or tuple of 0s and 1s')\n        if not isinstance(relevant_count, int) or relevant_count <= 0:\n            raise ValueError('The relevant count must be a positive integer')\n        reciprocal_rank = 0\n        for rank, relevance in enumerate(sequence, start=1):\n            if relevance:\n                reciprocal_rank = 1 / rank * (1 - discount_rate)**rank\n                break\n        adjusted_mrrs.append(reciprocal_rank)\n    return np.mean(adjusted_mrrs) if len(adjusted_mrrs) > 1 else adjusted_mrrs[0], adjusted_mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for seq, total in data:\n        rank = 0\n        found = False\n        for val in seq:\n            if val == 1:\n                rank += 1\n                found = True\n            if found:\n                break\n                \n        if found:\n            mrrs.append(1/(rank-discount_rate))\n        else:\n            mrrs.append(0)\n    return np.mean(mrrs)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Calculate the discounted Mean Reciprocal Rank \"MRR\" of the input data by applying a \"discount_rate\" to the rank of the first relevant result found in the data. The \"data\" parameter should either be a single tuple representing a sequence of binary relevance (1s and 0s) alongside a count of total relevant items, or a list of such tuples. The function starts by verifying if \"data\" is a valid list or tuple, then processes each tuple by calculating the reciprocal rank of the first relevant item found, adjusted by the \"discount_rate\". It then either returns the adjusted reciprocal rank directly or computes the mean of these values if multiple tuples are provided. The second return value is always a list containing the adjusted reciprocal ranks for each tuple.\n    :param data: the data must be a tuple, list of tuple 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n    ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    if not data: return 0.0, []\n\n    if isinstance(data, list):\n        return np.mean([d[0] for d in data]), [d[0] for d in data]\n\n    if isinstance(data, tuple) and len(data) == 2 and isinstance(data[0], list) and isinstance(data[1], int):\n        ranks = [i+1 for i, x in enumerate(data[0]) if x == 1]\n        if ranks:\n            rank = ranks[0]\n            return rank * discount_rate, [rank * discount_rate]\n        else:\n            return 0.0, [0.0]\n    return None, []",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('\"data\" must be a list or tuple.')\n    if isinstance(data, tuple):\n        data = [data]\n    adjusted_ranks = []\n    for (relevance, total_relevant) in data:\n        rank = next((i for i, rel in enumerate(relevance) if rel==1), total_relevant)\n        adjusted_ranks.append(1/rank * (1-discount_rate) + discount_rate)\n    return np.mean(adjusted_ranks) if len(adjusted_ranks) > 1 else adjusted_ranks[0]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs, adjusted_mrrs = [], []\n    if isinstance(data, tuple):\n        data = [data]\n    for d in data:\n        result, total = d\n        rank = result.index(1) + 1\n        adjusted_mrr = (1.0 / rank) * (1.0 - discount_rate) if rank > 1 else 0\n        mrrs.append(1.0 / rank)\n        adjusted_mrrs.append(adjusted_mrr)\n    if len(mrrs) == 1:\n        return adjusted_mrrs[0], mrrs[0]\n    return np.mean(adjusted_mrrs), np.mean(mrrs)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a list or a tuple.')\n    if isinstance(data, tuple):\n        data = [data]\n    total_discounted_mrr = 0\n    discounted_mrr_list = []\n    for sequence, relevant_num in data:\n        # Check if all items in the sequence are binary\n        if not all(isinstance(item, int) and item in (0, 1) for item in sequence):\n            raise ValueError('All items in the sequence must be binary.')\n        # Calculate MRR\n        for index, item in enumerate(sequence):\n            if item == 1:  # find the rank of first relevant result\n                rank = index + 1\n                break\n        else:\n            # no relevant item found, return 0\n            discounted_mrr = 0\n        # discount the MRR\n        discounted_mrr = rank * discount_rate\n        total_discounted_mrr += discounted_mrr\n        discounted_mrr_list.append(discounted_mrr)\n    # Return the average discounted MRR\n    return total_discounted_mrr / len(data) if data else 0, discounted_mrr_list",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for seq, total in data:\n        rank = 0\n        for element in seq:\n            rank += 1\n            if element == 1:\n                mrrs.append((1 / rank) * discount_rate)\n                break\n    if len(mrrs) == 0:\n        return 0, []\n    else:\n        return sum(mrrs) / len(mrrs), mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Compute the discounted Mean Reciprocal Rank 'MRR' for given data using a 'discount_rate'. The 'data' should be either a list of tuples or a single tuple where each tuple consists of a sequence of binary relevance (0s and 1s) and an integer representing the total relevant items. The function first checks if 'data' is a list or tuple, processes each tuple to find the reciprocal rank of the first relevant result, multiplies it by the 'discount_rate', and returns either the single adjusted reciprocal rank or the average of these values plus a list of these adjusted values for all tuples.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n     ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    def _compute_discounted_mrr(t):\n        result, total_relevant = t\n        for i, r in enumerate(result, 1):\n            if r == 1:\n                return i * discount_rate\n        return 0\n\n    # If data is a list of tuples, compute MRR for each and return their average.\n    if isinstance(data, list):\n        return np.mean([_compute_discounted_mrr(t) for t in data])\n\n    # If data is a single tuple, return the computed MRR.\n    else:\n        return _compute_discounted_mrr(data)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, list):\n        return sum(1/len(item[0]) + 1/len(item[0])*discount_rate for item in data if any(item[0])) / len(data)\n    else:\n        ranks = [i+1 for i, x in enumerate(data[0]) if x==1]\n        if len(ranks)==0:\n            return 0\n        else:\n            return (1/ranks[0] + 1/ranks[0]*discount_rate)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if type(data) == tuple:\n        return MetricsCalculator2.discounted_mrr([data], discount_rate)[0]\n    else:\n        result = []\n        for sequence in data:\n            ranks = [np.where(sequence[0] == 1)[0][i] + 1 for i in range(sequence[1])]\n            mrr = sum(1.0 / rank for rank in ranks)\n            discounted_mrr = mrr * discount_rate\n            result.append((discounted_mrr, ranks))\n        return result[0] if len(result) == 1 else result",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a list or a tuple.')\n    if isinstance(data, tuple):\n        data = [data]\n    total_discounted_mrr = 0\n    individual_discounted_mrr_values = []\n    for item in data:\n        if not isinstance(item, tuple) or len(item) != 2 or not all(isinstance(i, int) for i in item) or not isinstance(item[1], int) or item[1] == 0:\n            raise ValueError('Each item in the data list must be a tuple of two integers, where the first one is the count of relevant items and the second one is the count total relevant items.')\n        correct_answer_index = np.nonzero(item[0])[0]\n        if len(correct_answer_index) == 0:\n            raise ValueError('No relevant items have been found in the input data.')\n        first_relevant_item_rank = correct_answer_index[0] + 1\n        discounted_mrr_value = first_relevant_item_rank / (1 + discount_rate * first_relevant_item_rank)\n        individual_discounted_mrr_values.append(discounted_mrr_value)\n        total_discounted_mrr += discounted_mrr_value\n    return total_discounted_mrr / len(data), individual_discounted_mrr_values",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for seq, total in data:\n        rank = 0\n        found = False\n        for val in seq:\n            if val == 1 and not found:  # If found first relevant item\n                rank += 1\n                found = True\n            if found:  # If found relevant items after first\n                rank += 1\n        mrr = (1.0 - discount_rate) ** rank if found else 0.0\n        mrrs.append(mrr)\n    return np.mean(mrrs)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Determine the discounted Mean Reciprocal Rank 'MRR' for given 'data' adjusted by a 'discount_rate'. 'data' should be either a single tuple containing a sequence of binary relevance and the count of total relevant entries, or a list with such tuples. The function checks if 'data' is an appropriate structure, then for each tuple, it computes the reciprocal rank for the earliest relevant item, adjusts this by the 'discount_rate', and outputs either this value directly or the mean of these ranks along with a list of individual ranks adjusted for each tuple.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n     ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    # Check if data is a single tuple or a list of tuples\n    if isinstance(data, tuple):\n        data = [data]\n    if not all(isinstance(x, tuple) and len(x) == 2 for x in data):\n        raise ValueError(\"Invalid input format.\")\n\n    # Calculate MRR for each tuple\n    mrr_list = []\n    for seq, total_relevant in data:\n        if not isinstance(seq, list) or not all(isinstance(i, int) and i in [0, 1] for i in seq):\n            raise ValueError(\"Invalid binary relevance sequence.\")\n        if not isinstance(total_relevant, int) or total_relevant < 1:\n            raise ValueError(\"Invalid total relevant count.\")\n\n        # If no relevant items found, MRR is defined as 0\n        if total_relevant == 0:\n            mrr_list.append(0)\n        else:\n            # Find first relevant item\n            first_relevant_index = seq.index(1)\n            # Calculate reciprocal rank and apply discount\n            mrr = 1 / (first_relevant_index + 1) * (1 - discount_rate)\n            mrr_list.append(mrr)\n\n    return np.mean(mrr_list), mrr_list",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (tuple, list)):\n        raise ValueError(\"Input data must be a tuple or list\")\n    \n    if isinstance(data[0], (tuple, list)):\n        # Case: data is a list of tuples\n        mrrs = []\n        for d in data:\n            mrr = MetricsCalculator2.discounted_mrr(d, discount_rate)\n            mrrs.append(mrr)\n        return np.mean(mrrs)\n    \n    # Case: data is a single tuple\n    ranks = []\n    for i, rel in enumerate(data[0], 1):\n        if rel == 1:\n            rank = i\n            break\n    else:\n        # No relevant item found\n        return 0\n    \n    mrr = (1 / rank) * discount_rate\n    return mrr",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (tuple, list)):\n        raise ValueError(\"data should be a tuple or a list\")\n\n    if isinstance(data[0], (tuple, list)):  # list of tuples\n        return [MetricsCalculator2._discounted_mrr_tuple(t, discount_rate) for t in data]\n    elif isinstance(data[0], int):  # single tuple\n        return MetricsCalculator2._discounted_mrr_tuple(data, discount_rate)\n    else:\n        raise ValueError(\"Invalid input format\")\n\ndef _discounted_mrr_tuple(data, discount_rate):\n    if not isinstance(data[0], (list, tuple)) or not isinstance(data[1], int):\n        raise ValueError(\"Invalid input format for discounted_mrr_tuple\")\n\n    ranks = []\n    for i, relevance in enumerate(data[0], 1):\n        if relevance:  # first relevant item\n            rank = 1 / i * (1 - discount_rate) + discount_rate\n            ranks.append(rank)\n            break\n    else:  # no relevant item found (i.e., list is all zeros)\n        return 0.0\n\n    return np.mean(ranks)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a list or a tuple.')\n    if isinstance(data, tuple):\n        data = [data]\n    total_discounted_mrr = 0\n    individual_discounted_mrr_values = []\n    for item in data:\n        if not isinstance(item, tuple) or len(item) != 2 or not isinstance(item[0], list) or not isinstance(item[1], int):\n            raise ValueError('Each tuple in the input data should be of the form ([1, 0, ...], total_relevant_items).')\n        if not all(isinstance(i, int) and i in (0, 1) for i in item[0]):\n            raise ValueError('The binary sequence in each tuple should only contain 1s and 0s.')\n        ranking = item[0][::-1].index(1) + 1\n        if ranking > item[1]:\n            ranking = item[1]\n        discounted_mrr = 1 / ranking * (1 - discount_rate) ** (ranking - 1)\n        total_discounted_mrr += discounted_mrr\n        individual_discounted_mrr_values.append(discounted_mrr)\n        return total_discounted_mrr / len(data), individual_discounted_mrr_values if len(data) > 1 else individual_discounted_mrr_values[0]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrr_list = []\n    if isinstance(data, list):\n        for data_point in data:\n            rank_list = [1/i if i != 0 else 0 for i in range(len(data_point[0])) if data_point[0][i] == 1]\n            mrr = sum(rank_list)/len(rank_list) if rank_list else 0\n            discounted_mrr = mrr/(1-discount_rate) if mrr > 0 else 0\n            mrr_list.append(discounted_mrr)\n        if len(mrr_list) > 0:\n            mrr_list = sum(mrr_list)/len(mrr_list)\n    elif isinstance(data, tuple):\n        rank_list = [1/i if i != 0 else 0 for i in range(len(data[0])) if data[0][i] == 1]\n        mrr = sum(rank_list)/len(rank_list) if rank_list else 0\n        discounted_mrr = mrr/(1-discount_rate) if mrr > 0 else 0\n        mrr_list = discounted_mrr\n    return mrr_list",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Compute the adjusted Mean Reciprocal Rank 'MRR' using a 'discount_rate' from 'data' input. This 'data' can either be one tuple or a collection of tuples, each with a binary sequence (1s and 0s) and a number representing total relevant data points. The function ensures 'data' is a valid structure, then calculates the adjusted reciprocal rank of the first encountered relevant result by the given 'discount_rate', and finally, returns either this single value or the average of these values, alongside a list of the individual adjusted values for each data point.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n     ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    if isinstance(data, list):\n        results = []\n        for item in data:\n            result = discounted_mrr(item, discount_rate)\n            results.append(result)\n        return np.mean([r[0] for r in results]), [r[1] for r in results]\n\n    actual_result, total_num = data\n    ranks = [i+1 for i, v in enumerate(actual_result) if v == 1]\n    if not ranks:\n        return 0, []\n    mrr = np.reciprocal(ranks[0])\n    adjusted_mrr = mrr * (1 - discount_rate)\n    return adjusted_mrr, [adjusted_mrr]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, list):\n        total_scores = []\n        for d in data:\n            scores = [i for i, x in enumerate(d[0], 1) if x == 1]\n            if scores:\n                discounted_score = 1 / scores[0] * (1 - discount_rate)\n                total_scores.append(discounted_score)\n        return sum(total_scores) / len(total_scores), total_scores\n    elif isinstance(data, tuple):\n        scores = [i for i, x in enumerate(data[0], 1) if x == 1]\n        if scores:\n            discounted_score = 1 / scores[0] * (1 - discount_rate)\n            return discounted_score, [discounted_score]\n        else:\n            return 0, [0]\n    else:\n        raise ValueError(\"Data input should be either a list or a tuple.\")",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if type(data) == tuple:\n        return MetricsCalculator2.discounted_mrr([data], discount_rate)[0]\n    else:\n        total_num = 0\n        total_prec = 0\n        individual_prec = []\n        for d in data:\n            result, ground_truth = d[0], d[1]\n            mrr, prec = MetricsCalculator2.discounted_mrr([(result, ground_truth)], discount_rate)[0]\n            total_num += ground_truth\n            total_prec += prec\n            individual_prec.append(prec)\n        if total_num == 0:\n            return 0, []\n        else:\n            return total_prec / total_num, individual_prec",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a sequence (list or tuple).')\n        \n    if isinstance(data[0], (list, tuple)):\n        mrr_list = []\n        for tuple_data in data:\n            mrr_list.append(discounted_mrr(data=tuple_data, discount_rate=discount_rate))\n        return np.mean(mrr_list)\n    \n    else:\n        if not all(isinstance(item, int) for item in data):\n            raise ValueError('All elements in the data must be integers.')\n        \n        mrr = 0\n        for rank, relevancy in enumerate(data):\n            if relevancy != 0:\n                mrr = 1 / (rank + 1)\n                break\n        if mrr != 0:\n            mrr /= (1 - discount_rate)\n        \n        return mrr",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrr_scores = []\n    for sequence, total in data:\n        # find the first non-zero index\n        rank = next((i+1 for i, v in enumerate(sequence) if v > 0), len(sequence)+1)\n        # calculate reciprocal rank\n        reciprocal_rank = 1/rank\n        # calculate discounted reciprocal rank\n        discounted_rr = reciprocal_rank / (1 + discount_rate)\n        mrr_scores.append(discounted_rr)\n    return np.mean(mrr_scores), mrr_scores",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Evaluate the Mean Reciprocal Rank 'MRR' with a discount factored in by 'discount_rate' on the data input. Data can be a tuple or a list of tuples, each containing a sequence of binary relevancy and a total count of relevancies. The function verifies the type of 'data', then isolates the first non-zero score in each tuple, applies the reciprocal rank calculation, adjusts this by the 'discount_rate', and returns either just that score or the average score across all tuples and a list detailing each adjusted score.\n    :param data: the data must be a tuple, list or a list of tuples, each containing a sequence of binary relevancy and a total count of relevancies. The function verifies the type of 'data', then isolates the first non-zero score in each tuple, applies the reciprocal rank calculation, adjusts this by the 'discount_rate', and returns either just that score or the average score across all tuples and a list detailing each adjusted score.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    def reciprocal_rank(scores):\n        return 1 / (np.argmax(scores) + 1)\n\n    if isinstance(data, tuple):\n        data = [data]\n\n    discounted_ranks = []\n    for query in data:\n        if not isinstance(query, tuple):\n            raise ValueError(\"Each query must be a tuple or a list of tuples.\")\n        seq, total_count = query\n        actual_count = sum(seq)\n\n        if actual_count == 0:\n            discounted_rank = 0\n        else:\n            non_zero_reciprocal_rank = reciprocal_rank(seq)\n            discounted_rank = non_zero_reciprocal_rank * (1 - discount_rate)\n\n        discounted_ranks.append(discounted_rank)\n\n    return sum(discounted_ranks) / len(discounted_ranks), discounted_ranks",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, list):\n        total_scores = []\n        for d in data:\n            total_scores.append(discounted_mrr(d, discount_rate))\n        return np.mean(total_scores), total_scores\n    else:\n        ranks = [1 / (i + 1) for i, rel in enumerate(data[0]) if rel]\n        if ranks:\n            return (1 - discount_rate) * sum(ranks) / len(ranks)\n        else:\n            return 0.0",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if type(data) == tuple:\n        return 1 / (np.where(data[0] == 1)[0][0] + 1) * discount_rate\n    elif type(data) == list:\n        scores = []\n        for item in data:\n            scores.append(1 / (np.where(item[0] == 1)[0][0] + 1) * discount_rate)\n        return sum(scores) / len(scores)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('Incorrect data format.')\n\n    total_rank = 0.0\n    rank_list = []\n\n    for i in range(len(data)):\n        if not isinstance(data[i], (list, tuple)) or len(data[i]) != 2:\n            raise ValueError('Incorrect data item format.')\n        sequence, total = data[i]\n        if not isinstance(sequence, (list, tuple)) or not all(isinstance(x, int) and x in [0, 1] for x in sequence):\n            raise ValueError('Incorrect sequence format.')\n        if not isinstance(total, int):\n            raise ValueError('Incorrect total count format.')\n        if total == 0:\n            raise ValueError('Total count cannot be zero.')\n\n        if 1 in sequence[:total]:\n            rank = sequence.index(1) + 1\n            scaled_rank = rank * discount_rate ** (rank - 1)\n            total_rank += scaled_rank\n            rank_list.append(scaled_rank)\n        else:\n            rank = 0  # If no relevant item found, rank is 0\n            scaled_rank = 0\n            total_rank += scaled_rank\n            rank_list.append(scaled_rank)\n\n    if len(rank_list) > 0:\n        return total_rank / len(rank_list), rank_list\n    else:\n        return 0, []",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrr_list = []\n    if isinstance(data, list):\n        for data_element in data:\n            mrr_list.append(discounted_mrr(data_element, discount_rate))\n        return np.mean(mrr_list), mrr_list\n    elif isinstance(data, tuple):\n        data_reciprocal_rank = [1 / (i + 1) if x == 1 else 0 for i, x in enumerate(data[0])]\n        if sum(data[0]) != data[1]:\n            raise ValueError(\"Total ground truth number does not match provided relevancies\")\n        mrr = np.sum(data_reciprocal_rank) * discount_rate\n        return mrr\n    else:\n        raise TypeError(\"Input data should be a list or a tuple\")",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Process given 'data' to calculate its Mean Reciprocal Rank 'MRR', adjusted by a 'discount_rate'. Acceptable input for 'data' includes a tuple or a list of tuples, with each tuple comprising a sequence of binary relevancies (0s and 1s) and a total count of these relevancies. The function confirms the proper format of 'data', identifies the reciprocal rank of the first relevant element from each tuple, scales this figure by the 'discount_rate', and outputs either the lone scaled rank or the mean of scaled ranks accompanied by a list of these individual values.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n     ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    if not(isinstance(data, tuple) or isinstance(data, list)):\n        raise ValueError(\"Data must be a tuple or list.\")\n    if not all(isinstance(i, tuple) and len(i) == 2 and isinstance(i[0], list) and isinstance(i[1], int) and all(isinstance(j, int) and j in [0, 1] for j in i[0]) for i in data):\n        raise ValueError(\"Data is not in the correct format.\")\n    if not (isinstance(discount_rate, int) or isinstance(discount_rate, float)):\n        raise ValueError(\"Discount rate must be a number.\")\n\n    mrr = 0\n    mrr_list = []\n    for item in data:\n        item_mrr = next((1/i if item[0][i]==1 else 0 for i in range(item[1])), 0)\n        mrr += item_mrr / discount_rate\n        mrr_list.append(item_mrr / discount_rate)\n    return mrr / len(data) if isinstance(data, list) else mrr, mrr_list",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    scaled_ranks = []\n    for item in data:\n        rank = next((i+1 for i, x in enumerate(item[0]) if x), None)\n        if rank:\n            scaled_rank = rank / (discount_rate**rank)\n            scaled_ranks.append(scaled_rank)\n    return sum(scaled_ranks) / len(data) if data else 0, scaled_ranks",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for sequence, total in data:\n        if len(sequence) != total:\n            raise ValueError(\"The total count does not match the length of the sequence\")\n        rec_rank = 0\n        for rank, rel in enumerate(sequence, start=1):\n            if rel == 1:\n                rec_rank = rank\n                break\n        if rec_rank == 0:\n            mrrs.append(0)\n        else:\n            mrrs.append(rec_rank / (1-discount_rate)**rec_rank)\n    return np.mean(mrrs), mrrs",
                false
            ]
        ],
        "level 3": [
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, tuple):\n        results = np.array([i for i in data[0]])\n        total_count = data[1]\n        \n        reciprocal_ranks = 1 / np.where(results)[0]\n        mrr = np.sum(reciprocal_ranks)\n\n        discounted_mrr = mrr * (1 - discount_rate) + (reciprocal_ranks[0] * discount_rate)\n        return discounted_mrr, [mrr]\n\n    elif isinstance(data, list):\n        mrr_list = []\n        count_list = 0\n        for item in data:\n            results = np.array([i for i in item[0]])\n            total_count = item[1]\n            \n            reciprocal_ranks = 1 / np.where(results)[0]\n            mrr = np.sum(reciprocal_ranks)\n            \n            discounted_mrr = mrr * (1 - discount_rate) + (reciprocal_ranks[0] * discount_rate)\n            mrr_list.append(mrr)\n            count_list += total_count\n\n        mean_mrr = np.sum(mrr_list)/len(data)\n        return mean_mrr, mrr_list",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    total_mrr = 0\n    if isinstance(data, tuple):\n        data = [data]\n\n    for d in data:\n        result, count = d\n        result = np.array(result)\n        is_relevant = (result > 0)\n        if is_relevant.sum() == 0:\n            continue\n        ranks = is_relevant.argmax()\n        if ranks == 0:\n            ranks = 1\n        mrr = 1 / ranks\n        mrrs.append(mrr)\n        total_mrr += mrr\n        if discount_rate > 0:\n            mrr -= discount_rate\n\n    if len(mrrs):\n        avg_mrr = total_mrr / len(mrrs)\n    else:\n        avg_mrr = 0\n\n    return avg_mrr, mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Calculate the discounted Mean Reciprocal Rank \"MRR\" of the input \"data\", applying a \"discount_rate\" to the rank of the first relevant result. \"data\" must be a list of tuples where each tuple consists of a list of binary values (1 for correct answer, 0 for a wrong answer) and an integer representing the total number of ground truth items. The method checks if \"data\" is a list and initializes processing. If \"data\" is a list, it processes each tuple similarly and aggregates these results to compute an average discounted MRR, returning this average along with a list of individual MRRs. The function returns a tuple where the first element is the mean MRR and the second element is a list of MRRs for each tuple processed.\n    :param data: the data must be a list of tuple,eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)]. \n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the MRR of this list. The second return value is a list of MRRs for each input.\n    \"\"\"\n    mrr_list = []\n    for result in data:\n        ranks = np.nonzero(result[0])[0]\n        if len(ranks) == 0:\n            mrr_list.append(0)\n        else:\n            mrr = 1 / ranks[0]\n            mrr *= (1 - discount_rate) + discount_rate / len(ranks)\n            mrr_list.append(mrr)\n    return sum(mrr_list) / len(mrr_list), mrr_list",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, tuple):\n        items = list(data[0])\n        total = data[1]\n    elif isinstance(data, list):\n        items = [item[0] for item in data]\n        total = [item[1] for item in data]\n    else:\n        raise ValueError('data must be a list or tuple')\n\n    items = np.array(items)\n    ranks = np.argsort(items)[::-1] + 1\n  \n    res = [ranks[0] * (1 - discount_rate) + sum(ranks[ranks > 1] / ranks[ranks <= 1]) for items in items]\n    if isinstance(data, list):\n        return (sum(res) / len(res), res)\n    else:\n        return (sum(res / total), res)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs, mrrs_each = [], []\n    if isinstance(data, tuple):\n        data = [data]\n    for result in data:\n        result, total = result\n        result = np.array(result)\n        rank = np.where(result)[0][0] + 1 if np.sum(result) != 0 else total + 1\n        rank = min(rank, total)\n        mrr = (1. / rank)\n        mrrs.append(mrr)\n        mrrs_each.append(mrr)\n    if len(mrrs) > 1:\n        return np.mean(mrrs), mrrs_each\n    else:\n        return mrrs[0], mrrs_each[0]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (list, tuple)):\n        raise ValueError('The input data must be a list or a tuple.')\n    if isinstance(data, tuple):\n        data = [data]\n    mrrs = []\n    for item in data:\n        if not isinstance(item, tuple) or len(item) != 2:\n            raise ValueError('Each item in the list must be a tuple of length 2.')\n        results, true_num = item\n        if not isinstance(results, list):\n            raise ValueError('The list of results must be a list.')\n        if not all(isinstance(i, int) for i in results):\n            raise ValueError('All elements in the list of results must be integers (0 or 1).')\n        if not isinstance(true_num, int):\n            raise ValueError('The true_num must be an integer.')\n        results = np.array(results)\n        ranks = np.nonzero(results)[0]\n        if len(ranks) == 0:\n            mrr = 0\n        else:\n            first = ranks[0] + 1\n            mrr = 1 / first\n        mrrs.append(mrr)\n    return np.mean(mrrs), mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for result, true_num in data:\n        result = np.array(result)\n        rank = np.where(result==1)[0][0]\n        mrr = 1/(rank+discount_rate)\n        mrrs.append(mrr)\n    return np.mean(mrrs), mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Compute the discounted Mean Reciprocal Rank (MRR) for 'data' using a 'discount_rate' for the ranking of the initial correct response. 'data' should be structured as a tuple or a list of tuples, where each tuple contains a list of binary results (1 indicating correct, 0 incorrect) and a total number of true results. The function first verifies that 'data' is in acceptable formats and then, if a tuple, gathers the list of results and count, transforms these into a numpy numerical array, and calculates reciprocal ranks to then multiply these by the results. The rank of the first relevant answer is reduced by the 'discount_supply.' The processing of a list of tuples averages the computed MRRs and returns both the mean and a collection of individual MRRs.\n    :param data: the data must be a tuple, list of tuples. In each tuple (actual result, ground truth num), ground truth num is the total ground num.\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    if isinstance(data, tuple):\n        data = [data]\n    data = [d for d in data if len(d) == 2]\n    mrr_list = []\n    for results, total_true in data:\n        results = np.array(results, dtype=int)\n        rank = np.where(results == 1)[0][0] + 1\n        mrr = 1 / rank * (1 - discount_rate) ** rank\n        mrr_list.append(mrr)\n    average_mrr = sum(mrr_list) / len(mrr_list)\n    return average_mrr, mrr_list",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if not isinstance(data, (tuple, list)):\n        raise ValueError('Input data must be a tuple/list of tuples or lists.')\n    elif all(isinstance(i, (tuple, list)) for i in data):\n        mean_mrrs = []\n        for datum in data:\n            result_list, total_true_results = datum\n            if not isinstance(result_list, list) or not (all(isinstance(i, int) and i in (0, 1) for i in result_list)):\n                raise ValueError('Each list inside tuples/lists must be a list of 0s and 1s.')\n            elif not isinstance(total_true_results, int) or total_true_results > len(result_list) or total_true_results < 0:\n                raise ValueError('Total true results cannot be greater than the total number of results or negative.')\n            else:\n                result_array = np.array(result_list)\n                rank_array = np.where(result_array == 1)[0]\n                if len(rank_array) == 0:\n                    mean_mrrs.append(0.0)\n                else:\n                    min_rank = rank_array[0]\n                    discounted_rank = min_rank * (1 - discount_rate)\n                    mrr = 1 / discounted_rank\n                    mean_mrrs.append(mrr)\n        average_mrr = sum(mean_mrrs) / len(mean_mrrs)\n        return average_mrr, mean_mrrs\n    else:\n        result_list, total_true_results = data\n        if not isinstance(result_list, list) or not (all(isinstance(i, int) and i in (0, 1) for i in result_list)):\n            raise ValueError('Each list inside tuples/lists must be a list of 0s and 1s.')\n        elif not isinstance(total_true_results, int) or total_true_results > len(result_list) or total_true_results < 0:\n            raise ValueError('Total true results cannot be greater than the total number of results or negative.')\n        else:\n            result_array = np.array(result_list)\n            rank_array = np.where(result_array == 1)[0]\n            if len(rank_array) == 0:\n                return 0.0, []\n            else:\n                min_rank = rank_array[0]\n                discounted_rank = min_rank * (1 - discount_rate)\n                mrr = 1 / discounted_rank\n                return mrr, [mrr]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for results, total in data:\n        if len(results) != total:\n            raise ValueError(\"Number of correct results does not match total.\")\n        mrr = 0.0\n        discount = 1\n        for result in results:\n            mrr += 1.0 / result\n            mrr *= discount\n            discount *= (1 - discount_rate)\n        mrr /= total\n        mrrs.append(mrr)\n    return np.mean(mrrs), mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, list):\n        total = 0.0\n        for item in data:\n            result, count = item\n            result = np.array(result)\n            mrr_sum = 0.0\n            rank = np.where(result == 1)[0]\n            if rank.size > 0:\n                # Apply discount to the first relevant result's rank\n                rank = min(rank[0] + 1, int(1 / discount_rate))\n                mrr_sum = 1 / rank\n            total += mrr_sum\n        return [total / len(data), [mrr_sum / len(data)] * len(data)]\n    else:\n        result, count = data\n        result = np.array(result)\n        mrr_sum = 0.0\n        rank = np.where(result == 1)[0]\n        if rank.size > 0:\n            # Apply discount to the first relevant result's rank\n            rank = min(rank[0] + 1, int(1 / discount_rate))\n            mrr_sum = 1 / rank\n    return [mrr_sum, mrr_sum]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for d in data:\n        if isinstance(d, tuple):\n            result, total_num = d\n            result = np.array(result)\n            if total_num > 0:\n                mrr = (len(result) - np.where(result)[0][0]) / total_num\n                mrrs.append(max(0, mrr - discount_rate))\n        else:\n            raise ValueError(\"Invalid data, must be a tuple or list of tuples\")\n    return sum(mrrs) / len(mrrs) if len(mrrs) > 0 else 0",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Assess the discounted Mean Reciprocal Rank 'MRR' of 'data', applying 'discount_rate' to the first significant result's rank. The 'data' input should either be a tuple or a batch of tuples, containing a list of binary assessments (1 for correct, 0 for incorrect) alongside a number representing the total truth count. Verification of data type precede the operations where, if 'data' is a tuple, it pulls the result list and count, converts this to a numpy array, and performs reciprocal rank calculations subsequently applied to the result set values. The function discounts the first relevant result's rank with 'discount_rate' and stops. When 'data' is a list, each element undergoes the same process, and the results are averaged for a final discounted MRR, returning both a list and mean of MRRs.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n    ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    \n    if type(data) is tuple:\n        data = [data]\n    \n    all_mrrs = []\n    for d in data:\n        result, count = d\n        result = np.array(result)\n        \n        ranks = (np.cumsum(result) - result) + 1\n        ranks = ranks[result==1]\n        \n        if len(ranks) == 0:\n            continue\n        else:\n            rank = ranks[0]\n        \n        mrr = 1 / rank\n        discounted_mrr = mrr / (1 + discount_rate)\n        all_mrrs.append(discounted_mrr)\n    \n    if len(all_mrrs) == 0:\n        return 0\n        \n    average_mrr = sum(all_mrrs) / len(all_mrrs)\n    \n    return average_mrr",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, tuple):\n        data = [data]\n\n    mrrs = []\n    for d in data:\n        ranks = np.where(d[0])[0] + 1  # indices of 1s start at 0, so add one to get rank\n        if len(ranks) > 0:\n            mrr = 1 / ranks[0]  # reciprocal of first rank\n            mrr *= (1 - discount_rate)  # discount first rank\n            mrr += discount_rate / len(d[0])  # add discount rate for all other ranks\n            mrrs.append(mrr)\n        else:\n            mrrs.append(0)\n\n    return np.mean(mrrs), mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for d in data:\n        if isinstance(d, tuple):\n            results, truth_count = d\n            results = np.array(results)\n        else:\n            results = np.array(d)\n            truth_count = len(d)\n        rank = np.where(results == 1)[0][0] + 1\n        rank = min(rank, truth_count)\n        mrr = 1 / rank\n        mrrs.append(mrr - discount_rate)\n    return np.mean(mrrs), mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, list):\n        total = 0.0\n        mrrs = []\n        for d in data:\n            mrr, mrrs_d = get_mrr_and_mrrs(d)\n            if mrr is not None:\n                total += mrr\n                mrrs.append(mrrs_d)\n        return total / len(data), mrrs\n    else:\n        return get_mrr_and_mrrs(data)\n\ndef get_mrr_and_mrrs(data):\n    results, totals = data\n    if len(results) != totals:\n        return None, None\n    ranks = np.argsort(results)[::-1]\n    mrr = 0.0\n    mrrs = [(1 / (r+1) if r < totals else 0) for r in ranks]\n    for i in range(totals):\n        mrr += mrrs[i]\n    return mrr / totals, mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for result, total in data:\n        result_array = np.array(result)\n        rank = np.where(result_array == 1)[0]\n        if len(rank) == 0:\n            mrr = 0  # if no correct answer, return 0\n        else:\n            mrr = 1 / (rank[0] + 1)\n            if rank[0] != 0:\n                mrr *= (1 - discount_rate) ** rank[0]  # if the first rank is not first, apply the discount_rate\n        mrrs.append(mrr)\n\n    if isinstance(data[0][0], list):\n        avg_mrr = sum(mrrs) / len(mrrs)\n        return avg_mrr, mrrs\n    else:\n        return mrrs[0], [mrrs[0]]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Calculate the adjusted Mean Reciprocal Rank (MRR) of 'data', using a 'discount_rate' on the rank of the first pertinent result. The input 'data' should be formatted as either a single tuple or a series of tuples, each consisting of a binary result set (1 marks right answers and 0 marks wrong ones) and an integer of total correct responses. Upon confirming the data structure, if it's a tuple, the method extracts results and totals, processes these into a numpy array, and calculates the reciprocal ranks that are multiplied by the results. It then applies the 'discount_rate' on the rank for the first accurate outcome, ceasing further processes. If it's a list, similar operations apply across tuples, summarizing to average the discounted MRR and returning it with a detailed list of MRRs from each tuple.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n     ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    if isinstance(data, list): # if data is list of tuple\n        mrrs = []\n        for item in data:\n            mrr = MetricsCalculator2.discounted_mrr(item, discount_rate)\n            mrrs.append(mrr)\n        return sum(mrrs) / len(mrrs), mrrs\n    elif isinstance(data, tuple): # if data is tuple\n        results = np.array(data[0], dtype=np.bool)\n        total = data[1]\n        ranks = Results.rank_order(results)\n        mrr = np.reciprocal(ranks[0:total]) * results[0:total]\n        mrr = np.sum(mrr)\n        mrr *= (1 - discount_rate)\n        mrr += discount_rate * results[0]\n        return mrr\n    else:\n        raise TypeError('The input data must be a tuple or a list.')",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, tuple):\n        data = [data]\n\n    mrrs = []\n    for d in data:\n        ranks = np.where(d[0] == 1)[0] + 1\n        mrr = 0\n        for rank in ranks:\n            mrr = 1 / rank\n            mrr = mrr / (1 - discount_rate)\n            mrrs.append(mrr)\n            if rank == 1:\n                mrr = mrr * 1 / (1 - discount_rate)\n            else:\n                mrr = mrr * (1 - discount_rate)\n            break\n        if len(ranks) == 0:\n            mrr = 0\n        mrr = np.sum(mrrs) / len(mrrs)\n\n    return mrr",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    if isinstance(data, tuple):\n        data = [data]\n    for result, total_correct in data:\n        result = np.array(result)\n        total_correct = 1 / (result[:total_correct].sum() + 1e-10)\n        ranks = np.argsort(-result)\n        discounted_rank = (total_correct * discount_rate) + (1 - discount_rate) * np.sum(1 / (1 + ranks))\n        mrrs.append(discounted_rank)\n    return np.mean(mrrs)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, list):\n        total = 0.0\n        for item in data:\n            result, total_num = item\n            result, total_num = np.array(result), np.array(total_num)\n\n            ranks = np.where(result == 1)[0]\n            if len(ranks) == 0:\n                continue\n            rank = ranks[0] + 1  # rank starts from 1\n\n            total += (1 / rank) * discount_rate ** rank  # discounted MRR\n        return total / len(data)  # mean MRR\n    else:\n        result, total_num = data\n        result, total_num = np.array(result), np.array(total_num)\n\n        ranks = np.where(result == 1)[0]\n        if len(ranks) == 0:\n            return 0.0  # if no correct results found, MRR is 0\n        rank = ranks[0] + 1  # rank starts from 1\n\n        return (1 / rank) * discount_rate ** rank  # discounted MRR",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrr_list = []\n    if isinstance(data, list):\n        for data_element in data:\n            mrr_list.append(discounted_mrr(data_element, discount_rate))\n        return np.mean(mrr_list), mrr_list\n    elif isinstance(data, tuple):\n        data_records, total_count = data\n        total_count = min(len(data_records), total_count)\n        correct_count = sum(data_records[:total_count])\n        if correct_count == 0:\n            return 0\n        reciprocal_rank = 1 / (data_records.index(1) + 1)\n        if reciprocal_rank > discount_rate:\n            return reciprocal_rank - (reciprocal_rank - discount_rate)\n        else:\n            return reciprocal_rank\n    else:\n        raise ValueError(\"Invalid data format: Must be a list or tuple.\")\n\nclass MetricsCalculator2:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def map(data):\n        raise NotImplementedError(\"Method is not implemented.\")\n\n    def mrr(data):\n        raise NotImplementedError(\"Method is not implemented.\")\n\n    def discounted_mrr(data, discount_rate):\n        return discounted_mrr(data, discount_rate)",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Derive the discounted Mean Reciprocal Rank 'MRR' from 'data', using a 'discount_rate' on the ranking of the first accurate result. For 'data', which must be a list of tuples, each tuple should include a binary value list (1 for a correct response, 0 for incorrect) and a count of total accurate items. The functionality starts by confirming the data type and, for a tuple, extracts result arrays and their totals, processes these into a numpy array format, and performs calculations on reciprocal ranks which are then multiplied by result values. Discounting uses 'degrees' on the first found valid rank, closing computations post-hoc. For a list scenario, it equally processes each sub-tuple, averages the resultant MRR values, presenting both individual and mean MRRs.\n    :param data: the data must be a list of tuples, each tuple should include a binary value list (1 for a correct response, 0 for incorrect) and a count of total accurate items.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: the discounted mean reciprocal rank (discounted MRR) value.\n    \"\"\"\n    def _mrr(data, count):\n        \"\"\"\n        Calculate the mean reciprocal rank (MRR) given a list of binary results (1 for correct, 0 for incorrect) and a count of total accurate items.\n        :param data: a list of binary results.\n        :param count: the total accurate items.\n        :return: the MRR value.\n        \"\"\"\n        mrr_sum = 0.0\n        for idx, result in enumerate(data):\n            mrr_sum += (1.0 / (idx + 1)) * result\n        return mrr_sum / min(count, data.count(1))\n\n    mrr_values = []\n\n    if type(data) == list:\n        for d in data:\n            mrr_values.append(_mrr(d[0], int(d[1])))\n    else:\n        mrr_values.append(_mrr(data[0], int(data[1])))\n\n    mrr_values = np.array(mrr_values)\n    discounts = np.power(discount_rate, np.arange(mrr_values.size))\n    discounted_mrr_value = np.sum((mrr_values * discounts)) / (1 - discounts[-1])\n\n    return discounted_mrr_value",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, list):\n        mrr = []\n        for item in data:\n            res, total = item\n            mrr.append(MetricsCalculator2.discounted_mrr([res, total], discount_rate))\n        return np.mean(mrr), mrr\n    elif isinstance(data, tuple):\n        res, total = data\n        ranks = np.where(res)[0]\n        if len(ranks) > 0:\n            mrr = 1 / (ranks[0]+1) * (1-discount_rate) + discount_rate\n        else:\n            mrr = 0\n        return mrr * (res[0] == 1), [mrr]\n    else:\n        raise ValueError(\"Illegal data type\")",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if type(data) == tuple:\n        return MetricsCalculator2.calc_mrr(data, discount_rate)\n    elif type(data) == list:\n        total_mrr, precisions = 0, []\n        for sub_data in data:\n            mrr, precision = MetricsCalculator2.calc_mrr(sub_data, discount_rate)\n            total_mrr += mrr\n            precisions.append(precision)\n        return total_mrr / len(data), precisions\n    else:\n        raise ValueError('Invalid data type, should be tuple or list')\n\n@staticmethod\ndef calc_mrr(data, discount_rate):\n    result_list, total = data\n    result_list = np.array(result_list)\n    ranks = np.where(result_list == 1)[0]\n    if len(ranks) == 0:\n        return 0, 0\n    first_r = ranks[0]\n    discounted_r = 1 + (first_r * discount_rate)\n    mrr = np.reciprocal(discounted_r)\n    precision = 1 - (total - first_r) / total\n    return mrr, precision",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, list):\n        total = 0.0\n        MRRs = []\n        for d in data:\n            mrr, mrrs = MetricsCalculator2.discounted_mrr(d, discount_rate)\n            MRRs.extend(mrrs)\n            total += mrr\n        return total / len(data), MRRs\n    else:\n        result, total = data\n        result = np.array(result)\n        ranks = np.where(result == 1)[0]\n        if len(ranks) > 0:\n            rank = ranks[0] + 1  # rank is 1-indexed\n            return (rank / (1 + discount_rate * rank)), [(rank / (1 + discount_rate * rank))]\n        else:\n            return 0.0, [0.0]",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for result, total in data:\n        result = np.array(result)\n        if len(result) != total:\n            raise ValueError(\"The length of 'result' does not match 'total'.\")\n        rank = np.where(result == 1)[0][0] + 1\n        mrr = 1 / rank\n        discounted_mrr = mrr * (1 - discount_rate) ** (rank - 1) if rank > 0 else 0\n        mrrs.append(discounted_mrr)\n    return np.mean(mrrs), mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    \"\"\"\n    Evaluate the discounted Mean Reciprocal Rank 'MRR' from 'data', applying a 'discount_rate' on the first relevant rank found. 'data' must be structured as a tuple or a list of tuples, where each tuple comprises a list of binary values (1 indicating correct, 0 for incorrect) and an integer for the count of correct items. Initiate by validating the 'data' structure, if a tuple, retrieving results and total counts, converting to a numpy array, and calculating reciprocal ranks to be multiplied with results. Implement the 'discount_rate' on the rank of the primary relevant result then halts. For lists, it processes each tuple similarly, tabulates the MRRs to output an average MRR and a list of per-tuple MRRs.\n    :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n     ([1,0,...],5),\n    or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n    1 stands for a correct answer, 0 stands for a wrong answer.\n    :param discount_rate: The rate at which the first rank is discounted.\n    :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n    average recall on all list. The second return value is a list of precision for each input.\n    \"\"\"\n    data_list = data\n    if not isinstance(data, list):\n        data_list = [data]\n\n    mrrs = []\n    for item in data_list:\n        results, total_relevant = item\n        results = np.array(results)\n        rank_correct = np.where(results)[0][0]\n        if rank_correct == 0:  # No relevant at all\n            mrrs.append(0)\n        else:\n            mrrs.append((1 / rank_correct) * (1 - discount_rate) + discount_rate)\n\n    if len(mrrs) > 1:\n        return sum(mrrs) / len(mrrs), mrrs  # Average and list of MRRs\n    else:\n        return mrrs[0], mrrs  # Single MRR and list of MRRs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    if isinstance(data, tuple):\n        data = [data]\n\n    total_mrrs = []\n    for result, num_relevant in data:\n        result = np.array(result)\n        indices = np.where(result)[0]\n        if len(indices) > 0:\n            rank = indices[0] + 1\n            if rank == 1:\n                mrr = 1 / rank * (1 - discount_rate) +  discount_rate\n            else: \n                mrr = 1 / rank\n            total_mrrs.append(mrr)\n                \n    if len(total_mrrs) == 0:\n        return 0, []\n\n    return np.mean(total_mrrs), total_mrrs",
                false
            ],
            [
                "def discounted_mrr(data, discount_rate):\n    mrrs = []\n    for d in data:\n        if isinstance(d, tuple):\n            results = np.array(d[0])\n            total = d[1]\n        else:\n            results = np.array([result for result_list in d for result in result_list])\n            total = len(results)\n        \n        rr = np.where(results == 1)[0]\n        if len(rr) == 0:\n            mrrs.append(0)\n        else:\n            mrr = 1 / (rr[0] + 1)\n            if rr[0] > 0:\n                mrr *= (1 - discount_rate)\n            mrrs.append(mrr)\n    return np.mean(mrrs), mrrs",
                false
            ]
        ]
    },
    "3": {
        "level 1": [
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Calculate the correlation coefficient for two sets of data \"data1\" and \"data2\" after removing outliers from both datasets. Outliers are defined as data points that are strictly more than two standard deviations away from the mean in either of the dataset. Return the correlation coefficient as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    def mean(data):\n        return sum(data) / len(data)\n\n    def standard_deviation(data):\n        mu = mean(data)\n        return math.sqrt(sum((x - mu) ** 2 for x in data) / len(data))\n\n    def is_outlier(data, threshold=2):\n        mu = mean(data)\n        sigma = standard_deviation(data)\n        return [x for x in data if abs(x - mu) > threshold * sigma]\n\n    def correlation_coefficient(data1, data2):\n        n = len(data1)\n        sum1 = sum(data1)\n        sum2 = sum(data2)\n        sum1_sq = sum(x ** 2 for x in data1)\n        sum2_sq = sum(x ** 2 for x in data2)\n        psum = sum(x * y for x, y in zip(data1, data2))\n\n        num = psum - (sum1 * sum2 / n)\n        den = math.sqrt(\n            ((sum1_sq - (sum1 ** 2) / n) * (sum2_sq - (sum2 ** 2) / n))\n        )\n        if den == 0:\n            return 0\n        return num / den\n\n    outliers1 = is_outlier(data1)\n    outliers2 = is_outlier(data2)\n\n    data1 = [val for val in data1 if val not in outliers1]\n    data2 = [val for val in data2 if val not in outliers2]\n\n    return correlation_coefficient(data1, data2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    from scipy import stats\n    import numpy as np\n\n    # Calculating z-scores\n    z1 = np.abs(stats.zscore(data1))\n    z2 = np.abs(stats.zscore(data2))\n\n    # Filtering out data that are more than 2 standard deviations away from the mean\n    filtered_data1 = [data1[i] for i in range(len(data1)) if z1[i] <= 2]\n    filtered_data2 = [data2[i] for i in range(len(data2)) if z2[i] <= 2]\n\n    # Calculating correlation coefficient for filtered datasets\n    correlation_coefficient = DataStatistics4.correlation_coefficient(filtered_data1, filtered_data2)\n    return correlation_coefficient",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Calculate the robust correlation coefficient for two sets of data \"data1\" and \"data2\" after removing outliers from both datasets. Outliers are defined as data points that are strictly more than two standard deviations away from the mean in either of the dataset. Return the correlation coefficient as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    if len(data1) != len(data2):\n        return None  # data sets are not the same in length\n\n    def remove_outliers(data):\n        \"\"\"\n        Remove outliers from the data.\n        \"\"\"\n        mean = sum(data) / len(data)\n        std_dev = math.sqrt(sum([(i - mean) ** 2 for i in data]) / len(data))\n        return [i for i in data if abs(i - mean) <= 2 * std_dev]\n\n    data1_no_outliers = remove_outliers(data1)\n    data2_no_outliers = remove_outliers(data2)\n\n    if len(data1_no_outliers) <= 1 or len(data2_no_outliers) <= 1:\n        return None  # no correlation possible without at least two data points\n\n    n = len(data1_no_outliers)\n    mean1 = sum(data1_no_outliers) / n\n    mean2 = sum(data2_no_outliers) / n\n\n    numerator = sum([(data1_no_outliers[i] - mean1) * (data2_no_outliers[i] - mean2) for i in range(n)])\n    denominator = math.sqrt(sum([(i - mean1) ** 2 for i in data1_no_outliers]) * sum([(i - mean2) ** 2 for i in data2_no_outliers]))\n\n    return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    var_1 = sum((x - mean_1) ** 2 for x in data1) / len(data1)\n    var_2 = sum((x - mean_2) ** 2 for x in data2) / len(data2)\n    stddev_1 = var_1 ** 0.5\n    stddev_2 = var_2 ** 0.5\n    \n    # Calculating outliers\n    outliers1 = [x for x in data1 if abs(x - mean_1) > 2 * stddev_1]\n    outliers2 = [x for x in data2 if abs(x - mean_2) > 2 * stddev_2]\n    \n    # Removing outliers\n    data1 = [x for x in data1 if x not in outliers1]\n    data2 = [x for x in data2 if x not in outliers2]\n    \n    # Calculating correlation coefficient\n    mean_x = sum(data1) / len(data1)\n    mean_y = sum(data2) / len(data2)\n    cov = sum((x - mean_x) * (y - mean_y) for x, y in zip(data1, data2)) / len(data1)\n    corr_coeff = cov / (stddev_1 * stddev_2)\n    return corr_coeff",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, std1 = mean_and_std(data1)\n    mean2, std2 = mean_and_std(data2)\n    \n    data1 = [(x-mean1) / std1 for x in data1 if abs((x-mean1) / std1) <= 2]\n    data2 = [(x-mean2) / std2 for x in data2 if abs((x-mean2) / std2) <= 2]\n    \n    if len(data1) < 2 or len(data2) < 2:\n        raise ValueError('Data has less than 2 valid values after removing outliers')\n\n    return DataStatistics4.correlation_coefficient(data1, data2)\n\ndef mean_and_std(data):\n    n = len(data)\n    mean = sum(data) / n\n    std = math.sqrt(sum((x-mean)**2 for x in data) / n)\n    return mean, std",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n    std_dev1 = math.sqrt(sum([(x - mean1) ** 2 for x in data1]) / len(data1))\n    std_dev2 = math.sqrt(sum([(x - mean2) ** 2 for x in data2]) / len(data2))\n\n    filtered_data1 = [x for x in data1 if abs(x - mean1) <= 2 * std_dev1]\n    filtered_data2 = [x for x in data2 if abs(x - mean2) <= 2 * std_dev2]\n\n    correlation_coeff = sum([(x - mean1) * (y - mean2) for x, y in zip(filtered_data1, filtered_data2)]) / (len(filtered_data1) * std_dev1 * std_dev2)\n\n    return correlation_coeff",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    from scipy import stats\n    if len(data1) != len(data2):\n        raise ValueError(\"Both datasets should have the same length.\")\n    z_scores1 = stats.zscore(data1)\n    z_scores2 = stats.zscore(data2)\n    cleaned_data1 = [data1[i] for i in range(len(z_scores1)) if abs(z_scores1[i]) < 2]\n    cleaned_data2 = [data2[i] for i in range(len(z_scores2)) if abs(z_scores2[i]) < 2]\n    return stats.pearsonr(cleaned_data1, cleaned_data2)[0]",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Compute the robust correlation coefficient for two datasets 'data1' and 'data2' post elimination of outliers. Define outliers as entries exceeding two standard deviations above the mean in either of the dataset. The function should yield the correlation coefficient as a floating point number.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n\n    def calculate_mean(data):\n        return sum(data) / len(data)\n\n    def calculate_std_dev(data):\n        variance = sum([((x - calculate_mean(data)) ** 2) for x in data]) / len(data)\n        return variance ** 0.5\n\n    def remove_outliers(data):\n        mean = calculate_mean(data)\n        std_dev = calculate_std_dev(data)\n        return [x for x in data if (mean - 2*std_dev) <= x <= (mean + 2*std_dev)]\n\n    def calculate_correlation_coefficient(data1, data2):\n        n = len(data1)\n        sum1 = sum(data1)\n        sum2 = sum(data2)\n        sum1_sq = sum([i ** 2 for i in data1])\n        sum2_sq = sum([i ** 2 for i in data2])\n        product_sum = sum([data1[i] * data2[i] for i in range(n)])\n        num = product_sum - (sum1 * sum2 / n)\n        den = ((sum1_sq - pow(sum1, 2) / n) * (sum2_sq - pow(sum2, 2) / n)) ** 0.5\n        if den == 0:\n            return 0\n        return num / den\n\n    data1 = remove_outliers(data1)\n    data2 = remove_outliers(data2)\n    return calculate_correlation_coefficient(data1, data2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    var_1 = sum((x - mean_1) ** 2 for x in data1) / len(data1)\n    var_2 = sum((x - mean_2) ** 2 for x in data2) / len(data2)\n    stddev_1 = math.sqrt(var_1)\n    stddev_2 = math.sqrt(var_2)\n    \n    # Calculating outliers\n    outliers1 = [x for x in data1 if abs(x - mean_1) > 2 * stddev_1]\n    outliers2 = [x for x in data2 if abs(x - mean_2) > 2 * stddev_2]\n    \n    # Removing outliers\n    data1 = [x for x in data1 if x not in outliers1]\n    data2 = [x for x in data2 if x not in outliers2]\n    \n    # Calculating correlation coefficient\n    mean_x = sum(data1) / len(data1)\n    mean_y = sum(data2) / len(data2)\n    cov = sum((x - mean_x) * (y - mean_y) for x, y in zip(data1, data2)) / len(data1)\n    corr_coeff = cov / (stddev_1 * stddev_2)\n    return corr_coeff",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, std1 = (sum(data1)/len(data1)), (math.sqrt(sum((x - sum(data1)/len(data1))**2 for x in data1)/len(data1)))\n    mean2, std2 = (sum(data2)/len(data2)), (math.sqrt(sum((x - sum(data2)/len(data2))**2 for x in data2)/len(data2)))\n    \n    filtered1 = [i for i in data1 if abs((i - mean1)/std1) <= 2]\n    filtered2 = [i for i in data2 if abs((i - mean2)/std2) <= 2]\n\n    covariance = sum((x - mean1)*(y - mean2) for x, y in zip(filtered1, filtered2)) / len(filtered1)\n    correlation_coefficient = covariance / (std1 * std2)\n    return correlation_coefficient",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Determine the correlation coefficient between two data arrays 'data1' and 'data2' by first excluding outliers, which are points greater than two standard deviations from the average in either of the dataset. The result should be returned as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    combined_data = list(zip(data1, data2))\n    mu = sum(combined_data) / len(combined_data)\n    sigma = math.sqrt(sum((x - mu) ** 2 for x in combined_data) / len(combined_data))\n    \n    outliers_removed_data1 = [x for x in data1 if abs((x - mu[0]) / sigma[0]) <= 2]\n    outliers_removed_data2 = [x for x in data2 if abs((x - mu[1]) / sigma[1]) <= 2]\n    \n    return DataStatistics4.correlation_coefficient(outliers_removed_data1, outliers_removed_data2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    from scipy import stats\n    if len(data1) != len(data2):\n        raise ValueError(\"Both data arrays must have the same length\")\n    z_scores1 = abs(stats.zscore(data1))\n    z_scores2 = abs(stats.zscore(data2))\n\n    filtered_data1 = [data1[i] for i in range(len(data1)) if z_scores1[i] <= 2]\n    filtered_data2 = [data2[i] for i in range(len(data2)) if z_scores2[i] <= 2]\n    \n    return stats.pearsonr(filtered_data1, filtered_data2)[0]",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Determine the robust correlation coefficient between two data arrays 'data1' and 'data2' by first excluding outliers, which are points greater than two standard deviations from the average in either of the dataset. The result should be returned as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The robust correlation coefficient, float.\n    \"\"\"\n    # calculate mean and standard deviation\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n    std_dev1 = math.sqrt(sum((x - mean1) ** 2 for x in data1) / len(data1))\n    std_dev2 = math.sqrt(sum((x - mean2) ** 2 for x in data2) / len(data2))\n\n    # exclude outliers\n    data1_clean = [x for x in data1 if abs(x - mean1) < 2 * std_dev1]\n    data2_clean = [x for x in data2 if abs(x - mean2) < 2 * std_dev2]\n\n    # calculate correlation coefficient\n    correlation_coefficient = sum((x - mean1) * (y - mean2) for x, y in zip(data1_clean, data2_clean)) / (\n        len(data1_clean) * std_dev1 * std_dev2)\n\n    return correlation_coefficient",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    std_dev_1 = math.sqrt(sum((x - mean_1) ** 2 for x in data1) / len(data1))\n    std_dev_2 = math.sqrt(sum((x - mean_2) ** 2 for x in data2) / len(data2))\n    \n    filtered_data1 = [x for x in data1 if abs(x - mean_1) <= 2 * std_dev_1]\n    filtered_data2 = [x for x in data2 if abs(x - mean_2) <= 2 * std_dev_2]\n    \n    if len(filtered_data1) == 0 or len(filtered_data2) == 0:\n        return 0.0\n    \n    mean_1 = sum(filtered_data1) / len(filtered_data1)\n    mean_2 = sum(filtered_data2) / len(filtered_data2)\n    \n    numerator = sum((x - mean_1) * (y - mean_2) for x, y in zip(filtered_data1, filtered_data2))\n    denominator = math.sqrt(sum((x - mean_1) ** 2 for x in filtered_data1) * sum((x - mean_2) ** 2 for x in filtered_data2))\n    \n    return numerator / denominator if denominator != 0 else 0.0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, mean2 = sum(data1) / len(data1), sum(data2) / len(data2)\n    std1, std2 = math.sqrt(sum((x - mean1) ** 2 for x in data1) / len(data1)), math.sqrt(sum((x - mean2) ** 2 for x in data2) / len(data2))\n    z_scores1, z_scores2 = [(x - mean1) / std1 for x in data1], [(x - mean2) / std2 for x in data2]\n    filtered1, filtered2 = [x for x, z in zip(data1, z_scores1) if abs(z) <= 2], [x for x, z in zip(data2, z_scores2) if abs(z) <= 2]\n    return sum((x - mean1) * (y - mean2) for x, y in zip(filtered1, filtered2)) / (len(filtered1) - 1) / (std1 * std2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    For two sequences of data, 'data1' and 'data2', calculate the correlation coefficient after discarding outliers. Outliers are identified as values more than two standard deviations above the mean in either of the dataset. Output the correlation coefficient as a type float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    if not (isinstance(data1, list) and isinstance(data2, list)):\n        raise TypeError(\"Inputs should be lists\")\n    if len(data1) != len(data2):\n        raise ValueError(\"Input lists should have the same length\")\n    \n    mean1, mean2 = sum(data1) / len(data1), sum(data2) / len(data2)\n    stddev1, stddev2 = math.sqrt(sum((x - mean1) ** 2 for x in data1) / len(data1)), math.sqrt(sum((x - mean2) ** 2 for x in data2) / len(data2))\n    zscores1, zscores2 = [(x - mean1) / stddev1 for x in data1], [(x - mean2) / stddev2 for x in data2]\n    \n    outliers1, outliers2 = [x for x in zscores1 if abs(x) > 2], [x for x in zscores2 if abs(x) > 2]\n    data1, data2 = [x for i, x in enumerate(data1) if zscores1[i] not in outliers1], [x for i, x in enumerate(data2) if zscores2[i] not in outliers2]\n    \n    if len(data1) == 0 or len(data2) == 0:\n        raise ValueError(\"Datasets after removing outliers should not be empty\")\n    \n    mean1, mean2 = sum(data1) / len(data1), sum(data2) / len(data2)\n    return sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2)) / math.sqrt(sum((x - mean1) ** 2 for x in data1) * sum((x - mean2) ** 2 for x in data2))",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    from scipy import stats\n    if len(data1) != len(data2):\n        raise ValueError(\"Both data sets must have the same length\")\n    mean_data1 = sum(data1) / len(data1)\n    std_dev_data1 = math.sqrt(sum((x - mean_data1) ** 2 for x in data1) / len(data1))\n    mean_data2 = sum(data2) / len(data2)\n    std_dev_data2 = math.sqrt(sum((x - mean_data2) ** 2 for x in data2) / len(data2))\n    data1_clean = [x for x in data1 if abs(x - mean_data1) <= 2 * std_dev_data1]\n    data2_clean = [x for x in data2 if abs(x - mean_data2) <= 2 * std_dev_data2]\n    return stats.pearsonr(data1_clean, data2_clean)[0]",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    For two sequences of data, 'data1' and 'data2', calculate the correlation coefficient after discarding outliers. Outliers are identified as values more than two standard deviations above the mean in either of the dataset. Output the correlation coefficient as a type float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Combine data\n    combined_data = list(zip(data1, data2))\n    \n    # Calculate mean and standard deviation for each dataset\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n    std_dev1 = math.sqrt(sum((i - mean1) ** 2 for i in data1) / len(data1))\n    std_dev2 = math.sqrt(sum((i - mean2) ** 2 for i in data2) / len(data2))\n    \n    # Compute z-scores\n    z_scores1 = [(i - mean1) / std_dev1 for i, _ in combined_data]\n    z_scores2 = [(i - mean2) / std_dev2 for _, i in combined_data]\n    \n    # Identify outliers and exclude them from the correlation calculation\n    combined_data = [(x1, x2) for x1, x2 in combined_data if abs(z_scores1[i]) <= 2 and abs(z_scores2[i]) <= 2]\n\n    # Calculate the correlation coefficient\n    if len(combined_data) < 1:  # return 0 if no valid points are found\n        return 0\n    else:\n        return sum((x - mean1) * (y - mean2) for x, y in combined_data) / (len(combined_data) * std_dev1 * std_dev2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    var_1 = sum((x - mean_1) ** 2 for x in data1) / len(data1)\n    var_2 = sum((x - mean_2) ** 2 for x in data2) / len(data2)\n    stddev_1 = math.sqrt(var_1)\n    stddev_2 = math.sqrt(var_2)\n    \n    # Calculating outlier threshold\n    threshold = 2 * stddev_1 \n    new_data1 = [x for x in data1 if abs(x - mean_1) <= threshold]\n    threshold = 2 * stddev_2\n    new_data2 = [x for x in data2 if abs(x - mean_2) <= threshold]\n\n    # Calculating correlation coefficient\n    N = len(new_data1)\n    sum_xy = sum(x * y for x, y in zip(new_data1, new_data2))\n    sum_x = sum(new_data1)\n    sum_y = sum(new_data2)\n    sum_x_sq = sum(x**2 for x in new_data1)\n    sum_y_sq = sum(y**2 for y in new_data2)\n    corr_coeff = (N * sum_xy - sum_x * sum_y) / math.sqrt((N * sum_x_sq - sum_x ** 2) * (N * sum_y_sq - sum_y ** 2))\n\n    return corr_coeff",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, mean2 = sum(data1) / len(data1), sum(data2) / len(data2)\n    stddev1, stddev2 = math.sqrt(sum((x - mean1) ** 2 for x in data1) / len(data1)), math.sqrt(sum((x - mean2) ** 2 for x in data2) / len(data2))\n    z_scores1 = [(x - mean1) / stddev1 for x in data1]\n    z_scores2 = [(x - mean2) / stddev2 for x in data2]\n    cleaned1 = [x for x, z in zip(data1, z_scores1) if abs(z) <= 2]\n    cleaned2 = [x for x, z in zip(data2, z_scores2) if abs(z) <= 2]\n    return DataStatistics4.correlation_coefficient(cleaned1, cleaned2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Measure the correlation coefficient for two data collections, 'data1' and 'data2', after removing data points that are over two standard deviations from the mean as outliers in either of the dataset. The result needs to be a float representing the correlation coefficient.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    def standardize(data):\n        \"\"\"\n        Standardizes the data by subtracting the mean and dividing by the standard deviation\n        :param data: The data to be standardized, list\n        :return: The standardized data, list\n        \"\"\"\n        mean = sum(data)/len(data)\n        std_dev = (sum((x-mean)**2 for x in data)/len(data))**0.5\n        return [(x-mean)/std_dev for x in data]\n\n    def z_score(data):\n        \"\"\"\n        Calculates the z-score of each data point\n        :param data: The data to calculate z-scores, list\n        :return: The z-scores of the data points, list\n        \"\"\"\n        mean = sum(data)/len(data)\n        std_dev = (sum((x-mean)**2 for x in data)/len(data))**0.5\n        return [(x-mean)/std_dev for x in data]\n\n    # Standardize the data\n    data1 = standardize(data1)\n    data2 = standardize(data2)\n\n    # Calculate the z-scores\n    z_scores1 = z_score(data1)\n    z_scores2 = z_score(data2)\n\n    # Remove outliers\n    inliers1 = [z_scores1[i] for i in range(len(z_scores1)) if abs(z_scores1[i]) <= 2]\n    inliers2 = [z_scores2[i] for i in range(len(z_scores2)) if abs(z_scores2[i]) <= 2]\n\n    # Calculate the correlation coefficient\n    n = len(inliers1)\n    up = sum([a*b for a, b in zip(inliers1, inliers2)]) - n*inliers1[0]*inliers2[0]/n\n    down = math.sqrt((sum([a**2 for a in inliers1]) - n*inliers1[0]**2/n) * (sum([a**2 for a in inliers2]) - n*inliers2[0]**2/n))\n    return up / down",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    from scipy import stats\n    if len(data1) != len(data2):\n        raise ValueError(\"Both data sets must have the same length\")\n    mean_data1 = sum(data1) / len(data1)\n    std_dev_data1 = math.sqrt(sum((x - mean_data1) ** 2 for x in data1) / len(data1))\n    mean_data2 = sum(data2) / len(data2)\n    std_dev_data2 = math.sqrt(sum((x - mean_data2) ** 2 for x in data2) / len(data2))\n    data1_clean = [x for x in data1 if abs(x - mean_data1) <= 2 * std_dev_data1]\n    data2_clean = [x for x in data2 if abs(x - mean_data2) <= 2 * std_dev_data2]\n    return stats.pearsonr(data1_clean, data2_clean)[0]",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Measure the correlation coefficient for two data collections, 'data1' and 'data2', after removing data points that are over two standard deviations from the mean as outliers in either of the dataset. The result needs to be a float representing the correlation coefficient.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # calculate mean and standard deviation\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n    std_dev1 = math.sqrt(sum((x - mean1) ** 2 for x in data1) / len(data1))\n    std_dev2 = math.sqrt(sum((x - mean2) ** 2 for x in data2) / len(data2))\n\n    # remove outliers\n    data1 = [x for x in data1 if abs((x - mean1) / std_dev1) <= 2]\n    data2 = [x for x in data2 if abs((x - mean2) / std_dev2) <= 2]\n\n    # calculate correlation coefficient\n    n = len(data1)\n    coeff = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2)) / (n - 1) / std_dev1 / std_dev2\n    return coeff",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    var_1 = sum((x - mean_1) ** 2 for x in data1) / len(data1)\n    var_2 = sum((x - mean_2) ** 2 for x in data2) / len(data2)\n    stddev_1 = math.sqrt(var_1)\n    stddev_2 = math.sqrt(var_2)\n    \n    # Calculate Z-Score for each data point\n    z_scores_1 = [(x - mean_1) / stddev_1 for x in data1]\n    z_scores_2 = [(x - mean_2) / stddev_2 for x in data2]\n    \n    clean_data1 = [x for x, z in zip(data1, z_scores_1) if abs(z) < 2]\n    clean_data2 = [x for x, z in zip(data2, z_scores_2) if abs(z) < 2]\n    \n    correlation_coefficient = sum((x - mean_1) * (y - mean_2) for x, y in zip(clean_data1, clean_data2)) / math.sqrt(sum((x - mean_1) ** 2 for x in clean_data1) * sum((x - mean_2) ** 2 for x in clean_data2))\n    \n    return correlation_coefficient",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, std1 = mean_and_std(data1)\n    mean2, std2 = mean_and_std(data2)\n    \n    data1 = [(x-mean1) for x in data1 if abs((x-mean1)/std1)<=2]\n    data2 = [(x-mean2) for x in data2 if abs((x-mean2)/std2)<=2]\n\n    n = len(data1)\n    sum_xy = sum([data1[i]*data2[i] for i in range(n)])\n    sum_x = sum(data1)\n    sum_y = sum(data2)\n    sum_x2 = sum([i**2 for i in data1])\n    sum_y2 = sum([i**2 for i in data2])\n\n    numerator = n*sum_xy - sum_x*sum_y\n    denominator = math.sqrt((n*sum_x2 - sum_x**2)*(n*sum_y2 - sum_y**2))\n    if denominator != 0:\n        return numerator / denominator\n    else:\n        return 0\n\ndef mean_and_std(data):\n    n = len(data)\n    mean = sum(data)/n\n    std = math.sqrt(sum([(x - mean)**2 for x in data])/n)\n    return mean, std",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Assess the correlation coefficient for the datasets 'data1' and 'data2' after filtering out outliers, where outliers are defined as those points surpassing two standard deviations from their mean value in either of the dataset. Return the computed correlation coefficient as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Calculate the mean of each dataset\n    mu1 = sum(data1) / len(data1)\n    mu2 = sum(data2) / len(data2)\n\n    # Calculate the standard deviation of each dataset\n    sd1 = math.sqrt(sum([(i - mu1) ** 2 for i in data1]) / len(data1))\n    sd2 = math.sqrt(sum([(i - mu2) ** 2 for i in data2]) / len(data2))\n\n    # Calculate the covariance of the two datasets\n    cov = sum([(data1[i] - mu1) * (data2[i] - mu2) for i in range(len(data1))]) / len(data1)\n\n    # Calculate the correlation coefficient\n    r = cov / (sd1 * sd2)\n\n    return r",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    from scipy import stats\n    if len(data1) != len(data2):\n        raise ValueError(\"Both datasets should have the same length.\")\n    z_scores1 = stats.zscore(data1)\n    z_scores2 = stats.zscore(data2)\n    filtered1 = [i for i in data1 if abs(i - (sum(z_scores1) / len(z_scores1))) < 2]\n    filtered2 = [i for i in data2 if abs(i - (sum(z_scores2) / len(z_scores2))) < 2]\n    if len(filtered1) < 2 or len(filtered2) < 2:\n        return \"Not enough valid data. Cannot calculate correlation.\"\n    return stats.pearsonr(filtered1, filtered2)[0]",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Assess the correlation coefficient for the datasets 'data1' and 'data2' after filtering out outliers, where outliers are defined as those points surpassing two standard deviations from their mean value in either of the dataset. Return the computed correlation coefficient as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Combine the two datasets\n    combined_data = data1 + data2\n\n    # Calculate the mean and standard deviation for the combined dataset\n    mean = sum(combined_data) / len(combined_data)\n    std_dev = (sum((xi - mean) ** 2 for xi in combined_data) / len(combined_data)) ** 0.5\n\n    # Filter out the outliers\n    filtered_data1 = [xi for xi in data1 if mean - 2 * std_dev <= xi <= mean + 2 * std_dev]\n    filtered_data2 = [xi for xi in data2 if mean - 2 * std_dev <= xi <= mean + 2 * std_dev]\n\n    # Calculate the correlation coefficient for the filtered data\n    n = len(filtered_data1)\n    numerator = sum((xi - sum(filtered_data1) / n) * (yi - sum(filtered_data2) / n) for xi, yi in zip(filtered_data1, filtered_data2))\n    denominator = (sum((xi - sum(filtered_data1) / n) ** 2 for xi in filtered_data1) * sum((yi - sum(filtered_data2) / n) ** 2 for yi in filtered_data2)) ** 0.5\n\n    return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    var_1 = sum((x - mean_1) ** 2 for x in data1) / len(data1)\n    var_2 = sum((x - mean_2) ** 2 for x in data2) / len(data2)\n    stddev_1 = math.sqrt(var_1)\n    stddev_2 = math.sqrt(var_2)\n    \n    # Calculating outlier threshold\n    threshold = 2 * stddev_1 \n    new_data1 = [x for x in data1 if abs(x - mean_1) <= threshold]\n    threshold = 2 * stddev_2\n    new_data2 = [x for x in data2 if abs(x - mean_2) <= threshold]\n\n    # Calculating correlation coefficient\n    N = len(new_data1)\n    sum_xy = sum(x * y for x, y in zip(new_data1, new_data2))\n    sum_x = sum(new_data1)\n    sum_y = sum(new_data2)\n    sum_x_sq = sum(x**2 for x in new_data1)\n    sum_y_sq = sum(y**2 for y in new_data2)\n    corr_coeff = (N * sum_xy - sum_x * sum_y) / math.sqrt((N * sum_x_sq - sum_x ** 2) * (N * sum_y_sq - sum_y ** 2))\n\n    return corr_coeff",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, std1 = mean_and_std(data1)\n    mean2, std2 = mean_and_std(data2)\n    \n    filtered_data1 = [x for x in data1 if (x > mean1-2*std1 and x < mean1+2*std1)]\n    filtered_data2 = [x for x in data2 if (x > mean2-2*std2 and x < mean2+2*std2)]\n\n    covariance = sum((x-mean1)*(y-mean2) for x, y in zip(filtered_data1, filtered_data2)) / len(filtered_data1)\n    correlation_coefficient = covariance / (std1 * std2)\n    return correlation_coefficient\n\ndef mean_and_std(data):\n    n = len(data)\n    mean = sum(data) / n\n    std_dev = math.sqrt(sum((x - mean) ** 2 for x in data) / n)\n    return mean, std_dev",
                false
            ]
        ],
        "level 2": [
            [
                "def robust_correlation_coefficient(data1, data2):\n    def identify_and_remove_outliers(data):\n        mean = sum(data) / len(data)\n        std_dev = math.sqrt(sum((x - mean) ** 2 for x in data) / len(data))\n        return [x for x in data if abs(x - mean) <= 2 * std_dev]\n\n    data1 = identify_and_remove_outliers(data1)\n    data2 = identify_and_remove_outliers(data2)\n\n    if not data1 or not data2:  # If either data set is empty after outlier removal\n        return 0\n\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    denominator = math.sqrt(sum((x - mean1) ** 2 for x in data1) * sum((y - mean2) ** 2 for y in data2))\n\n    if denominator == 0:  # Avoid division by zero\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outliers(data):\n        mean = sum(data) / len(data)\n        std_dev = (sum((xi - mean) ** 2 for xi in data) / len(data)) ** 0.5\n        return [x for x in data if abs(x - mean) <= 2 * std_dev]\n\n    data1 = remove_outliers(data1)\n    data2 = remove_outliers(data2)\n\n    if len(data1) == 0 or len(data2) == 0:\n        return 0\n\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n\n    numerator = sum((xi - mean1) * (yi - mean2) for xi, yi in zip(data1, data2))\n    denominator = (len(data1) * sum((xi - mean1) ** 2 for xi in data1) * len(data2) * sum((yi - mean2) ** 2 for yi in data2)) ** 0.5\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Calculate the robust correlation coefficient for two sets of data \"data1\" and \"data2\" after removing outliers from both datasets. Outliers are defined as data points that are strictly more than two standard deviations away from the mean in either of the dataset. The function starts using a helper function to identify and remove the points from \"data1\" and \"data2\" that are outliers either in \"data1\" or in \"data2\". After cleaning the data of outliers, it calculates the mean of both datasets. Using these means, the function then computes the robust correlation coefficient. If the denominator in this calculation is zero, it returns 0 to avoid division errors. Otherwise, it returns the robust correlation coefficient as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The robust correlation coefficient, float.\n    \"\"\"\n    def is_outlier(point, data):\n        mean = sum(data) / len(data)\n        variance = sum([((x - mean) ** 2) for x in data]) / len(data)\n        return abs(point - mean) > 2 * math.sqrt(variance)\n\n    def remove_outliers(data):\n        return [point for point in data if not is_outlier(point, data)]\n\n    data1, data2 = remove_outliers(data1), remove_outliers(data2)\n    mean_data1, mean_data2 = sum(data1) / len(data1), sum(data2) / len(data2)\n    covariance = sum([(x - mean_data1) * (y - mean_data2) for x, y in zip(data1, data2)]) / len(data1)\n    std_dev_data1, std_dev_data2 = math.sqrt(sum([(x - mean_data1) ** 2 for x in data1]) / len(data1)), math.sqrt(sum([(x - mean_data2) ** 2 for x in data2]) / len(data2))\n\n    if std_dev_data1 * std_dev_data2 == 0:\n        return 0\n    else:\n        return covariance / (std_dev_data1 * std_dev_data2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, mean2 = st.mean(data1), st.mean(data2)\n    std_dev1, std_dev2 = st.std_dev(data1), st.std_dev(data2)\n    z_score_threshold = 2 # one standard deviation away\n\n    # Remove outliers\n    data1 = [x for x in data1 if (x - mean1) / std_dev1 < z_score_threshold]\n    data2 = [y for y in data2 if (y - mean2) / std_dev2 < z_score_threshold]\n\n    # Compute the correlation coefficient\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    denominator = (len(data1) * sum((x - mean1) ** 2 for x in data1) * len(data2) * sum((y - mean2) ** 2 for y in data2)) ** 0.5\n    \n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outliers(data):\n        mean = sum(data) / len(data)\n        std_dev = sum((x - mean) ** 2 for x in data) / len(data)\n        std_dev = math.sqrt(std_dev)\n        return [x for x in data if abs(x - mean) <= 2 * std_dev]\n\n    data1 = remove_outliers(data1)\n    data2 = remove_outliers(data2)\n\n    if len(data1) == 0 or len(data2) == 0:\n        return 0\n\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    denominator = math.sqrt(sum((x - mean1) ** 2 for x in data1) * sum((y - mean2) ** 2 for y in data2))\n\n    return numerator / denominator if denominator else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outliers(data, mean, std_dev):\n        return [value for value in data if abs(value-mean) <= 2*std_dev]\n\n    def calculate_mean(data):\n        return sum(data) / len(data)\n\n    def calculate_std_dev(data, mean):\n        return math.sqrt(sum([(x - mean) ** 2 for x in data]) / len(data))\n\n    def calculate_correlation_coefficient(data1, data2):\n        n = len(data1)\n        mean1 = calculate_mean(data1)\n        mean2 = calculate_mean(data2)\n        std_dev1 = calculate_std_dev(data1, mean1)\n        std_dev2 = calculate_std_dev(data2, mean2)\n\n        if std_dev1 == 0 or std_dev2 == 0:\n            return 0\n        else:\n            numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n            return numerator / (std_dev1 * std_dev2 * n)\n\n    data1 = remove_outliers(data1, calculate_mean(data1), calculate_std_dev(data1, calculate_mean(data1)))\n    data2 = remove_outliers(data2, calculate_mean(data2), calculate_std_dev(data2, calculate_mean(data2)))\n\n    return calculate_correlation_coefficient(data1, data2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    from scipy import stats\n    import numpy as np\n\n    # Calculating z-scores\n    z1 = np.abs(stats.zscore(data1))\n    z2 = np.abs(stats.zscore(data2))\n\n    # Filtering outliers\n    data1 = [i for i in data1 if i > -3 * np.std(data1) + np.mean(data1) or i < np.std(data1) - np.mean(data1)]\n    data2 = [i for i in data2 if i > -3 * np.std(data2) + np.mean(data2) or i < np.std(data2) - np.mean(data2)]\n\n    # Calculating correlation coefficient\n    corr_coef = np.corrcoef(data1, data2)[0, 1]\n\n    # Handling division by zero\n    if np.var(data1) == 0 or np.var(data2) == 0:\n        return 0\n    return corr_coef",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Determine the correlation coefficient for two data arrays 'data1' and 'data2' by first eliminating outliers. Outliers are points greater than two standard deviations from the mean in any of the datasets. Initially, a subordinate function sorts out these outliers from both 'data1' and 'data2'. Post outlier-removal, compute each dataset's mean, and then the correlation coefficient is calculated from these means. If the calculation\u2019s denominator is zero, return 0 to prevent division by zero; otherwise, provide the correlation coefficient as a floating-point number.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    \n    def calc_mean(data):\n        \"\"\"\n        Calculate the mean of the data.\n        :param data: The dataset, list.\n        :return: The mean of the data, float.\n        \"\"\"\n        return sum(data) / len(data)\n        \n    def calc_std_dev(data, mean):\n        \"\"\"\n        Calculate the standard deviation of the data.\n        :param data: The dataset, list.\n        :param mean: The mean of the data, float.\n        :return: The standard deviation of the data, float.\n        \"\"\"\n        return math.sqrt(sum((x - mean) ** 2 for x in data) / len(data))\n        \n    def remove_outliers(data, mean, std_dev):\n        \"\"\"\n        Remove outliers from the data.\n        :param data: The dataset, list.\n        :param mean: The mean of the data, float.\n        :param std_dev: The standard deviation of the data, float.\n        :return: The dataset without outliers, list.\n        \"\"\"\n        return [x for x in data if abs(x - mean) <= 2 * std_dev]\n      \n    mean1, mean2 = calc_mean(data1), calc_mean(data2)\n    std_dev1, std_dev2 = calc_std_dev(data1, mean1), calc_std_dev(data2, mean2)\n    data1, data2 = remove_outliers(data1, mean1, std_dev1), remove_outliers(data2, mean2, std_dev2)\n    \n    if not data1 or not data2:\n        return 0\n    \n    mean1, mean2 = calc_mean(data1), calc_mean(data2)\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    denominator = len(data1) * calc_std_dev(data1, mean1) * calc_std_dev(data2, mean2)\n    \n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, mean2 = st.mean(data1), st.mean(data2)\n    std_dev1, std_dev2 = st.std_dev(data1), st.std_dev(data2)\n    z_score_threshold = 2 # one standard deviation\n    trimmed_data1 = [x for x in data1 if abs((x-mean1)/std_dev1) < z_score_threshold]\n    trimmed_data2 = [x for x in data2 if abs((x-mean2)/std_dev2) < z_score_threshold]\n\n    if len(trimmed_data1) == 0 or len(trimmed_data2) == 0:\n        return 0\n\n    mean1, mean2 = st.mean(trimmed_data1), st.mean(trimmed_data2)\n\n    numerator = sum((xi - mean1) * (yi - mean2) for xi, yi in zip(trimmed_data1, trimmed_data2))\n    denominator = len(trimmed_data1) * st.std_dev(trimmed_data1) * st.std_dev(trimmed_data2)\n\n    if denominator == 0:\n        return 0\n\n    return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, std1 = DataStatistics4.mean_and_stddev(data1)\n    mean2, std2 = DataStatistics4.mean_and_stddev(data2)\n    \n    numerator = sum([(x - mean1) * (y - mean2) for x, y in zip(data1, data2)])\n    denominator = len(data1) * std1 * std2\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator\n\ndef mean_and_stddev(data):\n    mean = sum(data) / len(data)\n    stddev = math.sqrt(sum((x - mean) ** 2 for x in data) / (len(data) - 1))\n    return mean, stddev",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def filter_outliers(data, mean, std_dev):\n        return [value for value in data if abs(value-mean) <= 2*std_dev]\n\n    def calculate_mean(data):\n        return sum(data) / len(data)\n\n    def calculate_std_dev(data, mean):\n        return math.sqrt(sum([(x - mean) ** 2 for x in data]) / len(data))\n\n    def calculate_correlation_coefficient(data1, data2):\n        n = len(data1)\n        mean1 = calculate_mean(data1)\n        mean2 = calculate_mean(data2)\n        std_dev1 = calculate_std_dev(data1, mean1)\n        std_dev2 = calculate_std_dev(data2, mean2)\n\n        if std_dev1 == 0 or std_dev2 == 0:\n            return 0\n        else:\n            numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n            return numerator / (n * std_dev1 * std_dev2)\n\n    filtered_data1 = filter_outliers(data1, calculate_mean(data1), calculate_std_dev(data1, calculate_mean(data1)))\n    filtered_data2 = filter_outliers(data2, calculate_mean(data2), calculate_std_dev(data2, calculate_mean(data2)))\n\n    return calculate_correlation_coefficient(filtered_data1, filtered_data2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outliers(data):\n        mean = sum(data) / len(data)\n        sd = math.sqrt(sum((x - mean) ** 2 for x in data) / len(data))\n        return [x for x in data if (mean - 2 * sd) <= x <= (mean + 2 * sd)]\n\n    cleaned_data1 = remove_outliers(data1)\n    cleaned_data2 = remove_outliers(data2)\n\n    if not cleaned_data1 or not cleaned_data2:\n        return 0\n\n    x_bar = sum(cleaned_data1) / len(cleaned_data1)\n    y_bar = sum(cleaned_data2) / len(cleaned_data2)\n\n    numerator = sum((xi - x_bar) * (yi - y_bar) for xi, yi in zip(cleaned_data1, cleaned_data2))\n    denominator = math.sqrt(sum((xi - x_bar) ** 2 for xi in cleaned_data1) * sum((yi - y_bar) ** 2 for yi in cleaned_data2))\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Find the correlation coefficient for two sample sets 'data1' and 'data2' following outlier removal in each. Outliers are classified as values more than two standard deviations from the mean. A nested function first filters out these outliers from both data sets. Subsequently, the mean of each cleansed data set is computed. Using the means, calculate the correlation coefficient. If the denominator is zero during this process, output 0 to prevent division issues, but normally it returns the correlation coefficient as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    def filter_outliers(data):\n        \"\"\"\n        Function to filter outliers from a list of data. Outliers are identified as values more than two standard deviations from the mean.\n        :param data: Input list of data.\n        :return: A cleaned list with outliers removed.\n        \"\"\"\n        mean = sum(data) / len(data)\n        standard_deviation = math.sqrt(sum((x - mean) ** 2 for x in data) / len(data))\n        return [x for x in data if (mean - 2 * standard_deviation) <= x <= (mean + 2 * standard_deviation)]\n\n    cleaned_data1 = filter_outliers(data1)\n    cleaned_data2 = filter_outliers(data2)\n\n    if len(cleaned_data1) < 2 or len(cleaned_data2) < 2:\n        # If there are no cleaned data to calculate correlation, return 0\n        return 0\n\n    mean1 = sum(cleaned_data1) / len(cleaned_data1)\n    mean2 = sum(cleaned_data2) / len(cleaned_data2)\n\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(cleaned_data1, cleaned_data2))\n    denominator = math.sqrt(sum((x - mean1) ** 2 for x in cleaned_data1) * sum((x - mean2) ** 2 for x in cleaned_data2))\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, mean2 = np.mean(data1), np.mean(data2)\n    std1, std2 = np.std(data1), np.std(data2)\n    outliers = 2\n    data1 = [x for x in data1 if abs((x - mean1) / std1) <= outliers]\n    data2 = [x for x in data2 if abs((x - mean2) / std2) <= outliers]\n    mean1, mean2 = np.mean(data1), np.mean(data2)\n    std1, std2 = np.std(data1), np.std(data2)\n    if std1 != 0 and std2 != 0:\n        return sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2)) / (len(data1) * std1 * std2)\n    else:\n        return 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outliers(data):\n        mean = sum(data) / len(data)\n        std_dev = sum((x - mean) ** 2 for x in data) / len(data)\n        std_dev = math.sqrt(std_dev)\n        return [x for x in data if abs(x - mean) <= 2 * std_dev]\n\n    data1 = remove_outliers(data1)\n    data2 = remove_outliers(data2)\n\n    if len(data1) == 0 or len(data2) == 0:\n        return 0\n\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    denominator = math.sqrt(sum((x - mean1) ** 2 for x in data1) * sum((y - mean2) ** 2 for y in data2))\n\n    return numerator / denominator if denominator else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outliers(data, mean, std_dev):\n        return [value for value in data if abs(value-mean) < 2*std_dev]\n\n    def calculate_mean(data):\n        return sum(data) / len(data)\n\n    data1 = remove_outliers(data1, calculate_mean(data1), math.sqrt(sum((i-calculate_mean(data1))**2 for i in data1) / (len(data1)-1)))\n    data2 = remove_outliers(data2, calculate_mean(data2), math.sqrt(sum((i-calculate_mean(data2))**2 for i in data2) / (len(data2)-1)))\n\n    mean1, mean2 = calculate_mean(data1), calculate_mean(data2)\n    return sum((i-mean1)*(j-mean2) for i,j in zip(data1, data2)) / math.sqrt(sum((i-mean1)**2 for i in data1) * sum((i-mean2)**2 for i in data2)) if sum((i-mean1)**2 for i in data1) * sum((i-mean2)**2 for i in data2) != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outliers(data):\n        mean = sum(data) / len(data)\n        std_dev = (sum((xi - mean) ** 2 for xi in data) / len(data)) ** 0.5\n        return [x for x in data if abs(x - mean) <= 2 * std_dev]\n\n    data1 = remove_outliers(data1)\n    data2 = remove_outliers(data2)\n\n    if len(data1) == 0 or len(data2) == 0:\n        return 0\n\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n\n    numerator = sum((xi - mean1) * (yi - mean2) for xi, yi in zip(data1, data2))\n    denominator = (len(data1) * sum((xi - mean1) ** 2 for xi in data1) * len(data2) * sum((yi - mean2) ** 2 for yi in data2)) ** 0.5\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Compute the robust correlation coefficient for two collections of data, 'data1' and 'data2', excluding outliers. Outliers are specified as being over two standard deviations from the mean in either collection. Initially, a helper function is employed to eliminate these outliers from both 'data1' and 'data2'. After purging the outliers, calculate the means of both adjusted datasets. The correlation coefficient is then derived from these means. If zero occurs in the denominator of the computation, return 0; otherwise, provide the calculated coefficient as a decimal.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The robust correlation coefficient, float.\n    \"\"\"\n    def remove_outliers(data):\n        mean = sum(data) / len(data)\n        std_dev = math.sqrt(sum((x - mean) ** 2 for x in data) / len(data))\n        data = [x for x in data if abs(x - mean) <= 2 * std_dev]\n        return data\n\n    data1 = remove_outliers(data1)\n    data2 = remove_outliers(data2)\n\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n\n    covariance = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2)) / len(data1)\n    variance1 = sum((x - mean1) ** 2 for x in data1) / len(data1)\n    variance2 = sum((x - mean2) ** 2 for x in data2) / len(data2)\n\n    if variance1 * variance2 == 0:\n        return 0\n    else:\n        return covariance / math.sqrt(variance1 * variance2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    var_1 = sum((x - mean_1) ** 2 for x in data1) / len(data1)\n    var_2 = sum((x - mean_2) ** 2 for x in data2) / len(data2)\n    cov = sum((x - mean_1) * (y - mean_2) for x, y in zip(data1, data2)) / len(data1)\n    std_dev1 = var_1 ** 0.5\n    std_dev2 = var_2 ** 0.5\n\n    if std_dev1 * std_dev2 == 0:\n        return 0\n    else:\n        return cov / (std_dev1 * std_dev2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outliers(data):\n        mean = sum(data) / len(data)\n        std_dev = sum((x - mean) ** 2 for x in data) / len(data)\n        std_dev = math.sqrt(std_dev)\n        return [x for x in data if abs(x - mean) <= 2 * std_dev]\n\n    data1 = remove_outliers(data1)\n    data2 = remove_outliers(data2)\n\n    if len(data1) == 0 or len(data2) == 0:\n        return 0\n\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    denominator = math.sqrt(sum((x - mean1) ** 2 for x in data1) * sum((y - mean2) ** 2 for y in data2))\n\n    return numerator / denominator if denominator else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mu1 = sum(data1) / len(data1)\n    mu2 = sum(data2) / len(data2)\n    std1 = math.sqrt((1 / len(data1) * sum((i - mu1) ** 2 for i in data1)))\n    std2 = math.sqrt((1 / len(data2) * sum((i - mu2) ** 2 for i in data2)))\n    \n    # Exclude outliers that exceed two standard deviations from their dataset's mean\n    data1 = [i for i in data1 if abs(i - mu1) <= 2 * std1]\n    data2 = [i for i in data2 if abs(i - mu2) <= 2 * std2]\n\n    new_mu1 = sum(data1) / len(data1) if data1 else 0\n    new_mu2 = sum(data2) / len(data2) if data2 else 0\n\n    new_std1 = math.sqrt((1 / len(data1) * sum((i - new_mu1) ** 2 for i in data1))) if data1 else 0\n    new_std2 = math.sqrt((1 / len(data2) * sum((i - new_mu2) ** 2 for i in data2))) if data2 else 0\n    \n    if new_std1 == 0 or new_std2 == 0:\n        return 0\n\n    correlation_coefficient = sum((x - new_mu1) * (y - new_mu2) for x, y in zip(data1, data2)) / (len(data1) * new_std1 * new_std2)\n    \n    return correlation_coefficient",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    from scipy import stats\n    import numpy as np\n\n    # Remove outliers that exceed two standard deviations from their dataset's mean\n    data1 = [x for x in data1 if abs(x - np.mean(data1)) < 2*np.std(data1)]\n    data2 = [x for x in data2 if abs(x - np.mean(data2)) < 2*np.std(data2)]\n\n    # Calculate the correlation coefficient\n    r, _ = stats.pearsonr(data1, data2)\n\n    return r if not np.isnan(r) else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Ascertain the correlation coefficient for two groups of data, 'data1' and 'data2', after removing outliers that exceed two standard deviations from their dataset's mean. A secondary function initializes this process by excluding such data points from both 'data1' and 'data2'. Following the removal of these outliers, both datasets' means are computed. Based on these computed means, the correlation coefficient is then calculated. If resultant denominator is zero, return a 0 to avert any division error; if not, the correlation coefficient is provided as a floating-point value.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # remove outlier points from both data sets\n    mean_data1 = sum(data1) / len(data1)\n    mean_data2 = sum(data2) / len(data2)\n\n    # calculating standard deviation\n    std_dev1 = math.sqrt(sum([((x - mean_data1) ** 2) for x in data1]) / len(data1))\n    std_dev2 = math.sqrt(sum([((x - mean_data2) ** 2) for x in data2]) / len(data2))\n\n    # create new datasets excluding outliers\n    cutoff = 2 * std_dev1\n    outliers_removed1 = [x for x in data1 if abs(x - mean_data1) <= cutoff]\n    cutoff = 2 * std_dev2\n    outliers_removed2 = [x for x in data2 if abs(x - mean_data2) <= cutoff]\n\n    # calculate correlation coefficient\n    mean_rmoutliers1 = sum(outliers_removed1) / len(outliers_removed1)\n    mean_rmoutliers2 = sum(outliers_removed2) / len(outliers_removed2)\n\n    covariance_removed = sum([(x - mean_rmoutliers1) * (y - mean_rmoutliers2) for x, y in zip(outliers_removed1, outliers_removed2)])\n    denominator = len(outliers_removed1) * std_dev1 * std_dev2\n\n    # avoid division by zero\n    if denominator == 0:\n        return 0\n    else:\n        return covariance_removed / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n\n    std_dev_1 = math.sqrt(sum((x - mean_1) ** 2 for x in data1) / len(data1))\n    std_dev_2 = math.sqrt(sum((x - mean_2) ** 2 for x in data2) / len(data2))\n\n    data1 = [x for x in data1 if abs(x - mean_1) <= 2 * std_dev_1]\n    data2 = [x for x in data2 if abs(x - mean_2) <= 2 * std_dev_2]\n\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n\n    if len(data1) <= 1 or len(data2) <= 1:\n        return 0\n\n    cov_sum = sum((x - mean_1) * (y - mean_2) for x, y in zip(data1, data2))\n    correlation_coefficient = cov_sum / ((len(data1) - 1) * std_dev_1 * std_dev_2)\n\n    return correlation_coefficient",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, mean2 = mean(data1), mean(data2)\n    std_dev1, std_dev2 = stdev(data1), stdev(data2)\n\n    if not std_dev1 or not std_dev2:\n        return 0\n\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    denominator = len(data1) * std_dev1 * std_dev2\n\n    return numerator / denominator\n\ndef mean(data):\n    return sum(data) / len(data)\n\ndef stdev(data):\n    m = mean(data)\n    return math.sqrt(sum((x - m) ** 2 for x in data) / len(data))",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def extract_outliers(data, mean, std_dev):\n        return [x for x in data if abs(x-mean) <= 2*std_dev]\n\n    def calculate_mean(data):\n        return sum(data) / len(data)\n\n    def calculate_std_dev(data, mean):\n        return math.sqrt(sum([(x - mean) ** 2 for x in data]) / len(data))\n\n    def calculate_correlation_coefficient(data1, data2):\n        n = len(data1)\n        mean1 = calculate_mean(data1)\n        mean2 = calculate_mean(data2)\n        std_dev1 = calculate_std_dev(data1, mean1)\n        std_dev2 = calculate_std_dev(data2, mean2)\n\n        if std_dev1 == 0 or std_dev2 == 0:\n            return 0\n        else:\n            numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n            return numerator / (std_dev1 * std_dev2 * n)\n\n    outliers1 = extract_outliers(data1, calculate_mean(data1), calculate_std_dev(data1, calculate_mean(data1)))\n    outliers2 = extract_outliers(data2, calculate_mean(data2), calculate_std_dev(data2, calculate_mean(data2)))\n\n    clean_data1 = [x for x in data1 if x not in outliers1]\n    clean_data2 = [x for x in data2 if x not in outliers2]\n\n    return calculate_correlation_coefficient(clean_data1, clean_data2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def extract_outliers(data):\n        mean = sum(data) / len(data)\n        sd = math.sqrt(sum((x - mean) ** 2 for x in data) / len(data))\n        outliers = [x for x in data if abs(x - mean) > 2 * sd]\n        return outliers\n\n    def calculate_mean(data):\n        return sum(data) / len(data)\n\n    def calculate_correlation_coefficient(x_mean, y_mean, x_data, y_data):\n        numerator = sum((xi - x_mean) * (yi - y_mean) for xi, yi in zip(x_data, y_data))\n        denominator = math.sqrt(sum((xi - x_mean)**2 for xi in x_data)) * math.sqrt(sum((yi - y_mean)**2 for yi in y_data))\n        return numerator / denominator if denominator != 0 else 0\n\n    outliers1 = extract_outliers(data1)\n    outliers2 = extract_outliers(data2)\n\n    data1 = [x for x in data1 if x not in outliers1]\n    data2 = [y for y in data2 if y not in outliers2]\n\n    x_mean = calculate_mean(data1)\n    y_mean = calculate_mean(data2)\n\n    return calculate_correlation_coefficient(x_mean, y_mean, data1, data2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Evaluate the correlation coefficient between 'data1' and 'data2' after discarding outliers in each dataset. Here, outliers are defined as entries significantly more than two standard deviations away from the mean. A helper function first extracts these outliers from both 'data1' and 'data2'. Then, mean values of the cleansed datasets are calculated. Subsequently, using these means, the correlation coefficient is computed. Return 0 if the correlation computation's denominator is zero to avoid a division error, else return the correlation coefficient as a float.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    def extract_outliers(data):\n        mean = sum(data)/len(data)\n        std_dev = math.sqrt(sum([(x - mean) ** 2 for x in data]) / len(data))\n        outliers = [x for x in data if abs(x - mean) > 2 * std_dev]\n        return outliers\n\n    outliers1 = extract_outliers(data1)\n    outliers2 = extract_outliers(data2)\n    \n    clean_data1 = [x for x in data1 if x not in outliers1]\n    clean_data2 = [x for x in data2 if x not in outliers2]\n\n    mean1 = sum(clean_data1)/len(clean_data1)\n    mean2 = sum(clean_data2)/len(clean_data2)\n\n    covariance = sum([(x - mean1) * (y - mean2) for x, y in zip(clean_data1, clean_data2)])\n    variance1 = sum([(x - mean1) ** 2 for x in clean_data1])\n    variance2 = sum([(y - mean2) ** 2 for y in clean_data2])\n\n    if variance1 * variance2 == 0:\n        return 0\n    else:\n        return covariance / math.sqrt(variance1 * variance2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    var_1 = sum((x - mean_1) ** 2 for x in data1)\n    var_2 = sum((x - mean_2) ** 2 for x in data2)\n    std_dev_1 = math.sqrt(var_1 / len(data1))\n    std_dev_2 = math.sqrt(var_2 / len(data2))\n    \n    # Calculating outliers\n    z_scores_1 = [(x - mean_1) / std_dev_1 for x in data1]\n    z_scores_2 = [(x - mean_2) / std_dev_2 for x in data2]\n    outliers_1 = [x for x, z in zip(data1, z_scores_1) if abs(z) > 2]\n    outliers_2 = [x for x, z in zip(data2, z_scores_2) if abs(z) > 2]\n    \n    # Removing outliers\n    data1 = [x for x in data1 if x not in outliers_1]\n    data2 = [x for x in data2 if x not in outliers_2]\n    \n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    var_1 = sum((x - mean_1) ** 2 for x in data1)\n    var_2 = sum((x - mean_2) ** 2 for x in data2)\n    std_dev_1 = math.sqrt(var_1 / len(data1))\n    std_dev_2 = math.sqrt(var_2 / len(data2))\n    cov = sum((x - mean_1) * (y - mean_2) for x, y in zip(data1, data2)) / len(data1)\n    \n    if std_dev_1 * std_dev_2 == 0:\n        return 0\n    else:\n        return cov / (std_dev_1 * std_dev_2)",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def extract_outliers(data):\n        mean = sum(data) / len(data)\n        std_dev = sum((x - mean) ** 2 for x in data) / len(data)\n        outliers = [x for x in data if abs(x - mean) > 2 * math.sqrt(std_dev)]\n        return outliers\n\n    def compute_means(data):\n        data = [x for x in data if x not in outliers]\n        return sum(data) / len(data)\n\n    outliers1 = extract_outliers(data1)\n    outliers2 = extract_outliers(data2)\n    outliers = outliers1 + outliers2\n\n    data1 = [x for x in data1 if x not in outliers]\n    data2 = [x for x in data2 if x not in outliers]\n    \n    mean1 = compute_means(data1)\n    mean2 = compute_means(data2)\n\n    covariance = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    std_dev1 = math.sqrt(sum((x - mean1) ** 2 for x in data1) / len(data1))\n    std_dev2 = math.sqrt(sum((x - mean2) ** 2 for x in data2) / len(data2))\n\n    if std_dev1 * std_dev2 == 0:\n        return 0\n    else:\n        return covariance / (std_dev1 * std_dev2)",
                false
            ]
        ],
        "level 3": [
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        mean = sum(data) / len(data)\n        std = math.sqrt(sum([(x - mean) ** 2 for x in data]) / len(data))\n        return [x for x in data if abs(x - mean) <= 2 * std]\n\n    data1 = remove_outlier(data1)\n    data2 = remove_outlier(data2)\n\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n\n    numerator = sum([(x - mean1) * (y - mean2) for x, y in zip(data1, data2)])\n\n    std1 = math.sqrt(sum([(x - mean1) ** 2 for x in data1]) / len(data1))\n    std2 = math.sqrt(sum([(x - mean2) ** 2 for x in data2]) / len(data2))\n\n    denominator = std1 * std2\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        mean = sum(data) / len(data)\n        std = math.sqrt(sum((i - mean) ** 2 for i in data) / len(data))\n        return [i for i in data if abs(i - mean) <= 2 * std]\n\n    cleaned_data1 = remove_outlier(data1)\n    cleaned_data2 = remove_outlier(data2)\n\n    mean1 = sum(cleaned_data1) / len(cleaned_data1)\n    mean2 = sum(cleaned_data2) / len(cleaned_data2)\n\n    numerator = sum((i - mean1) * (j - mean2) for i, j in zip(cleaned_data1, cleaned_data2))\n    std1 = math.sqrt(sum((i - mean1) ** 2 for i in cleaned_data1) / len(cleaned_data1))\n    std2 = math.sqrt(sum((i - mean2) ** 2 for i in cleaned_data2) / len(cleaned_data2))\n    denominator = std1 * std2\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Calculate the robust correlation coefficient for two sets of data \"data1\" and \"data2\". \n    The function begins by calculating the means and standard deviations for both \"data1\" and \"data2\".\n    Then it removes any data points that are more than two standard deviations above the mean in any of the sets of data.\n    After cleaning the data of outliers, it recalculates the means of both datasets (\"mean1\" and \"mean2\"). \n    Using these means, the function calculates the numerator of the correlation coefficient by multiplying the deviations from the mean of \"data1\" and \"data2\", then summing up these products. \n    It also calculates the denominator as the product of the standard deviations of \"data1\" and \"data2\". \n    Finally, it returns the correlation coefficient, which is the division of the numerator by the denominator. \n    If the denominator is zero, the function returns 0 to avoid division by zero errors.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # Calculate mean and standard deviation of data1\n    data1_mean = sum(data1) / len(data1)\n    data1_std = (sum((x - data1_mean) ** 2 for x in data1) / len(data1)) ** 0.5\n\n    # Calculate mean and standard deviation of data2\n    data2_mean = sum(data2) / len(data2)\n    data2_std = (sum((x - data2_mean) ** 2 for x in data2) / len(data2)) ** 0.5\n\n    # Remove outliers from both datasets\n    data1 = [x for x in data1 if abs((x - data1_mean) / data1_std) < 2]\n    data2 = [x for x in data2 if abs((x - data2_mean) / data2_std) < 2]\n\n    # Recalculate mean of data1 and data2\n    data1_mean = sum(data1) / len(data1)\n    data2_mean = sum(data2) / len(data2)\n\n    # Calculate numerator of correlation coefficient\n    numerator = sum((x - data1_mean) * (y - data2_mean) for x, y in zip(data1, data2))\n\n    # Calculate denominator of correlation coefficient\n    denominator = data1_std * data2_std * len(data1)\n\n    # If denominator is zero, return 0 to avoid division by zero errors\n    if denominator == 0:\n        return 0\n\n    # Return correlation coefficient\n    return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, std1 = st.mean(data1), st.stdev(data1)\n    mean2, std2 = st.mean(data2), st.stdev(data2)\n\n    data1 = [e for e in data1 if (e < mean1 + 2 * std1) and (e > mean1 - 2 * std1)]\n    data2 = [e for e in data2 if (e < mean2 + 2 * std2) and (e > mean2 - 2 * std2)]\n\n    mean1, mean2 = st.mean(data1), st.mean(data2)\n\n    numerator = sum((e - mean1) * (f - mean2) for e, f in zip(data1, data2))\n    denominator = math.sqrt(sum((e - mean1) ** 2 for e in data1)) * math.sqrt(sum((f - mean2) ** 2 for f in data2))\n\n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        mean = sum(data) / len(data)\n        std = math.sqrt(sum([(datum - mean) ** 2 for datum in data]) / len(data))\n        return [datum for datum in data if abs(datum - mean) <= 2 * std]\n\n    data1_outliers = [i for i in range(len(data1)) if data1[i] < min(data1) or data1[i] > max(data1)]\n    data2_outliers = [i for i in range(len(data2)) if data2[i] < min(data2) or data2[i] > max(data2)]\n\n    outliers = list(set(data1_outliers) & set(data2_outliers))\n    \n    data1_clean = [data1[i] for i in range(len(data1)) if i not in outliers]\n    data2_clean = [data2[i] for i in range(len(data2)) if i not in outliers]\n\n    mean1 = sum(data1_clean) / len(data1_clean)\n    mean2 = sum(data2_clean) / len(data2_clean)\n\n    numerator = sum([(data1_clean[i] - mean1) * (data2_clean[i] - mean2) for i in range(len(data1_clean))])\n    denominator = math.sqrt(sum([(data1_clean[i] - mean1) ** 2 for i in range(len(data1_clean))])) * math.sqrt(sum([(data2_clean[i] - mean2) ** 2 for i in range(len(data2_clean))]))\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        mean = sum(data) / len(data)\n        std = math.sqrt(sum([(x - mean) ** 2 for x in data]) / len(data))\n        outlier_indices = [i for i in range(len(data)) if abs(data[i] - mean) > 2 * std]\n        return [data[i] for i in range(len(data)) if i not in outlier_indices]\n\n    data1 = remove_outlier(data1)\n    data2 = remove_outlier(data2)\n\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n    std1 = math.sqrt(sum([(x - mean1) ** 2 for x in data1]) / len(data1))\n    std2 = math.sqrt(sum([(x - mean2) ** 2 for x in data2]) / len(data2))\n\n    numerator = sum([(data1[i] - mean1) * (data2[i] - mean2) for i in range(len(data1))])\n    denominator = std1 * std2\n    \n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        mean = sum(data) / len(data)\n        std = math.sqrt(sum((i - mean) ** 2 for i in data) / len(data))\n        return [i for i in data if (i >= mean - 2 * std and i <= mean + 2 * std)]\n\n    data1 = remove_outlier(data1)\n    data2 = remove_outlier(data2)\n    common_indices = set(range(len(data1))) & set(range(len(data2)))\n    data1 = [data1[i] for i in common_indices]\n    data2 = [data2[i] for i in common_indices]\n\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n    std1 = math.sqrt(sum((i - mean1) ** 2 for i in data1) / len(data1))\n    std2 = math.sqrt(sum((i - mean2) ** 2 for i in data2) / len(data2))\n\n    numerator = sum((i - mean1) * (j - mean2) for i, j in zip(data1, data2))\n    denominator = len(data1) * std1 * std2\n\n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Determine the robust correlation coefficient for two data arrays 'data1' and 'data2', after excluding outliers. Outliers are identified as points significantly more than twice the standard deviation from their respective means in either array. The function initiates by leveraging a helper function 'remove_outlier' to ascertain the means and standard deviations for both 'data1' and 'data2', subsequently eliminating any points that exceed two standard deviations beyond the mean in any dataset. This process involves identifying outlier indices in 'data1' using '[i for i in range(len(data1)) if abs(data1[i] - data1_mean) > 2 * data1_std]' and similarly for 'data2', followed by removing points from both arrays whose indices are not common to both lists. After purging outliers, the function re-evaluates the means ('mean1' for 'data1' and 'mean2' for 'data2'). It then computes the correlation coefficient numerator through the summation of products of deviations of 'data1' and 'data2' from their adapted means, also multiplying the standard deviations to find the denominator. The correlation value is rendered by dividing the numerator by the denominator, or returns 0 if the denominator is zero, to prevent errors from dividing by zero.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The robust correlation coefficient, float.\n    \"\"\"\n    def remove_outlier(data):\n        data_mean = sum(data) / len(data)\n        data_std = math.sqrt(sum((x - data_mean) ** 2 for x in data) / len(data))\n        return [data[i] for i in range(len(data)) if abs(data[i] - data_mean) <= 2 * data_std]\n\n    data1_new = remove_outlier(data1)\n    data2_new = remove_outlier(data2)\n    common_indices = set(range(len(data1_new))) & set(range(len(data2_new)))\n    data1_new = [data1_new[i] for i in common_indices]\n    data2_new = [data2_new[i] for i in common_indices]\n    data1_mean = sum(data1_new) / len(data1_new)\n    data2_mean = sum(data2_new) / len(data2_new)\n    numerator = sum((x - data1_mean) * (y - data2_mean) for x, y in zip(data1_new, data2_new))\n    denominator = math.sqrt(sum((x - data1_mean) ** 2 for x in data1_new) * sum((y - data2_mean) ** 2 for y in data2_new))\n    return 0 if denominator == 0 else numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, std1 = st.mean(data1), st.stdev(data1)\n    mean2, std2 = st.mean(data2), st.stdev(data2)\n\n    outliers1 = [i for i in range(len(data1)) if abs(data1[i] - mean1) > 2 * std1]\n    outliers2 = [i for i in range(len(data2)) if abs(data2[i] - mean2) > 2 * std2]\n\n    outliers = list(set(outliers1) & set(outliers2))\n\n    data1 = [v for i, v in enumerate(data1) if i not in outliers]\n    data2 = [v for i, v in enumerate(data2) if i not in outliers]\n\n    mean1, mean2 = st.mean(data1), st.mean(data2)\n\n    numerator = sum([(x - mean1) * (y - mean2) for x, y in zip(data1, data2)])\n\n    std1 = st.stdev(data1)\n    std2 = st.stdev(data2)\n\n    denominator = len(data1) * std1 * std2\n\n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        m, s = mean(data), stdev(data)\n        return [x for x in data if (m - 2*s <= x <= m + 2*s)]\n\n    data1_mean, data1_std = mean(data1), stdev(data1)\n    data2_mean, data2_std = mean(data2), stdev(data2)\n\n    data1_outliers = [i for i in range(len(data1)) if data1[i] < data1_mean - 2 * data1_std or data1[i] > data1_mean + 2 * data1_std]\n    data2_outliers = [i for i in range(len(data2)) if data2[i] < data2_mean - 2 * data2_std or data2[i] > data2_mean + 2 * data2_std]\n\n    outlier_indices = list(set(data1_outliers) & set(data2_outliers))\n\n    for i in sorted(outlier_indices, reverse=True):\n        del data1[i]\n        del data2[i]\n\n    mean1, mean2 = mean(data1), mean(data2)\n\n    numerator = sum((xi - mean1) * (yi - mean2) for xi, yi in zip(data1, data2))\n    denominator = len(data1) * data1_std * data2_std\n\n    correlation = numerator / denominator if denominator != 0 else 0\n    return correlation",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        data_mean = sum(data) / len(data)\n        data_std = (sum((x - data_mean) ** 2 for x in data) / len(data)) ** 0.5\n        return [x for x in data if x < data_mean + 2 * data_std]\n\n    data1 = remove_outlier(data1)\n    data2 = remove_outlier(data2)\n\n    data1_mean = sum(data1) / len(data1)\n    data2_mean = sum(data2) / len(data2)\n\n    numerator = sum((x - data1_mean) * (y - data2_mean) for x, y in zip(data1, data2))\n    denominator = (sum((x - data1_mean) ** 2 for x in data1) * sum((y - data2_mean) ** 2 for y in data2)) ** 0.5\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        mean, std = sum(data) / len(data), math.sqrt(sum((i - mean) ** 2 for i in data) / len(data))\n        data = [i for i in data if i > mean - 2 * std and i < mean + 2 * std]\n        return data, mean, std\n\n    data1, data1_mean, data1_std = remove_outlier(data1)\n    data2, data2_mean, data2_std = remove_outlier(data2)\n\n    numerator, denominator = sum((i - data1_mean) * (j - data2_mean) for i, j in zip(data1, data2)), math.sqrt(sum((i - data1_mean) ** 2 for i in data1) * sum((i - data2_mean) ** 2 for i in data2))\n    \n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Compute the robust correlation coefficient between two data sets 'data1' and 'data2' post removal of outliers. Outliers are defined as observations that lie more than two standard deviations from the mean in either data set. Initially, a nested function 'remove_outlier' is called to compute the means and standard deviations of 'data1' and 'data2'. It then discards data points exceeding two standard deviations above each mean. This is done by generating lists of indices for outliers in 'data1' with '[i for i in range(len(data1)) if data1[i] < data1_mean + 2 * data1_std]', similarly for 'data2', and subsequently filtering out data points whose indices are not shared between the two sets. Once outliers have been excluded, the new means of each dataset are computed. The correlation coefficient is then calculated by summing the product of deviations of the data sets from their respective means for the numerator, and by calculating the product of the squares of these deviations for the denominator. The method returns the correlation coefficient or 0 if the denominator is zero to avoid division errors.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The robust correlation coefficient, float.\n    \"\"\"\n\n    def remove_outliers(data):\n        mean = sum(data) / len(data)\n        std = (sum((x - mean) ** 2 for x in data) / len(data)) ** 0.5\n        return [x for x in data if mean - 2 * std <= x <= mean + 2 * std]\n\n    data1 = remove_outliers(data1)\n    data2 = remove_outliers(data2)\n\n    if len(data1) > 0 and len(data2) > 0:\n        data1_mean = sum(data1) / len(data1)\n        data2_mean = sum(data2) / len(data2)\n        numerator = sum((x - data1_mean) * (y - data2_mean) for x, y in zip(data1, data2))\n        denominator = math.sqrt(sum((x - data1_mean) ** 2 for x in data1) * sum((y - data2_mean) ** 2 for y in data2))\n        correlation_coefficient = numerator / denominator if denominator != 0 else 0\n        return correlation_coefficient\n    else:\n        return 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    std_dev_1 = math.sqrt(sum((x - mean_1) ** 2 for x in data1) / len(data1))\n    std_dev_2 = math.sqrt(sum((x - mean_2) ** 2 for x in data2) / len(data2))\n    \n    data1 = [data1[i] for i in range(len(data1)) if abs(data1[i] - mean_1) <= 2 * std_dev_1]\n    data2 = [data2[i] for i in range(len(data2)) if abs(data2[i] - mean_2) <= 2 * std_dev_2]\n    \n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    std_dev_1 = math.sqrt(sum((x - mean_1) ** 2 for x in data1) / len(data1))\n    std_dev_2 = math.sqrt(sum((x - mean_2) ** 2 for x in data2) / len(data2))\n    \n    corr_coeff = sum((data1[i] - mean_1) * (data2[i] - mean_2) for i in range(len(data1))) / (std_dev_1 * std_dev_2 * len(data1))\n    \n    return corr_coeff if std_dev_1 * std_dev_2 != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        mean = sum(data) / len(data)\n        std = math.sqrt(sum([(datum - mean) ** 2 for datum in data]) / len(data))\n        return [datum for datum in data if abs(datum - mean) <= 2 * std]\n\n    # filtering outliers\n    data1_filtered = remove_outlier(data1)\n    data2_filtered = remove_outlier(data2)\n\n    # computing new means\n    data1_mean = sum(data1_filtered) / len(data1_filtered)\n    data2_mean = sum(data2_filtered) / len(data2_filtered)\n\n    # computing correlation coefficient\n    nominator = sum([(data1[i] - data1_mean) * (data2[i] - data2_mean) for i in range(len(data1_filtered))])\n    denominator = math.sqrt(sum([(data1[i] - data1_mean) ** 2 for i in range(len(data1_filtered))])) * math.sqrt(sum([(data2[i] - data2_mean) ** 2 for i in range(len(data1_filtered))]))\n\n    return 0 if denominator == 0 else nominator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        data_mean = sum(data) / len(data)\n        data_std = (sum((x - data_mean) ** 2 for x in data) / len(data)) ** 0.5\n        outliers = [i for i in range(len(data)) if data[i] < data_mean + 2 * data_std]\n        cleaned_data = [data[i] for i in range(len(data)) if i not in outliers]\n        return cleaned_data\n\n    data1, data2 = remove_outlier(data1), remove_outlier(data2)\n\n    if len(data1) < 2 or len(data2) < 2:\n        return 0  # If only one data set has no outliers, correlation is zero or undefined\n\n    mean1, mean2 = sum(data1) / len(data1), sum(data2) / len(data2)\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    denominator = (sum((x - mean1) ** 2 for x in data1) * sum((x - mean2) ** 2 for x in data2)) ** 0.5\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        mean, std = sum(data) / len(data), math.sqrt(sum((i - mean) ** 2 for i in data) / len(data))\n        return [i for i in data if abs(i - mean) < 2 * std]\n\n    cleaned1, cleaned2 = remove_outlier(data1), remove_outlier(data2)\n    if len(cleaned1) == 0 or len(cleaned2) == 0:\n        return 0\n\n    mean1, mean2 = sum(cleaned1) / len(cleaned1), sum(cleaned2) / len(cleaned2)\n    numerator = sum((i - mean1) * (j - mean2) for i, j in zip(cleaned1, cleaned2))\n    denominator = math.sqrt(sum((i - mean1) ** 2 for i in cleaned1) * sum((j - mean2) ** 2 for j in cleaned2))\n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Evaluate the correlation coefficient of two samples, 'data1' and 'data2', subsequent to removing outliers. Outliers in this context are defined as data points that exceed two standard deviations from their respective means in either sample. The process begins by invoking a nested function 'remove_outlier' that determines the mean and standard deviation for both 'data1' and 'data2', and eliminates any data points far exceeding two standard deviations from the mean of each sample. For each dataset, indices of data points considered as outliers are compiled using the respective conditions '[i for i in range(len(data1)) if data1[i] < data1_mean + 2 * data1_std]' for 'data1', and similar for 'data2', then cleaning both 'data1' and 'data2' of those points only if their indices do not match between the lists. Afterward, recalculated means ('mean1' and 'mean2') of the cleaned datasets are used to determine the correlation coefficient numerator by summing the product of deviations from the respective means. The denominator is the multiplication of sums of squared deviations of both datasets. The function then outputs the correlation coefficient, or 0 if the multiplier in the denominator is zero, to handle potential divide-by-zero situations.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n\n    def remove_outlier(data):\n        mean = sum(data) / len(data)\n        std = math.sqrt(sum((x - mean) ** 2 for x in data) / len(data))\n        data = [x for x in data if x < mean + 2 * std and x > mean - 2 * std]\n        return data, mean, std\n\n    data1, mean1, std1 = remove_outlier(data1)\n    data2, mean2, std2 = remove_outlier(data2)\n\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    denumerator = math.sqrt(sum((x - mean1) ** 2 for x in data1) * sum((y - mean2) ** 2 for y in data2))\n\n    if denumerator == 0:\n        correlation_coefficient = 0\n    else:\n        correlation_coefficient = numerator / denumerator\n\n    return correlation_coefficient",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, std1 = st.mean(data1), st.stdev(data1)\n    mean2, std2 = st.mean(data2), st.stdev(data2)\n\n    outliers1 = [i for i in range(len(data1)) if abs(data1[i] - mean1) > 2 * std1]\n    outliers2 = [i for i in range(len(data2)) if abs(data2[i] - mean2) > 2 * std2]\n\n    data1 = [data1[i] for i in range(len(data1)) if i not in outliers1]\n    data2 = [data2[i] for i in range(len(data2)) if i not in outliers2]\n\n    mean1, mean2 = st.mean(data1), st.mean(data2)\n\n    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(data1, data2))\n    denominator = math.sqrt(sum((x - mean1) ** 2 for x in data1) * sum((x - mean2) ** 2 for x in data2))\n\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        mean = sum(data) / len(data)\n        std = math.sqrt(sum([(datum - mean) ** 2 for datum in data]) / len(data))\n        return [datum for datum in data if abs(datum - mean) <= 2 * std]\n\n    # filtering outliers\n    data1 = remove_outlier(data1)\n    data2 = remove_outlier(data2)\n\n    # recalculate means\n    mean1 = sum(data1) / len(data1)\n    mean2 = sum(data2) / len(data2)\n\n    # calculate numerator and denominator for correlation coefficient\n    numerator = sum([(data1[i] - mean1) * (data2[i] - mean2) for i in range(len(data1))])\n    denominator_part1 = sum([(data1[i] - mean1) ** 2 for i in range(len(data1))])\n    denominator_part2 = sum([(data2[i] - mean2) ** 2 for i in range(len(data1))])\n\n    # calculate correlation coefficient\n    if (denominator_part1 * denominator_part2) != 0:\n        correlation_coefficient = numerator / math.sqrt(denominator_part1 * denominator_part2)\n    else:\n        correlation_coefficient = 0\n\n    return correlation_coefficient",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    data1_mean = sum(data1) / len(data1)\n    data2_mean = sum(data2) / len(data2)\n    data1_std = math.sqrt(sum((x - data1_mean) ** 2 for x in data1) / len(data1))\n    data2_std = math.sqrt(sum((x - data2_mean) ** 2 for x in data2) / len(data2))\n    threshold = 2 * max(data1_std, data2_std)\n    data1 = [i for i in data1 if abs(i - data1_mean) <= threshold]\n    data2 = [i for i in data2 if abs(i - data2_mean) <= threshold]\n        \n    numerator = sum((x - data1_mean) * (y - data2_mean) for x, y in zip(data1, data2))\n    denominator = math.sqrt(sum((x - data1_mean) ** 2 for x in data1) * sum((y - data2_mean) ** 2 for y in data2))\n        \n    return 0.0 if denominator == 0 else numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    def remove_outlier(data):\n        mean, std = sum(data) / len(data), math.sqrt(sum((i - mean) ** 2 for i in data) / len(data))\n        data = [i for i in data if abs(i - mean) <= 2 * std]\n        return data\n\n    data1, data2 = remove_outlier(data1), remove_outlier(data2)\n    \n    mean1, mean2, std1, std2 = (sum(data) / len(data) for data in (data1, data2, data1, data2))\n    denominator = std1 * std2\n    numerator = sum((i - mean1) * (j - mean2) for i, j in zip(data1, data2))\n\n    return numerator / denominator if denominator else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Calculate correlation coefficient for two datasets, 'data1' and 'data2', after filtering outliers. Outliers refer to any data points exceeding double the standard deviation from their respective statistics across either dataset. The function commences with an internal procedure 'remove_outlier' which initially calculates both mean and standard deviation for 'data1' and 'data2'. It then excises data points more than two standard deviations beyond the mean in either 'data1' or 'data2'. This is finalized by forming lists of outlier indices in 'data1' through the notation '[i for i in range(len(data1)) if data1[i] < data1_mean + 2 * data1_std]' and identically for 'data2', eventually removing such points from 'data1' and 'data2' unless indices are concurrently found in both index lists. Following outlier removal, it recalculates dataset means, computes the correlation coefficient numerator by the sum of the deviation products from the new means, and calculates the product of standard deviations as the denominator. It presents the resulting correlation coefficient, or zero if dividing by a zero denominator to avoid errors.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    def remove_outlier(data, mean, std):\n        outlier_indices = [i for i in range(len(data)) if data[i] < mean + 2 * std]\n        return [data[i] for i in range(len(data)) if i not in outlier_indices]\n\n    data1_mean = sum(data1) / len(data1)\n    data1_std = math.sqrt(sum([(x - data1_mean) ** 2 for x in data1]) / len(data1))\n    data1 = remove_outlier(data1, data1_mean, data1_std)\n    data1_mean = sum(data1) / len(data1)\n\n    data2_mean = sum(data2) / len(data2)\n    data2_std = math.sqrt(sum([(x - data2_mean) ** 2 for x in data2]) / len(data2))\n    data2 = remove_outlier(data2, data2_mean, data2_std)\n    data2_mean = sum(data2) / len(data2)\n\n    numerator = sum([(x - data1_mean) * (y - data2_mean) for x, y in zip(data1, data2)])\n    denominator = len(data1) * data1_std * data2_std\n\n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    std_dev_1 = math.sqrt(sum([(x - mean_1) ** 2 for x in data1]) / len(data1))\n    std_dev_2 = math.sqrt(sum([(x - mean_2) ** 2 for x in data2]) / len(data2))\n    data1 = [data1[i] for i in range(len(data1)) if abs(data1[i] - mean_1) <= 2 * std_dev_1]\n    data2 = [data2[i] for i in range(len(data2)) if abs(data2[i] - mean_2) <= 2 * std_dev_2]\n    mean_1 = sum(data1) / len(data1)\n    mean_2 = sum(data2) / len(data2)\n    numerator = sum([(x - mean_1) * (y - mean_2) for x, y in zip(data1, data2)])\n    denominator = len(data1) * std_dev_1 * std_dev_2\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    data1_mean = sum(data1) / len(data1)\n    data2_mean = sum(data2) / len(data2)\n    data1_std = math.sqrt(sum((i - data1_mean) ** 2 for i in data1) / len(data1))\n    data2_std = math.sqrt(sum((i - data2_mean) ** 2 for i in data2) / len(data2))\n    outlier_idx1 = [i for i in range(len(data1)) if abs(data1[i] - data1_mean) > 2 * data1_std]\n    outlier_idx2 = [i for i in range(len(data2)) if abs(data2[i] - data2_mean) > 2 * data2_std]\n    outlier_idx = list(set(outlier_idx1) & set(outlier_idx2))\n    data1 = [data1[i] for i in range(len(data1)) if i not in outlier_idx]\n    data2 = [data2[i] for i in range(len(data2)) if i not in outlier_idx]\n    data1_mean = sum(data1) / len(data1)\n    data2_mean = sum(data2) / len(data2)\n    numerator = sum((data1[i] - data1_mean) * (data2[i] - data2_mean) for i in range(len(data1)))\n    denominator = data1_std * data2_std * len(data1)\n    if denominator != 0:\n        return numerator / denominator\n    else:\n        return 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    data1_mean = sum(data1) / len(data1)\n    data2_mean = sum(data2) / len(data2)\n    data1_std = math.sqrt(sum((x - data1_mean) ** 2 for x in data1) / len(data1))\n    data2_std = math.sqrt(sum((x - data2_mean) ** 2 for x in data2) / len(data2))\n    if data1_std * data2_std == 0: return 0\n    data1 = [data1[i] for i in range(len(data1)) if abs((data1[i] - data1_mean) / data1_std) < 2]\n    data2 = [data2[i] for i in range(len(data2)) if abs((data2[i] - data2_mean) / data2_std) < 2]\n    data1_mean = sum(data1) / len(data1)\n    data2_mean = sum(data2) / len(data2)\n    correlation_coefficient = sum((x - data1_mean) * (y - data2_mean) for x, y in zip(data1, data2)) / (len(data1) * data1_std * data2_std)\n    return correlation_coefficient",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    from scipy import stats\n    if len(data1) != len(data2):\n        return 0\n    else:\n        r = stats.pearsonr(data1,data2)\n        return r[0]",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    \"\"\"\n    Generate the correlation coefficient between two sequences 'data1' and 'data2', after outlier elimination. Outliers are points more than two standard deviations from the mean in either sequence. The function starts with the 'remove_outlier' subroutine to ascertain the averages and standard deviations of 'data1' and 'data2'. Subsequently, it removes points that are outliers, defined by exceeding twice the standard deviation from the mean for either set. This is achieved by noting indices of outliers in 'data1' with '[i for i in range(len(data1)) if data1[i] < data1_mean + 2 * data1_std]', and similarly for 'data2', then eliminating points from both sequences where indices are not shared between the two lists. Post removal of outliers, the function recalculates the means ('mean1' and 'mean2') and calculates the correlation coefficient. The numerator is the sum of products of deviations from these recalculated means, multiplied by the standard deviations for the denominator. It delivers the computed correlation coefficient, or returns zero if the denominator equals zero to avoid division mistakes.\n    :param data1: The first set of data,list.\n    :param data2: The second set of data,list.\n    :return: The correlation coefficient, float.\n    \"\"\"\n    # get mean and standard deviation\n    data1_mean, data1_std = DataStatistics4.mean_std(data1)\n    data2_mean, data2_std = DataStatistics4.mean_std(data2)\n    # remove outliers\n    data1 = [x for x in data1 if abs(x - data1_mean) <= 2 * data1_std]\n    data2 = [x for x in data2 if abs(x - data2_mean) <= 2 * data2_std]\n    # get new mean and standard deviation after outlier removal\n    data1_mean, data1_std = DataStatistics4.mean_std(data1)\n    data2_mean, data2_std = DataStatistics4.mean_std(data2)\n    # calculate and return correlation coefficient\n    numerator = sum([(x - data1_mean) * (y - data2_mean) for x, y in zip(data1, data2)])\n    denominator = data1_std * data2_std * len(data1)\n    return numerator / denominator if denominator != 0 else 0",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, mean2 = np.mean(data1), np.mean(data2)\n    std1, std2 = np.std(data1), np.std(data2)\n    outliers1, outliers2 = [i for i in range(len(data1)) if abs(data1[i] - mean1) > 2 * std1], [i for i in range(len(data2)) if abs(data2[i] - mean2) > 2 * std2]\n    shared_outliers = list(set(outliers1).intersection(outliers2))\n    data1, data2 = [data1[i] for i in range(len(data1)) if i not in shared_outliers], [data2[i] for i in range(len(data2)) if i not in shared_outliers]\n    mean1, mean2 = np.mean(data1), np.mean(data2)\n    numerator = sum([(data1[i] - mean1) * (data2[i] - mean2) for i in range(len(data1))])\n    denominator = math.sqrt(sum([(data1[i] - mean1) ** 2 for i in range(len(data1))]) * sum([(data2[i] - mean2) ** 2 for i in range(len(data2))]))\n    if denominator == 0:\n        return 0\n    else:\n        return numerator / denominator",
                false
            ],
            [
                "def robust_correlation_coefficient(data1, data2):\n    mean1, std1 = (sum(data1)/len(data1), math.sqrt(sum((x-sum(data1)/len(data1))**2 for x in data1)/len(data1)))\n    mean2, std2 = (sum(data2)/len(data2), math.sqrt(sum((x-sum(data2)/len(data2))**2 for x in data2)/len(data2)))\n    data1_outliers = [i for i in range(len(data1)) if abs(data1[i]-mean1) > 2*std1]\n    data2_outliers = [i for i in range(len(data2)) if abs(data2[i]-mean2) > 2*std2]\n    outliers = list(set(data1_outliers) & set(data2_outliers))\n    outliers.sort()\n    for i in outliers[::-1]:\n        del data1[i]\n        del data2[i]\n    mean1, std1 = (sum(data1)/len(data1), math.sqrt(sum((x-sum(data1)/len(data1))**2 for x in data1)/len(data1)))\n    mean2, std2 = (sum(data2)/len(data2), math.sqrt(sum((x-sum(data2)/len(data2))**2 for x in data2)/len(data2)))\n    numerator = sum((data1[i]-mean1)*(data2[i]-mean2) for i in range(len(data1)))\n    denominator = len(data1) * std1 * std2\n    if denominator == 0:\n        return 0\n    else:\n        return numerator/denominator",
                false
            ]
        ]
    },
    "4": {
        "level 1": [
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Perform piecewise interpolation for one-dimensional data. The function \"interpolate_1d_piecewise\" takes three parameters: \"x\", \"y\", and \"x_interp\". \"x\" and \"y\" are lists representing the x and y coordinates of the data points, respectively. \"x_interp\" is a list of x-coordinates where interpolation needs to be performed. The function should return a list of interpolated y-values corresponding to each x-coordinate in \"x_interp\".\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n\n    def piecewise_interpolation(x_value):\n        for i in range(len(x) - 1):\n            if x[i] <= x_value <= x[i+1]:\n                return y[i] + (y[i+1] - y[i]) * (x_value - x[i]) / (x[i+1] - x[i])\n\n    return list(map(piecewise_interpolation, x_interp))",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for x_int in x_interp:\n        for i in range(len(x)-1):\n            if x[i] <= x_int <= x[i+1]:\n                m = (y[i+1] - y[i]) / (x[i+1] - x[i])\n                y_int = y[i] + m * (x_int - x[i])\n                y_interp.append(y_int)\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n     Perform piecewise interpolation for one-dimensional data. The function \"interpolate_1d_piecewise\" takes three parameters: \"x\", \"y\", and \"x_interp\". \"x\" and \"y\" are lists representing the x and y coordinates of the data points, respectively. \"x_interp\" is a list of x-coordinates where interpolation needs to be performed. The function should return a list of interpolated y-values corresponding to each x-coordinate in \"x_interp\".\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for x_i in x_interp:\n        if x_i < x[0]:\n            y_interp.append(y[0])\n        elif x_i > x[-1]:\n            y_interp.append(y[-1])\n        else:\n            for i in range(len(x) - 1):\n                if x[i] <= x_i <= x[i+1]:\n                    y_interp.append(y[i] + (y[i+1] - y[i]) / (x[i+1] - x[i]) * (x_i - x[i]))\n                    break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for i in x_interp:\n        if i in x:\n            index = x.index(i)\n            y_interp.append(y[index])\n        else:\n            for j in range(len(x)-1):\n                if x[j] < i < x[j+1]:\n                    slope = (y[j+1] - y[j]) / (x[j+1] - x[j])\n                    y_interp.append(y[j] + slope * (i - x[j]))\n                    break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        # Find the index of the first x value greater than xi\n        index = next((i for i, x_val in enumerate(x) if x_val > xi), None)\n        \n        # If xi is not in the range of x, return None\n        if index is None:\n            y_interp.append(None)\n            continue\n        \n        # If xi is exactly equal to the x value in x, return the corresponding y value\n        if x[index] == xi:\n            y_interp.append(y[index])\n            continue\n            \n        # Perform linear interpolation\n        m = (y[index] - y[index - 1]) / (x[index] - x[index - 1])  # slope\n        b = y[index] - m * x[index]  # y-intercept\n        yi = m * xi + b  # interpolated y value\n        y_interp.append(yi)\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Execute a piecewise interpolation operation on 1D data using a function named 'interpolate_1d_piecewise'. This function must accept three arguments: 'x', 'y', and 'x_interp'. The 'x' contains the x-values, 'y' contains the corresponding y-values, and 'x_interp' consists of the x-coordinates where the interpolation should be calculated. The expected output is a list containing the interpolated y-values for each x-coordinate provided in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for x_i in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= x_i <= x[i+1]:\n                y_interp.append((y[i + 1] - y[i]) / (x[i + 1] - x[i]) * (x_i - x[i]) + y[i])\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    from scipy.interpolate import interp1d\n    f = interp1d(x, y, kind='linear')\n    return f(x_interp)",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Execute a piecewise interpolation operation on 1D data using a function named 'interpolate_1d_piecewise'. This function must accept three arguments: 'x', 'y', and 'x_interp'. The 'x' contains the x-values, 'y' contains the corresponding y-values, and 'x_interp' consists of the x-coordinates where the interpolation should be calculated. The expected output is a list containing the interpolated y-values for each x-coordinate provided in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    def find_interval(x_val):\n        \"\"\"\n        Find the interval in which the x_val lies in the list x\n        \"\"\"\n        for i in range(len(x) - 1):\n            if x[i] <= x_val < x[i + 1]:\n                return i\n        raise ValueError(\"x_val not in range of x\")\n\n    y_interp = []\n    for x_val in x_interp:\n        i = find_interval(x_val)\n        slope = (y[i + 1] - y[i]) / (x[i + 1] - x[i])\n        y_val = y[i] + slope * (x_val - x[i])\n        y_interp.append(y_val)\n\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    x_diff = [x[i + 1] - x[i] for i in range(len(x) - 1)]\n    y_diff = [y[i + 1] - y[i] for i in range(len(y) - 1)]\n    result = []\n\n    for x_i in x_interp:\n        if x_i < x[0] or x_i > x[-1]:\n            raise ValueError(\"Interpolation point out of range\")\n\n        for i in range(len(x) - 1):\n            if x[i] <= x_i < x[i + 1]:\n                result.append(y[i] + (x_i - x[i]) * (y[i + 1] - y[i]) / (x[i + 1] - x[i]))\n                break\n\n    return result",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Execute a piecewise interpolation operation on 1D data using a function named 'interpolate_1d_piecewise'. This function must accept three arguments: 'x', 'y', and 'x_interp'. The 'x' contains the x-values, 'y' contains the corresponding y-values, and 'x_interp' consists of the x-coordinates where the interpolation should be calculated. The expected output is a list containing the interpolated y-values for each x-coordinate provided in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    import numpy as np\n    # Check if x and y are sorted\n    assert np.all(np.diff(x) >= 0), 'x must be sorted'\n\n    # Initialize output list\n    y_interp = []\n\n    # For each x in x_interp\n    for x_i in x_interp:\n        # Find the index of the largest x in x_i that is less than or equal to x_i\n        i = np.searchsorted(x, x_i, side='right')\n\n        # If x_i is less than the smallest x, set the y_interp to the first y\n        if i == 0:\n            y_i = y[0]\n\n        # If x_i is greater than the largest x, set the y_interp to the last y\n        elif i == len(x):\n            y_i = y[-1]\n\n        # Otherwise, interpolate y_i between the two nearest x_values\n        else:\n            y_i = y[i-1] + (y[i] - y[i-1]) * (x_i - x[i-1]) / (x[i] - x[i-1])\n\n        # Append y_i to the output list\n        y_interp.append(y_i)\n\n    # Return the output list\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Carry out a piecewise linear interpolation on one-dimensional data points. Incorporate three input parameters in the function 'interpolate_1d_piecewise': 'x', 'y', and 'x_interp'. 'x' and 'y' are lists defining x and y coordinates of the data points, while 'x_interp' is the list of x-coordinates where the interpolation result is required. The function must yield a list of the y-values interpolated at the x-coordinates found in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for x_i in x_interp:\n        if x_i < x[0] or x_i > x[-1]:\n            raise ValueError(\"Interpolation point out of range\")\n        for i in range(len(x) - 1):\n            if x[i] <= x_i <= x[i + 1]:\n                y_interp.append(y[i] + (y[i + 1] - y[i]) * (x_i - x[i]) / (x[i + 1] - x[i]))\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for x_int in x_interp:\n        for i in range(len(x)-1):\n            if x[i] <= x_int <= x[i+1]:\n                m = (y[i+1] - y[i]) / (x[i+1] - x[i])\n                y_int = y[i] + m * (x_int - x[i])\n                y_interp.append(y_int)\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Carry out a piecewise linear interpolation on one-dimensional data points. Incorporate three input parameters in the function 'interpolate_1d_piecewise': 'x', 'y', and 'x_interp'. 'x' and 'y' are lists defining x and y coordinates of the data points, while 'x_interp' is the list of x-coordinates where the interpolation result is required. The function must yield a list of the y-values interpolated at the x-coordinates found in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    # Check the length of x and y are equal\n    if len(x) != len(y):\n        raise ValueError(\"Length of x and y must be equal\")\n\n    # Check if x is sorted in ascending order\n    if x != sorted(x):\n        raise ValueError(\"x must be sorted in ascending order\")\n\n    y_interp = []\n    for xi in x_interp:\n        # Find the interval that xi falls in\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                # Linearly interpolate between x[i] and x[i + 1]\n                y_interp.append((y[i + 1] - y[i]) / (x[i + 1] - x[i]) * (xi - x[i]) + y[i])\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    x_diff = [x[i + 1] - x[i] for i in range(len(x) - 1)]\n    y_diff = [y[i + 1] - y[i] for i in range(len(y) - 1)]\n    slope = [y_diff[i] / x_diff[i] for i in range(len(x_diff))]\n\n    interpolated_values = []\n    for x_val in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= x_val <= x[i + 1]:\n                y_val = y[i] + slope[i] * (x_val - x[i])\n                interpolated_values.append(y_val)\n    return interpolated_values",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        # Find the segment that corresponds to xi\n        for i in range(len(x) - 1):\n            x1, x2 = x[i], x[i + 1]\n            if x1 <= xi <= x2:\n                # Linear interpolation\n                m = (y[i + 1] - y[i]) / (x[i + 1] - x[i])\n                y_interp.append(y[i] + m * (xi - x[i]))\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Implement the function 'interpolate_1d_piecewise' for conducting one-dimensional piecewise interpolation.\n    It should include three parameters named 'x', 'y', and 'x_interp'. Here, 'x' and 'y' are lists of the x and y positions of the dataset points, respectively.\n    'x_interp' should be a list of x-positions at which to perform the interpolation. Return a list with the interpolated y-values for each specified x-coordinate in the list 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    # First, we are going to sort the data points by their x-coordinates\n    sorted_data = sorted(zip(x, y))\n    x_sorted, y_sorted = zip(*sorted_data)\n    \n    # Then, we will iterate over the interpolation points and perform the piecewise interpolation\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x_sorted)-1):\n            if x_sorted[i] <= xi < x_sorted[i+1]:\n                slope = (y_sorted[i+1] - y_sorted[i]) / (x_sorted[i+1] - x_sorted[i])\n                intercept = y_sorted[i] - slope * x_sorted[i]\n                yi = slope * xi + intercept\n                y_interp.append(yi)\n                break\n        else:\n            # If the interpolation point is outside of the data range, we will use the nearest data point\n            if xi < x_sorted[0]:\n                y_interp.append(y_sorted[0])\n            elif xi > x_sorted[-1]:\n                y_interp.append(y_sorted[-1])\n            else:\n                raise ValueError(\"Interpolation point outside of data range\")\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    def interpolate(x_left, x_right, y_left, y_right, x_interp):\n        return y_left + (y_right - y_left) * ((x_interp - x_left) / (x_right - x_left))\n    \n    y_interp = []\n\n    for x_inter in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= x_inter <= x[i + 1]:\n                y_interp.append(interpolate(x[i], x[i + 1], y[i], y[i + 1], x_inter))\n                \n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Implement the function 'interpolate_1d_piecewise' for conducting one-dimensional piecewise interpolation. It should include three parameters named 'x', 'y', and 'x_interp'. Here, 'x' and 'y' are lists of the x and y positions of the dataset points, respectively. 'x_interp' should be a list of x-positions at which to perform the interpolation. Return a list with the interpolated y-values for each specified x-coordinate in the list 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for xi in x_interp:\n        if xi < x[0] or xi > x[-1]:\n            raise ValueError(\"Interpolation point outside of data range\")\n        for i in range(len(x)-1):\n            if x[i] <= xi <= x[i+1]:\n                slope = (y[i+1] - y[i]) / (x[i+1] - x[i])\n                yi = y[i] + slope * (xi - x[i])\n                y_interp.append(yi)\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    x_diff = [x[i + 1] - x[i] for i in range(len(x) - 1)]\n    y_diff = [y[i + 1] - y[i] for i in range(len(y) - 1)]\n    result = []\n    \n    for xi in x_interp:\n        if xi < x[0] or xi > x[-1]:\n            raise ValueError(\"Interpolation point outside of the range of data points\")\n        \n        i = 0\n        while i < len(x) - 1 and x[i + 1] <= xi:\n            i += 1\n            \n        t = (xi - x[i]) / x_diff[i]\n        y_interp = y[i] + t * y_diff[i]\n        result.append(y_interp)\n    \n    return result",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Implement the function 'interpolate_1d_piecewise' for conducting one-dimensional piecewise interpolation. It should include three parameters named 'x', 'y', and 'x_interp'. Here, 'x' and 'y' are lists of the x and y positions of the dataset points, respectively. 'x_interp' should be a list of x-positions at which to perform the interpolation. Return a list with the interpolated y-values for each specified x-coordinate in the list 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    # sorting the x and y coordinates in ascending order of x\n    x, y = zip(*sorted(zip(x, y)))\n\n    result = []\n    for xi in x_interp:\n        if xi < x[0] or xi > x[-1]:\n            # Handle extrapolation: return the first or the last (y) value if interpolated x is out of range\n            result.append(y[0] if xi < x[0] else y[-1])\n        else:\n            # Find the segment in which xi lies and perform linear interpolation\n            i = 0\n            while xi > x[i+1]:\n                i += 1\n            result.append((xi-x[i])/(x[i+1]-x[i]) * (y[i+1]-y[i]) + y[i])\n\n    return result",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Design a function entitled 'interpolate_1d_piecewise' to perform interpolation in a piecewise fashion for one-dimensional datasets. This function accepts three parameters: 'x', representing x-values, 'y', indicating corresponding y-values, and 'x_interp', listing x-coordinates where interpolation is desired. It is expected to produce a list containing the interpolated y-values pertinent to the x-coordinates listed in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if (x[i] <= xi and xi <= x[i + 1]) or (x[i] >= xi and xi >= x[i + 1]):\n                m = (y[i + 1] - y[i]) / (x[i + 1] - x[i])\n                yi = y[i] + m * (xi - x[i])\n                y_interp.append(yi)\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    def interpolate(x_left, x_right, y_left, y_right, x_interp):\n        return y_left + (y_right - y_left) * ((x_interp - x_left) / (x_right - x_left))\n    \n    y_interp = []\n\n    for x_inter in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= x_inter <= x[i+1]:\n                y_interp.append(interpolate(x[i], x[i+1], y[i], y[i+1], x_inter))\n                \n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Design a function entitled 'interpolate_1d_piecewise' to perform interpolation in a piecewise fashion for one-dimensional datasets. This function accepts three parameters: 'x', representing x-values, 'y', indicating corresponding y-values, and 'x_interp', listing x-coordinates where interpolation is desired. It is expected to produce a list containing the interpolated y-values pertinent to the x-coordinates listed in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x)-1):\n            if x[i] <= xi <= x[i + 1]:\n                slope = (y[i + 1] - y[i]) / (x[i + 1] - x[i])\n                yi = y[i] + slope * (xi - x[i])\n                y_interp.append(yi)\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    x_sort = sorted(x)\n    y_sort = sorted(y)\n    x_interp_sort = sorted(x_interp)\n    result = []\n\n    for x_p in x_interp_sort:\n        i = 0\n        while i < len(x_sort) and x_p > x_sort[i]:\n            i += 1\n\n        if i == 0:\n            result.append(y_sort[0])\n        elif i == len(x_sort):\n            result.append(y_sort[-1])\n        else:\n            x_low = x_sort[i - 1]\n            x_high = x_sort[i]\n            y_low = y_sort[i - 1]\n            y_high = y_sort[i]\n            result.append((y_high - y_low) / (x_high - x_low) * (x_p - x_low) + y_low)\n\n    return result",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    This function performs linear interpolation in a piecewise fashion for one-dimensional datasets. \n    It accepts three parameters: 'x', representing x-values, 'y', indicating corresponding y-values, and 'x_interp', listing x-coordinates where interpolation is desired. \n    The function produces a list containing the interpolated y-values pertinent to the x-coordinates listed in 'x_interp'.\n    \"\"\"\n    def calculate_slope(x1, x2, y1, y2):\n        \"\"\"\n        This helper function calculates the slope between two points.\n        \"\"\"\n        return (y2 - y1) / (x2 - x1)\n\n    def calculate_intercept(x, y, slope):\n        \"\"\"\n        This helper function calculates the intercept of the line that connects two points.\n        \"\"\"\n        return y - slope * x\n\n    def interpolate(slope, intercept, x_interp):\n        \"\"\"\n        This helper function applies the formula for linear interpolation.\n        \"\"\"\n        return slope * x_interp + intercept\n\n    # Ensure x and y have the same length\n    if len(x) != len(y):\n        raise ValueError(\"x and y must have the same length\")\n\n    # Ensure x and x_interp are sorted\n    if x != sorted(x):\n        raise ValueError(\"x must be sorted in ascending order\")\n\n    if x_interp != sorted(x_interp):\n        raise ValueError(\"x_interp must be sorted in ascending order\")\n\n    # Find the points on either side of each x_interp in x\n    x_points = [(i, i - 1) for i in range(1, len(x)) if x[i - 1] <= x_interp[i] <= x[i]]\n\n    # Calculate the slope and intercept between each pair of points\n    slopes = [calculate_slope(x[i], x[i - 1], y[i], y[i - 1]) for i in range(1, len(x))]\n    intercepts = [calculate_intercept(x[i], y[i], slope) for i, slope in zip(range(1, len(x)), slopes)]\n\n    # Interpolate each x_interp\n    y_interp = [interpolate(slopes[i], intercepts[i], x_interp[i]) for i in range(len(x_interp))]\n\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Construct a function called 'interpolate_1d_piecewise' to manage piecewise interpolation for data in one dimension. It requires three inputs: 'x' and 'y', lists of respective x and y data point coordinates; and 'x_interp', a list indicating the x-coordinates at which to compute interpolation. It should deliver a list of y-coordinates interpolated corresponding to the x-coordinates supplied in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    result = []\n    for xi in x_interp:\n        yi = None\n        for i in range(len(x)):\n            if x[i] == xi:\n                yi = y[i]\n                break\n            elif i > 0 and x[i-1] < xi < x[i]:\n                m = (y[i] - y[i-1]) / (x[i] - x[i-1])\n                yi = y[i-1] + m * (xi - x[i-1])\n                break\n        result.append(yi)\n    return result",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    def interpolate(x_left, x_right, y_left, y_right, x_interp):\n        return (y_right - y_left) / (x_right - x_left) * (x_interp - x_left) + y_left\n    \n    y_interp = []\n\n    for x_inter in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= x_inter <= x[i + 1]:\n                y_interp.append(interpolate(x[i], x[i + 1], y[i], y[i + 1], x_inter))\n                \n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Construct a function called 'interpolate_1d_piecewise' to manage piecewise interpolation for data in one dimension. It requires three inputs: 'x' and 'y', lists of respective x and y data point coordinates; and 'x_interp', a list indicating the x-coordinates at which to compute interpolation. It should deliver a list of y-coordinates interpolated corresponding to the x-coordinates supplied in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    import numpy as np\n    # Sort the input data points in ascending order of x\n    indices = np.argsort(x)\n    x = np.array(x)[indices]\n    y = np.array(y)[indices]\n    \n    # Define an empty list for interpolated y values\n    y_interp = []\n    \n    # For each interpolation point\n    for x_i in x_interp:\n        # Find the index j such that x[j-1] < x_i <= x[j]\n        j = np.searchsorted(x, x_i, side='right')\n        \n        # If x_i is less than the smallest x, use the first point\n        if j == 0:\n            y_interp.append(y[0])\n        # If x_i is greater than the greatest x, use the last point\n        elif j >= len(x):\n            y_interp.append(y[-1])\n        # Otherwise, interpolate between x[j-1] and x[j]\n        else:\n            x0, y0, x1, y1 = x[j-1], y[j-1], x[j], y[j]\n            y_interp.append(y0 + (y1 - y0) * (x_i - x0) / (x1 - x0))\n    \n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Construct a function called 'interpolate_1d_piecewise' to manage piecewise interpolation for data in one dimension. It requires three inputs: 'x' and 'y', lists of respective x and y data point coordinates; and 'x_interp', a list indicating the x-coordinates at which to compute interpolation. It should deliver a list of y-coordinates interpolated corresponding to the x-coordinates supplied in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    assert len(x) == len(y), \"The number of x data points must be equal to the number of y data points\"\n    assert all(xi < x[i+1] for i in range(len(x)-1) for xi in x_interp if xi < x[i] or xi > x[i+1]), \"Interpolation points must lie within the range of x_interp\"\n\n    def interpolate(x_interp):\n        i = 0\n        while i < len(x) - 1 and x[i] <= x_interp:\n            i += 1\n        i -= 1\n        if x[i] == x[i+1]:\n            return None\n        return y[i] + ((y[i+1] - y[i]) * (x_interp - x[i])) / (x[i+1] - x[i])\n\n    return [interpolate(x_interp[i]) for i in range(len(x_interp))]",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Construct a function called 'interpolate_1d_piecewise' to manage piecewise interpolation for data in one dimension. It requires three inputs: 'x' and 'y', lists of respective x and y data point coordinates; and 'x_interp', a list indicating the x-coordinates at which to compute interpolation. It should deliver a list of y-coordinates interpolated corresponding to the x-coordinates supplied in 'x_interp'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for x_i in x_interp:\n        if x_i < x[0] or x_i > x[-1]:\n            print(f\"Interpolation point {x_i} is out of the range of given data points.\")\n            continue\n        for i in range(len(x)-1):\n            if x[i] <= x_i <= x[i+1]:\n                y_interp.append(y[i] + (y[i+1] - y[i]) * (x_i - x[i]) / (x[i+1] - x[i]))\n                break\n    return y_interp",
                false
            ]
        ],
        "level 2": [
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Perform piecewise interpolation for one-dimensional data using the function \"interpolate_1d_piecewise\". This function receives three lists as parameters: \"x\" (x-coordinates of original data points), \"y\" (y-coordinates of original data points), and \"x_interp\" (x-coordinates where interpolation is to be computed). The goal is to generate a list of interpolated y-values corresponding to each entry in \"x_interp\". The interpolation is performed by iterating over \"x_interp\" and for each point, determining its position relative to the nearest data points in \"x\". Instead of computing a linear interpolation, the function selects the y-value of the nearest x-point based on proximity. This results in a piecewise constant approximation, where each segment between two consecutive x-points from \"x\" assumes a constant y-value determined by the nearest x-point.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    # Sorting the points in ascending order\n    x_sort = sorted(enumerate(x), key=lambda x: x[1])\n    y_interp = []\n    \n    # Perform piecewise interpolation\n    for x_i in x_interp:\n        # Find the nearest data point\n        i = bisect_left(x, x_i)\n        if i == len(x):\n            y_interp.append(y[i-1])\n        elif i == 0:\n            y_interp.append(y[i])\n        elif x_i - x[i-1] < x[i] - x[i-1]:\n            y_interp.append(y[i-1])\n        else:\n            y_interp.append(y[i])\n            \n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for x_point in x_interp:\n        nearest_index = min(range(len(x)), key=lambda i: abs(x[i]-x_point))\n        y_interp.append(y[nearest_index])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Perform piecewise interpolation for one-dimensional data using the function \"interpolate_1d_piecewise\". This function receives three lists as parameters: \"x\" (x-coordinates of original data points), \"y\" (y-coordinates of original data points), and \"x_interp\" (x-coordinates where interpolation is to be computed). The goal is to generate a list of interpolated y-values corresponding to each entry in \"x_interp\". The interpolation is performed by iterating over \"x_interp\" and for each point, determining its position relative to the nearest data points in \"x\". Instead of computing a linear interpolation, the function selects the y-value of the nearest x-point based on proximity. This results in a piecewise constant approximation, where each segment between two consecutive x-points from \"x\" assumes a constant y-value determined by the nearest x-point.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for i in x_interp:\n        diff = [abs(j-i) for j in x]\n        min_index = diff.index(min(diff))\n        y_interp.append(y[min_index])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for i in x_interp:\n        if i in x:  # check if x_interp is in x, if true just append the corresponding y value\n            y_interp.append(y[x.index(i)])\n        else:  \n            for j in range(len(x) - 1):\n                if x[j] <= i <= x[j + 1]:  # find the range where x_interp falls\n                    y1, y2 = y[j], y[j + 1]\n                    x1, x2 = x[j], x[j + 1]\n                    y_interp.append(y1)  # append the closest y value\n                    break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        # Find the nearest point in \"x\" to \"xi\"\n        nearest_point = min(x, key=lambda x: abs(x - xi))\n        # Find the index of the nearest point in \"x\"\n        index = x.index(nearest_point)\n        # Append the corresponding y-value from \"y\" to \"y_interp\"\n        y_interp.append(y[index])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Using the function 'interpolate_1d_piecewise', conduct a piecewise interpolation on one-dimensional data. This function takes three lists: 'x' representing the x-coordinates of the original data, 'y' indicating the y-coordinates of these data points, and 'x_interp', the x-coordinates at which you want to estimate the y-values. The aim is to create a list of y-values for each position in 'x_interp' by checking each point's proximity to the nearest original data points in 'x'. Rather than performing a linear interpolation, this method uses the nearest y-value from 'x', thereby maintaining a piecewise constant output for segments between consecutive x-points in 'x'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for xi in x_interp:\n        if xi < x[0]:\n            y_interp.append(y[0])\n        elif xi > x[-1]:\n            y_interp.append(y[-1])\n        else:\n            idx = next((i for i, val in enumerate(x) if val > xi), len(x)-1)\n            y_interp.append(y[idx])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for x_point in x_interp:\n        nearest_index = min(range(len(x)), key=lambda i: abs(x[i]-x_point))\n        y_interp.append(y[nearest_index])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Using the function 'interpolate_1d_piecewise', conduct a piecewise interpolation on one-dimensional data. This function takes three lists: 'x' representing the x-coordinates of the original data, 'y' indicating the y-values of these data points, and 'x_interp', the x-coordinates at which you want to estimate the y-values. The aim is to create a list of y-values for each position in 'x_interp' by checking each point's proximity to the nearest original data points in 'x'. Rather than performing a linear interpolation, this method uses the nearest y-value from 'x', thereby maintaining a piecewise constant output for segments between consecutive x-points in 'x'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    # Sorting the original data\n    x_sorted, y_sorted = zip(*sorted(zip(x,y)))\n    x_sorted = list(x_sorted)\n    y_sorted = list(y_sorted)\n\n    # Interpolating the data\n    y_interp = []\n    for xi in x_interp:\n        # Finding the nearest x-value in the sorted list\n        idx = min(range(len(x_sorted)), key=lambda i: abs(x_sorted[i]-xi))\n        y_interp.append(y_sorted[idx])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for i in x_interp:\n        min_i = min(range(len(x)), key=lambda j: abs(x[j]-i))\n        y_interp.append(y[min_i])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        # Find the nearest point in x to xi\n        nearest_idx = min(range(len(x)), key=lambda i: abs(x[i]-xi))\n        # Use the y-value of the nearest point\n        y_interp.append(y[nearest_idx])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Execute piecewise interpolation on 1D data by utilizing the 'interpolate_1d_piecewise' function. It accepts three arrays: 'x' (the x-coordinates of the starting data points), 'y' (the y-coordinates of these points), and 'x_interp' (the x-coordinates for which y-values need interpolation). It generates interpolated y-values by iterating over 'x_interp' to determine proximity to nearest data points in 'x'. This approach avoids linear interpolations, instead selecting the closest y-coordinate from 'x', resulting in a constant y-value across each segment between consecutive x-points.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    \n    y_interp = []\n    for i in range(len(x_interp)):\n        min_diff = float('inf')\n        y_val = None\n        for j in range(len(x)):\n            diff = abs(x_interp[i] - x[j])\n            if diff < min_diff:\n                min_diff = diff\n                y_val = y[j]\n        y_interp.append(y_val)\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for x_point in x_interp:\n        nearest_index = min(range(len(x)), key=lambda i: abs(x[i]-x_point))\n        y_interp.append(y[nearest_index])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Execute piecewise interpolation on 1D data by utilizing the 'interpolate_1d_piecewise' function. It accepts three arrays: 'x' (the x-coordinates of the starting data points), 'y' (the y-coordinates of these points), and 'x_interp' (the x-coordinates for which y-values need interpolation). It generates interpolated y-values by iterating over 'x_interp' to determine proximity to nearest data points in 'x'. This approach avoids linear interpolations, instead selecting the closest y-coordinate from 'x', resulting in a constant y-value across each segment between consecutive x-points.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for xi in x_interp:\n        index = min(range(len(x)), key=lambda i: abs(x[i]-xi))\n        y_interp.append(y[index])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for i in x_interp:\n        closest_i = min(range(len(x)), key=lambda j: abs(x[j]-i))\n        y_interp.append(y[closest_i])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        # Find the index of the nearest x value in x\n        idx = min(range(len(x)), key=lambda i: abs(x[i]-xi))\n        # Get the corresponding y value\n        yi = y[idx]\n        y_interp.append(yi)\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Use the 'interpolate_1d_piecewise' function for performing piecewise interpolation on one-dimensional datasets. The function receives three parameters as lists: 'x', which are the x-coordinates of the initial data points; 'y', their corresponding y-coordinates; and 'x_interp', the x-coordinates for interpolation. For each x-coordinate in 'x_interp', the function determines the closest original x-points and adopts their y-value, foregoing linear interpolation. This results in a y-value that is constant between successive x-points in 'x'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for x_i in x_interp:\n        if x_i in x:\n            y_interp.append(y[x.index(x_i)])\n        else:\n            for i in range(len(x) - 1):\n                if x[i] < x_i < x[i + 1]:\n                    y_interp.append(y[i])\n                elif x_i == x[i]:\n                    y_interp.append(y[i])\n                elif x_i == x[i + 1]:\n                    y_interp.append(y[i + 1])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for x_point in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= x_point <= x[i+1]:\n                y_interp.append(y[i])\n                break\n            if x[i] > x_point:\n                y_interp.append(y[0])\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Use the 'interpolate_1d_piecewise' function for performing piecewise interpolation on one-dimensional datasets. The function receives three parameters as lists: 'x', which are the x-coordinates of the initial data points; 'y', their corresponding y-coordinates; and 'x_interp', the x-coordinates for interpolation. For each x-coordinate in 'x_interp', the function determines the closest original x-points and adopts their y-value, foregoing linear interpolation. This results in a y-value that is constant between successive x-points in 'x'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for i in x_interp:\n        if i < x[0]:\n            y_interp.append(y[0])\n        elif i > x[-1]:\n            y_interp.append(y[-1])\n        else:\n            j = 0\n            while j < len(x)-1 and i > x[j]:\n                j += 1\n            y_interp.append(y[j])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for i in x_interp:\n        closest_i = min(range(len(x)), key=lambda j: abs(x[j]-i))\n        y_interp.append(y[closest_i])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        # Find the closest original x-points\n        idx = min(range(len(x)), key=lambda i: abs(x[i]-xi))\n        # Append the corresponding y-value\n        y_interp.append(y[idx])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    if not x or not y or not x_interp:\n        return []\n    \n    x.sort()\n    y.sort()\n    y_interp = []\n    \n    for x_i in x_interp:\n        if x_i < x[0]:\n            y_interp.append(y[0])\n            continue\n        if x_i > x[-1]:\n            y_interp.append(y[-1])\n            continue\n            \n        for i in range(len(x) - 1):\n            if x[i] <= x_i <= x[i+1]:\n                y_interp.append(y[i])\n                break\n            \n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for x_point in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= x_point <= x[i + 1]:\n                y_interp.append(y[i])\n                break\n            elif x[i + 1] < x_point:\n                y_interp.append(y[i + 1])\n                break\n        else:\n            if x_point < x[0]:\n                y_interp.append(y[0])\n            elif x_point > x[-1]:\n                y_interp.append(y[-1])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Implement a piecewise interpolation for a set of one-dimensional data points using the 'interpolate_1d_piecewise' function, which processes three input lists: 'x'\u2014the x-values of the data, 'y'\u2014the corresponding y-values, and 'x_interp'\u2014the x-values where y-values need to be interpolated. The procedure iterates over 'x_interp', finding each point's nearest x-values from 'x' to assign the closest y-value, hence skipping a linear interpolation approach and maintaining piecewise constant y-values for segments defined by consecutive x-points.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    def find_nearest(array, value):\n        array = np.asarray(array)\n        idx = (np.abs(array - value)).argmin()\n        return idx\n    \n    y_interp = []\n    for x_val in x_interp:\n        idx = find_nearest(x, x_val)\n        y_interp.append(y[idx])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for i in x_interp:\n        if i in x:\n            y_interp.append(y[x.index(i)])\n        else:\n            for j in range(len(x)-1):\n                if x[j] <= i <= x[j+1]:\n                    y_interp.append(y[j])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        # Find the index of the nearest x value in x\n        idx = min(range(len(x)), key=lambda i: abs(x[i]-xi))\n        # If xi is less than the first x value, use the first y value\n        if xi < x[0]:\n            y_interp.append(y[0])\n        # If xi is greater than the last x value, use the last y value\n        elif xi > x[-1]:\n            y_interp.append(y[-1])\n        # Otherwise, use the y value at the found index\n        else:\n            y_interp.append(y[idx])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Carry out a piecewise interpolation of 1D data using the provided 'interpolate_1d_piecewise' function. Input parameters include three lists: 'x', the x-coordinates of your data points; 'y', the y-coordinates associated with these points; and 'x_interp', x-coordinates at which to perform the interpolation. By examining each entry in 'x_interp' to find the nearest points on 'x', the function ascribes the y-value of the closest x-point, preserving piecewise constant y-values throughout intervals between neighboring x-points from the list 'x'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    # Initialize an empty list to store the interpolated y values\n    y_interp = []\n\n    # For each interpolation point\n    for i in x_interp:\n        # Find the nearest data point\n        nearest_index = min(range(len(x)), key=lambda j: abs(x[j]-i))\n\n        # Add the corresponding y value to our list of interpolated y values\n        y_interp.append(y[nearest_index])\n\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for x_point in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= x_point <= x[i + 1]:\n                y_interp.append(y[i])\n                break\n            if x_point < x[0]:\n                y_interp.append(y[0])\n                break\n            if x_point > x[-1]:\n                y_interp.append(y[-1])\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Carry out a piecewise interpolation of 1D data using the provided 'interpolate_1d_piecewise' function. Input parameters include three lists: 'x', the x-coordinates of your data points; 'y', the y-coordinates associated with these points; and 'x_interp', x-coordinates at which to perform the interpolation. By examining each entry in 'x_interp' to find the nearest points on 'x', the function ascribes the y-value of the closest x-point, preserving piecewise constant y-values throughout intervals between neighboring x-points from the list 'x'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    def find_nearest_index(array, value):\n        array = np.asarray(array)\n        idx = (np.abs(array - value)).argmin()\n        return idx\n    \n    y_interp = []\n    for x_val in x_interp:\n        index = find_nearest_index(x, x_val)\n        y_interp.append(y[index])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for i in x_interp:\n        if i in x:\n            index = x.index(i)\n            y_interp.append(y[index])\n        else:\n            for j in range(len(x)-1):\n                if x[j] < i < x[j+1]:\n                    y_interp.append(y[j] + (y[j+1]-y[j]) * (i-x[j]) / (x[j+1]-x[j]))\n                    break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        # Find the index of the nearest x value\n        idx = min(range(len(x)), key=lambda i: abs(x[i]-xi))\n        # Append the corresponding y value\n        y_interp.append(y[idx])\n    return y_interp",
                false
            ]
        ],
        "level 3": [
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        if xi < x[0] or xi > x[-1]:\n            raise ValueError(\"Input x-coordinate out of range\")\n        for i in range(len(x)-1):\n            if x[i] <= xi <= x[i+1]:\n                if x[i+1] - xi < xi - x[i]:\n                    y_interp.append(y[i+1])\n                else:\n                    y_interp.append(y[i])\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if abs(x[i + 1] - xi) < abs(xi - x[i]):\n                    y_interp.append(y[i + 1])\n                else:\n                    y_interp.append(y[i])\n    return y_interp",
                true
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Perform piecewise interpolation for one-dimensional data using the \"interpolate_1d_piecewise\" method of the \"Interpolation\" class. This function accepts three parameters: \"x\", \"y\", and \"x_interp\", all of which are lists. \"x\" and \"y\" represent the coordinates of the data points, while \"x_interp\" contains the x-coordinates at which interpolation is desired. The function returns a list of interpolated y-values corresponding to each x-coordinate in \"x_interp\". Inside the method, a local list \"y_interp\" is initialized to store the results. The function iterates over each element \"xi\" in \"x_interp\", and for each \"xi\", it iterates over the range of \"x\" indices to find the segment (between two consecutive \"x\" values) where \"xi\" falls. The method then compares the distances to the boundaries of this segment and assigns \"yi\" as the y-value of the closest boundary point, that is \"y[i+1]\" if \"x[i+1] - xi < xi - x[i]\" otherwise \"y[i]\". This value is then appended to \"y_interp\". The process ensures a piecewise constant interpolation, where each interval defined by consecutive \"x\" values assumes the y-value of the point closer to \"xi\".\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if x[i + 1] - xi < xi - x[i]:\n                    y_interp.append(y[i + 1])\n                else:\n                    y_interp.append(y[i])\n    return y_interp",
                true
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if x[i + 1] - xi < xi - x[i]:\n                    yi = y[i + 1]\n                else:\n                    yi = y[i]\n                y_interp.append(yi)\n                break\n    return y_interp",
                true
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if x[i + 1] - xi < xi - x[i]:\n                    y_interp.append(y[i + 1])\n                else:\n                    y_interp.append(y[i])\n    return y_interp",
                true
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        if xi < x[0] or xi > x[-1]:\n            raise ValueError(\"x_interp must be within the range of x\")\n        i = 0\n        while x[i] < xi:\n            i += 1\n        yi = y[i-1] if xi-x[i-1] < x[i]-xi else y[i]\n        y_interp.append(yi)\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if abs(xi - x[i]) < abs(xi - x[i + 1]):\n                    yi = y[i]\n                else:\n                    yi = y[i + 1]\n                y_interp.append(yi)\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Carry out a piecewise constant interpolation of one-dimensional data using the function named 'interpolate_1d_piecewise' from the 'Interpolation' class. This method receives three lists as parameters: 'x', 'y', and 'x_interp'. The lists 'x' and 'y' contain the data point coordinates, while 'x_interp' consists of the x-coordinates where you want to perform the interpolation. It outputs a list comprising the interpolated y-values for each x-coordinate specified in 'x_interp'. Within the function, 'y_interp' is initially an empty list that is populated by iterating over each 'xi' in 'x_interp'. During each iteration, it traverses through the segments created by consecutive 'x' values to locate the correct segment for 'xi'. Depending on which endpoint of the segment 'xi' is closer to, either 'y[i+1]' or 'y[i]' is assigned to 'yi', subsequently appended to 'y_interp'. This ensures that the interpolation within each segment reflects the y-value of the endpoint nearest to 'xi'.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] < xi <= x[i + 1]:\n                if xi - x[i] < x[i + 1] - xi:\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i + 1])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                y_interp.append(y[i])\n                break\n        else:\n            y_interp.append(y[-1])\n            \n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if xi - x[i] <= x[i + 1] - xi:\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i + 1])\n    return y_interp",
                true
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        if xi < x[0] or xi > x[-1]:\n            raise ValueError(\"Input x-coordinate out of range\")\n        for i in range(len(x)-1):\n            if x[i] <= xi <= x[i+1]:\n                if xi - x[i] < x[i+1] - xi:\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i+1])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if abs(xi - x[i]) < abs(xi - x[i + 1]):\n                    y_interp.append(y[i])\n                    break\n                else:\n                    y_interp.append(y[i + 1])\n                    break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Implement a method 'interpolate_1d_piecewise' inside the 'Interpolation' class for piecewise constant interpolation of one-dimensional data. The function takes three input lists, namely 'x', 'y', and 'x_interp'. The 'x' and 'y' lists denote the coordinates of the data points, whereas 'x_interp' lists the x-coordinates at which you need interpolated values. It returns a list of y-values interpolated at the x-coordinates specified in 'x_interp'. Starting with an empty list 'y_interp', the function iterates each 'xi' in 'x_interp', scans through intervals formed by consecutive 'x' values to find the interval containing 'xi', and determines the y-value by choosing the closer endpoint value, either 'y[i+1]' if 'xi' is closer to 'x[i+1]', or 'y[i]' otherwise, which is then added to 'y_interp'. This setup ensures piecewise constant interpolation with each 'xi' taking the y-value of the closest data point.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if (xi >= x[i]) and (xi <= x[i+1]):\n                if (xi - x[i]) < (x[i+1] - xi):\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i+1])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if xi - x[i] <= x[i + 1] - xi:\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i + 1])\n    return y_interp",
                true
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if xi - x[i] <= x[i + 1] - xi:\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i + 1])\n    return y_interp",
                true
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        if xi < x[0] or xi > x[-1]:\n            raise ValueError(\"x_interp must be within the range of x\")\n        i = 0\n        while x[i] < xi:\n            i += 1\n        if abs(x[i] - xi) < abs(x[i-1] - xi):\n            y_interp.append(y[i])\n        else:\n            y_interp.append(y[i-1])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i+1]:\n                dx = xi - x[i]\n                dy = y[i+1] - y[i]\n                y_interp.append(y[i] + dy * dx / (x[i+1] - x[i]))\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Use the 'interpolate_1d_piecewise' function from the 'Interpolation' class to perform a piecewise constant interpolation on one-dimensional data. The method requires three argument lists: 'x', which are the x-coordinates of data points; 'y', which are the corresponding y-coordinates; and 'x_interp', the x-coordinates at which to interpolate. The function generates a list of y-values corresponding to each 'x_interp' coordinate by first initializing an empty list, 'y_interp'. For each 'xi' in 'x_interp', the function identifies the appropriate segment between consecutive 'x' values where 'xi' falls, determines which endpoint of the segment is nearer, and adds the corresponding y-value to 'y_interp', either 'y[i+1]' if closer to 'x[i+1]' or 'y[i]' if closer to 'x[i]'. This ensures the interpolation is piecewise constant and accurately reflects the nearest original data point's y-value.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if xi - x[i] < x[i + 1] - xi:\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i + 1])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if xi - x[i] < x[i + 1] - xi:\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i + 1])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        i = 0\n        while i < (len(x) - 1) and x[i] < xi:\n            i += 1\n        if abs(xi - x[i]) < abs(xi - x[i-1]):\n            y_interp.append(y[i])\n        else:\n            y_interp.append(y[i-1])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        if xi < x[0] or xi > x[-1]:\n            raise ValueError(\"Input x-coordinate out of range\")\n        for i in range(len(x)-1):\n            if x[i] <= xi <= x[i+1]:\n                y_interp.append(y[i])\n                break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if abs(xi - x[i]) < abs(xi - x[i + 1]):\n                    y_interp.append(y[i])\n                    break\n                else:\n                    y_interp.append(y[i + 1])\n                    break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Execute a piecewise constant interpolation using the 'interpolate_1d_piecewise' function of the 'Interpolation' class, which takes three parameters in the form of lists: 'x', 'y', and 'x_interp'. Here, 'x' and 'y' denote the sets of coordinates for the data points, whereas 'x_interp' includes the x-coordinates where interpolation must be conducted. The method produces a list containing interpolated y-values associated with each coordinate in 'x_interp'. Inside the method, an empty list 'y_interp' gathers the interpolated values. As the function progresses through each 'xi' in 'x_interp', it compares segments defined by adjacent 'x' values, locating the right interval for 'xi' and deciding whether 'yi' should be 'y[i+1]' or 'y[i]' based on proximity, accumulating these values in 'y_interp'. This method ensures that the output interpolation is piecewise constant, with intervals adopting the y-value of the closest x-boundary.\n     :param x: The x-coordinate of the data point, list.\n     :param y: The y-coordinate of the data point, list.\n     :param x_interp: The x-coordinate of the interpolation point, list.\n     :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x)-1):\n            if x[i] <= xi <= x[i+1]:\n                y_interp.append(y[i])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for i in x_interp:\n        if i <= x[0]:\n            y_interp.append(y[0])\n        elif i >= x[-1]:\n            y_interp.append(y[-1])\n        else:\n            for j in range(len(x)-1):\n                if x[j] < i <= x[j+1]:\n                    y_interp.append(y[j])\n                    break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if xi - x[i] <= x[i + 1] - xi:\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i + 1])\n    return y_interp",
                true
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        if xi < x[0] or xi > x[-1]:\n            raise ValueError(\"Input x-coordinate out of range\")\n        for i in range(len(x)-1):\n            if x[i] <= xi <= x[i+1]:\n                if xi - x[i] < x[i+1] - xi:\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i+1])\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if abs(xi - x[i]) < abs(xi - x[i + 1]):\n                    y_interp.append(y[i])\n                    break\n                else:\n                    y_interp.append(y[i + 1])\n                    break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    \"\"\"\n    Apply piecewise constant one-dimensional interpolation through the 'interpolate_1d_piecewise' function found in the 'Interpolation' class. This function accepts three list parameters\u2014'x', 'y', and 'x_interp'. The 'x' and 'y' lists represent the coordinates of the data points, and 'x_interp' includes the x-coordinates where the interpolation is required. The outcome is a list that contains interpolated y-values corresponding to each 'x_interp' coordinate. Within the function, 'y_interp' is a list that initializes empty and is populated as the function iterates over each 'xi' in 'x_interp'. By examining each segment delineated by consecutive 'x' values, it identifies where 'xi' is situated, assigns 'yi' based on the nearest endpoint\u2014'y[i+1]' if 'xi' is nearer to 'x[i+1]' or 'y[i]' if otherwise, and appends this to 'y_interp'. This ensures the interpolation is piecewise constant, each 'xi' adopting the y-value of its nearest point.\n    :param x: The x-coordinate of the data point, list.\n    :param y: The y-coordinate of the data point, list.\n    :param x_interp: The x-coordinate of the interpolation point, list.\n    :return: The y-coordinate of the interpolation point, list.\n    \"\"\"\n    y_interp = []\n    for xi in x_interp:\n        if xi <= x[0]:\n            y_interp.append(y[0])\n        elif xi >= x[-1]:\n            y_interp.append(y[-1])\n        else:\n            for i in range(len(x)-1):\n                if x[i] <= xi <= x[i+1]:\n                    if xi - x[i] < x[i+1] - xi:\n                        y_interp.append(y[i])\n                    else:\n                        y_interp.append(y[i+1])\n                    break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for i in x_interp:\n        if i <= x[0]:\n            y_interp.append(y[0])\n        elif i >= x[-1]:\n            y_interp.append(y[-1])\n        else:\n            for j in range(len(x)-1):\n                if x[j] < i <= x[j+1]:\n                    y_interp.append(y[j])\n                    break\n    return y_interp",
                false
            ],
            [
                "def interpolate_1d_piecewise(x, y, x_interp):\n    y_interp = []\n    for xi in x_interp:\n        for i in range(len(x) - 1):\n            if x[i] <= xi <= x[i + 1]:\n                if xi - x[i] <= x[i + 1] - xi:\n                    y_interp.append(y[i])\n                else:\n                    y_interp.append(y[i + 1])\n    return y_interp",
                true
            ]
        ]
    }
}